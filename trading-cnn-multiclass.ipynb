{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sheet I will apply Convolutional Neural Networks for stock prediction of S&P500 index. I will divide data from last 20 years into chunks. Every day contains four values: opening, low, high and closing ones - therefore input data for 30-day chunk has size 30x4. Predicted output has three classes: whether stock will go up, down or stay constant X days after last input.\n",
    "\n",
    "Story: Investor observes stock for 60 days. Then decides whether buy some stocks and sell it after 10 days. Therefore input consist of stock prices from day 1st to 60th, output is:\n",
    "* 0 if price will go down by more than \\$\\{PERCENTAGE_THRESHOLD\\}%, \n",
    "* 1 if price will not go up or down by more than \\$\\{PERCENTAGE_THRESHOLD\\}% \n",
    "* 2 if price will go up by more than \\$\\{PERCENTAGE_THRESHOLD\\}%\n",
    "\n",
    "Relative change output is calculated using the following formula: (opening_price_on_buyout_day -closing_price_on_last_day_of_observation) / opening_price_on_buyout_day * 100%\n",
    "\n",
    "Based on percentage value from formula above, label will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_TIME = 60\n",
    "PREDICTION_AFTER_DAYS = 10\n",
    "PERCENTAGE_THRESHOLD = 1\n",
    "EPOCHS = 500\n",
    "TEST_SIZE = 0.10\n",
    "RANDOM_SPLIT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-22</td>\n",
       "      <td>1346.089966</td>\n",
       "      <td>1358.109985</td>\n",
       "      <td>1331.880005</td>\n",
       "      <td>1352.170044</td>\n",
       "      <td>1352.170044</td>\n",
       "      <td>980000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-23</td>\n",
       "      <td>1352.170044</td>\n",
       "      <td>1370.109985</td>\n",
       "      <td>1342.439941</td>\n",
       "      <td>1360.689941</td>\n",
       "      <td>1360.689941</td>\n",
       "      <td>993700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-02-24</td>\n",
       "      <td>1360.689941</td>\n",
       "      <td>1364.800049</td>\n",
       "      <td>1329.880005</td>\n",
       "      <td>1353.430054</td>\n",
       "      <td>1353.430054</td>\n",
       "      <td>1215000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>1353.430054</td>\n",
       "      <td>1362.140015</td>\n",
       "      <td>1329.150024</td>\n",
       "      <td>1333.359985</td>\n",
       "      <td>1333.359985</td>\n",
       "      <td>1065200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-02-28</td>\n",
       "      <td>1333.359985</td>\n",
       "      <td>1360.819946</td>\n",
       "      <td>1325.069946</td>\n",
       "      <td>1348.050049</td>\n",
       "      <td>1348.050049</td>\n",
       "      <td>1026500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2000-02-22  1346.089966  1358.109985  1331.880005  1352.170044   \n",
       "1  2000-02-23  1352.170044  1370.109985  1342.439941  1360.689941   \n",
       "2  2000-02-24  1360.689941  1364.800049  1329.880005  1353.430054   \n",
       "3  2000-02-25  1353.430054  1362.140015  1329.150024  1333.359985   \n",
       "4  2000-02-28  1333.359985  1360.819946  1325.069946  1348.050049   \n",
       "\n",
       "     Adj Close      Volume  \n",
       "0  1352.170044   980000000  \n",
       "1  1360.689941   993700000  \n",
       "2  1353.430054  1215000000  \n",
       "3  1333.359985  1065200000  \n",
       "4  1348.050049  1026500000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/sp500_20Y_without_covid.csv')\n",
    "df.reindex(index=df.index[::-1])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_to_label(percentage_value):\n",
    "    return 0 if percentage_value < -PERCENTAGE_THRESHOLD else 1 if percentage_value <= PERCENTAGE_THRESHOLD else 2\n",
    "\n",
    "def investor_observes_stocks_for(x_days=60, then_buy_stocks=True, and_sells_them=True, after_y_days=10, dataframe=df):\n",
    "    assert then_buy_stocks\n",
    "    assert and_sells_them\n",
    "    observe_buy_sell_process_length = x_days + after_y_days\n",
    "    \n",
    "    observed_chunks = []\n",
    "    observation_results = []\n",
    "    \n",
    "    for first_day_of_observation in range(len(dataframe) - observe_buy_sell_process_length):\n",
    "        buyout_day = first_day_of_observation + x_days\n",
    "        sell_day = buyout_day + after_y_days\n",
    "        \n",
    "        observed_chunk = dataframe[first_day_of_observation:buyout_day].reset_index()\n",
    "        observation_result = dataframe.iloc[sell_day]\n",
    "        \n",
    "        closing_price_on_buyout_day = dataframe.iloc[buyout_day]['Close']\n",
    "        opening_price_on_sell_day = dataframe.iloc[sell_day]['Open']\n",
    "        \n",
    "        relative_price_change_as_percentage = (opening_price_on_sell_day - closing_price_on_buyout_day) / closing_price_on_buyout_day * 100\n",
    "        \n",
    "        observed_chunks += [observed_chunk]\n",
    "        observation_results += [percentage_to_label(relative_price_change_as_percentage)]\n",
    "    \n",
    "    return observed_chunks, observation_results\n",
    "\n",
    "observed_chunks, observation_results = investor_observes_stocks_for(x_days=OBSERVATION_TIME, then_buy_stocks=True, and_sells_them=True, after_y_days=PREDICTION_AFTER_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    2005\n",
       "1    1598\n",
       "0    1357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(observation_results)\n",
    "plt.show()\n",
    "\n",
    "pd.Series(observation_results).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE** Selecting test/valiations chunks randomly from the whole set of observation chunks seems to be a big mistake. It causes situation where network actually seen chunks from the future, therefore the more overfitted network, the better results will be. Network should be trained incrementally - with data from time x to x+1 and validated with data from x+1 to x+2. Then learned with data from x to x+2 and validated with data from x+3 to x+3 and so on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def categorical_labels(label_array):\n",
    "    return to_categorical(label_array)\n",
    "\n",
    "categorical_labels(observation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 60, 16)            336       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 60, 16)            64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 60, 8)             520       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60, 8)             32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 60, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 60, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                30784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 32,187\n",
      "Trainable params: 32,011\n",
      "Non-trainable params: 176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(input_shape = (60, 5), filters=16, kernel_size=4, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution1D(filters=8, kernel_size=4, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam\n",
    "import keras\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(optimizer=Nadam(lr=0.002),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4464, 60, 5), (4464, 3), (496, 60, 5), (496, 3))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(list(map(lambda df: df[['Open', 'High', 'Low', 'Close', 'Adj Close']].to_numpy(), observed_chunks)))\n",
    "Y = np.array(categorical_labels(observation_results))\n",
    "\n",
    "def chronological_split(X_data, Y_data, test_size=0.25):\n",
    "    training_test_split_index = int((1 - test_size) * len(X_data))\n",
    "    X_train = X_data[:training_test_split_index]\n",
    "    Y_train = Y_data[:training_test_split_index]\n",
    "    X_test = X_data[training_test_split_index:]\n",
    "    Y_test = Y_data[training_test_split_index:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "def random_split(X_data, Y_data, test_size=0.25):\n",
    "    return train_test_split(X_data, Y_data, test_size=test_size, random_state=42)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = random_split(X, Y, TEST_SIZE) if RANDOM_SPLIT else chronological_split(X, Y, TEST_SIZE)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4464 samples, validate on 496 samples\n",
      "Epoch 1/500\n",
      "4464/4464 [==============================] - 1s 261us/step - loss: 0.9900 - tp: 1438.0000 - fp: 997.0000 - tn: 7931.0000 - fn: 3026.0000 - accuracy: 0.5262 - precision: 0.5906 - recall: 0.3221 - auc: 0.7071 - val_loss: 1.7286 - val_tp: 141.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 355.0000 - val_accuracy: 0.3367 - val_precision: 0.3534 - val_recall: 0.2843 - val_auc: 0.4827\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.72863, saving model to model.hdf5\n",
      "Epoch 2/500\n",
      "4464/4464 [==============================] - 0s 77us/step - loss: 0.9833 - tp: 1452.0000 - fp: 954.0000 - tn: 7974.0000 - fn: 3012.0000 - accuracy: 0.5224 - precision: 0.6035 - recall: 0.3253 - auc: 0.7098 - val_loss: 1.3920 - val_tp: 130.0000 - val_fp: 213.0000 - val_tn: 779.0000 - val_fn: 366.0000 - val_accuracy: 0.3589 - val_precision: 0.3790 - val_recall: 0.2621 - val_auc: 0.5581\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.72863 to 1.39199, saving model to model.hdf5\n",
      "Epoch 3/500\n",
      "4464/4464 [==============================] - 0s 83us/step - loss: 0.9804 - tp: 1447.0000 - fp: 981.0000 - tn: 7947.0000 - fn: 3017.0000 - accuracy: 0.5237 - precision: 0.5960 - recall: 0.3241 - auc: 0.7110 - val_loss: 1.3096 - val_tp: 143.0000 - val_fp: 215.0000 - val_tn: 777.0000 - val_fn: 353.0000 - val_accuracy: 0.3730 - val_precision: 0.3994 - val_recall: 0.2883 - val_auc: 0.5621\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.39199 to 1.30963, saving model to model.hdf5\n",
      "Epoch 4/500\n",
      "4464/4464 [==============================] - 0s 80us/step - loss: 0.9721 - tp: 1448.0000 - fp: 951.0000 - tn: 7977.0000 - fn: 3016.0000 - accuracy: 0.5280 - precision: 0.6036 - recall: 0.3244 - auc: 0.7127 - val_loss: 1.3702 - val_tp: 162.0000 - val_fp: 213.0000 - val_tn: 779.0000 - val_fn: 334.0000 - val_accuracy: 0.4234 - val_precision: 0.4320 - val_recall: 0.3266 - val_auc: 0.5976\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.30963\n",
      "Epoch 5/500\n",
      "4464/4464 [==============================] - 0s 81us/step - loss: 0.9678 - tp: 1499.0000 - fp: 891.0000 - tn: 8037.0000 - fn: 2965.0000 - accuracy: 0.5381 - precision: 0.6272 - recall: 0.3358 - auc: 0.7197 - val_loss: 1.2623 - val_tp: 92.0000 - val_fp: 136.0000 - val_tn: 856.0000 - val_fn: 404.0000 - val_accuracy: 0.3488 - val_precision: 0.4035 - val_recall: 0.1855 - val_auc: 0.5174\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.30963 to 1.26231, saving model to model.hdf5\n",
      "Epoch 6/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9791 - tp: 1430.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 3034.0000 - accuracy: 0.5226 - precision: 0.6041 - recall: 0.3203 - auc: 0.7094 - val_loss: 1.6811 - val_tp: 166.0000 - val_fp: 304.0000 - val_tn: 688.0000 - val_fn: 330.0000 - val_accuracy: 0.3468 - val_precision: 0.3532 - val_recall: 0.3347 - val_auc: 0.5358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.26231\n",
      "Epoch 7/500\n",
      "4464/4464 [==============================] - 0s 76us/step - loss: 0.9601 - tp: 1431.0000 - fp: 863.0000 - tn: 8065.0000 - fn: 3033.0000 - accuracy: 0.5298 - precision: 0.6238 - recall: 0.3206 - auc: 0.7214 - val_loss: 1.5859 - val_tp: 167.0000 - val_fp: 279.0000 - val_tn: 713.0000 - val_fn: 329.0000 - val_accuracy: 0.3831 - val_precision: 0.3744 - val_recall: 0.3367 - val_auc: 0.5292\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.26231\n",
      "Epoch 8/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9635 - tp: 1399.0000 - fp: 872.0000 - tn: 8056.0000 - fn: 3065.0000 - accuracy: 0.5432 - precision: 0.6160 - recall: 0.3134 - auc: 0.7206 - val_loss: 1.7135 - val_tp: 151.0000 - val_fp: 288.0000 - val_tn: 704.0000 - val_fn: 345.0000 - val_accuracy: 0.3407 - val_precision: 0.3440 - val_recall: 0.3044 - val_auc: 0.4812\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.26231\n",
      "Epoch 9/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9633 - tp: 1427.0000 - fp: 823.0000 - tn: 8105.0000 - fn: 3037.0000 - accuracy: 0.5441 - precision: 0.6342 - recall: 0.3197 - auc: 0.7243 - val_loss: 1.5468 - val_tp: 159.0000 - val_fp: 244.0000 - val_tn: 748.0000 - val_fn: 337.0000 - val_accuracy: 0.3669 - val_precision: 0.3945 - val_recall: 0.3206 - val_auc: 0.5333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.26231\n",
      "Epoch 10/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9669 - tp: 1455.0000 - fp: 893.0000 - tn: 8035.0000 - fn: 3009.0000 - accuracy: 0.5385 - precision: 0.6197 - recall: 0.3259 - auc: 0.7204 - val_loss: 2.6661 - val_tp: 156.0000 - val_fp: 331.0000 - val_tn: 661.0000 - val_fn: 340.0000 - val_accuracy: 0.3206 - val_precision: 0.3203 - val_recall: 0.3145 - val_auc: 0.5143\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.26231\n",
      "Epoch 11/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.9641 - tp: 1446.0000 - fp: 863.0000 - tn: 8065.0000 - fn: 3018.0000 - accuracy: 0.5332 - precision: 0.6262 - recall: 0.3239 - auc: 0.7212 - val_loss: 1.6216 - val_tp: 120.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 376.0000 - val_accuracy: 0.3085 - val_precision: 0.3183 - val_recall: 0.2419 - val_auc: 0.4614\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.26231\n",
      "Epoch 12/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.9534 - tp: 1464.0000 - fp: 862.0000 - tn: 8066.0000 - fn: 3000.0000 - accuracy: 0.5392 - precision: 0.6294 - recall: 0.3280 - auc: 0.7263 - val_loss: 1.6289 - val_tp: 150.0000 - val_fp: 283.0000 - val_tn: 709.0000 - val_fn: 346.0000 - val_accuracy: 0.3327 - val_precision: 0.3464 - val_recall: 0.3024 - val_auc: 0.4897\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.26231\n",
      "Epoch 13/500\n",
      "4464/4464 [==============================] - 0s 76us/step - loss: 0.9631 - tp: 1433.0000 - fp: 859.0000 - tn: 8069.0000 - fn: 3031.0000 - accuracy: 0.5388 - precision: 0.6252 - recall: 0.3210 - auc: 0.7231 - val_loss: 1.3772 - val_tp: 117.0000 - val_fp: 207.0000 - val_tn: 785.0000 - val_fn: 379.0000 - val_accuracy: 0.3306 - val_precision: 0.3611 - val_recall: 0.2359 - val_auc: 0.4840\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.26231\n",
      "Epoch 14/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9517 - tp: 1436.0000 - fp: 809.0000 - tn: 8119.0000 - fn: 3028.0000 - accuracy: 0.5482 - precision: 0.6396 - recall: 0.3217 - auc: 0.7314 - val_loss: 2.7068 - val_tp: 201.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 295.0000 - val_accuracy: 0.4234 - val_precision: 0.4196 - val_recall: 0.4052 - val_auc: 0.5909\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.26231\n",
      "Epoch 15/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9583 - tp: 1451.0000 - fp: 866.0000 - tn: 8062.0000 - fn: 3013.0000 - accuracy: 0.5475 - precision: 0.6262 - recall: 0.3250 - auc: 0.7262 - val_loss: 1.5314 - val_tp: 137.0000 - val_fp: 224.0000 - val_tn: 768.0000 - val_fn: 359.0000 - val_accuracy: 0.3468 - val_precision: 0.3795 - val_recall: 0.2762 - val_auc: 0.5327\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.26231\n",
      "Epoch 16/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9595 - tp: 1450.0000 - fp: 859.0000 - tn: 8069.0000 - fn: 3014.0000 - accuracy: 0.5426 - precision: 0.6280 - recall: 0.3248 - auc: 0.7230 - val_loss: 1.5913 - val_tp: 143.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 353.0000 - val_accuracy: 0.3125 - val_precision: 0.3265 - val_recall: 0.2883 - val_auc: 0.4630\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.26231\n",
      "Epoch 17/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9586 - tp: 1466.0000 - fp: 836.0000 - tn: 8092.0000 - fn: 2998.0000 - accuracy: 0.5455 - precision: 0.6368 - recall: 0.3284 - auc: 0.7277 - val_loss: 1.4409 - val_tp: 103.0000 - val_fp: 191.0000 - val_tn: 801.0000 - val_fn: 393.0000 - val_accuracy: 0.3125 - val_precision: 0.3503 - val_recall: 0.2077 - val_auc: 0.4884\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.26231\n",
      "Epoch 18/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9551 - tp: 1477.0000 - fp: 869.0000 - tn: 8059.0000 - fn: 2987.0000 - accuracy: 0.5356 - precision: 0.6296 - recall: 0.3309 - auc: 0.7254 - val_loss: 2.1978 - val_tp: 182.0000 - val_fp: 304.0000 - val_tn: 688.0000 - val_fn: 314.0000 - val_accuracy: 0.3750 - val_precision: 0.3745 - val_recall: 0.3669 - val_auc: 0.5732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss did not improve from 1.26231\n",
      "Epoch 19/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9524 - tp: 1461.0000 - fp: 836.0000 - tn: 8092.0000 - fn: 3003.0000 - accuracy: 0.5470 - precision: 0.6360 - recall: 0.3273 - auc: 0.7306 - val_loss: 2.1223 - val_tp: 167.0000 - val_fp: 320.0000 - val_tn: 672.0000 - val_fn: 329.0000 - val_accuracy: 0.3407 - val_precision: 0.3429 - val_recall: 0.3367 - val_auc: 0.5530\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.26231\n",
      "Epoch 20/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9648 - tp: 1386.0000 - fp: 842.0000 - tn: 8086.0000 - fn: 3078.0000 - accuracy: 0.5374 - precision: 0.6221 - recall: 0.3105 - auc: 0.7217 - val_loss: 2.2826 - val_tp: 205.0000 - val_fp: 289.0000 - val_tn: 703.0000 - val_fn: 291.0000 - val_accuracy: 0.4153 - val_precision: 0.4150 - val_recall: 0.4133 - val_auc: 0.6067\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.26231\n",
      "Epoch 21/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9570 - tp: 1459.0000 - fp: 841.0000 - tn: 8087.0000 - fn: 3005.0000 - accuracy: 0.5455 - precision: 0.6343 - recall: 0.3268 - auc: 0.7271 - val_loss: 1.8664 - val_tp: 206.0000 - val_fp: 245.0000 - val_tn: 747.0000 - val_fn: 290.0000 - val_accuracy: 0.4556 - val_precision: 0.4568 - val_recall: 0.4153 - val_auc: 0.5900\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.26231\n",
      "Epoch 22/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9509 - tp: 1484.0000 - fp: 842.0000 - tn: 8086.0000 - fn: 2980.0000 - accuracy: 0.5488 - precision: 0.6380 - recall: 0.3324 - auc: 0.7309 - val_loss: 1.9791 - val_tp: 160.0000 - val_fp: 323.0000 - val_tn: 669.0000 - val_fn: 336.0000 - val_accuracy: 0.3286 - val_precision: 0.3313 - val_recall: 0.3226 - val_auc: 0.5243\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.26231\n",
      "Epoch 23/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9570 - tp: 1485.0000 - fp: 861.0000 - tn: 8067.0000 - fn: 2979.0000 - accuracy: 0.5381 - precision: 0.6330 - recall: 0.3327 - auc: 0.7241 - val_loss: 1.5683 - val_tp: 158.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 338.0000 - val_accuracy: 0.3508 - val_precision: 0.3649 - val_recall: 0.3185 - val_auc: 0.5337\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.26231\n",
      "Epoch 24/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9564 - tp: 1432.0000 - fp: 836.0000 - tn: 8092.0000 - fn: 3032.0000 - accuracy: 0.5441 - precision: 0.6314 - recall: 0.3208 - auc: 0.7257 - val_loss: 1.4043 - val_tp: 125.0000 - val_fp: 215.0000 - val_tn: 777.0000 - val_fn: 371.0000 - val_accuracy: 0.3609 - val_precision: 0.3676 - val_recall: 0.2520 - val_auc: 0.4942\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.26231\n",
      "Epoch 25/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9649 - tp: 1319.0000 - fp: 809.0000 - tn: 8119.0000 - fn: 3145.0000 - accuracy: 0.5374 - precision: 0.6198 - recall: 0.2955 - auc: 0.7198 - val_loss: 1.4338 - val_tp: 167.0000 - val_fp: 266.0000 - val_tn: 726.0000 - val_fn: 329.0000 - val_accuracy: 0.3730 - val_precision: 0.3857 - val_recall: 0.3367 - val_auc: 0.5369\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.26231\n",
      "Epoch 26/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9603 - tp: 1400.0000 - fp: 838.0000 - tn: 8090.0000 - fn: 3064.0000 - accuracy: 0.5477 - precision: 0.6256 - recall: 0.3136 - auc: 0.7248 - val_loss: 1.4031 - val_tp: 169.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 327.0000 - val_accuracy: 0.4093 - val_precision: 0.4112 - val_recall: 0.3407 - val_auc: 0.5828\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.26231\n",
      "Epoch 27/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9588 - tp: 1450.0000 - fp: 849.0000 - tn: 8079.0000 - fn: 3014.0000 - accuracy: 0.5522 - precision: 0.6307 - recall: 0.3248 - auc: 0.7286 - val_loss: 1.2069 - val_tp: 106.0000 - val_fp: 124.0000 - val_tn: 868.0000 - val_fn: 390.0000 - val_accuracy: 0.4315 - val_precision: 0.4609 - val_recall: 0.2137 - val_auc: 0.5816\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.26231 to 1.20694, saving model to model.hdf5\n",
      "Epoch 28/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9546 - tp: 1436.0000 - fp: 856.0000 - tn: 8072.0000 - fn: 3028.0000 - accuracy: 0.5444 - precision: 0.6265 - recall: 0.3217 - auc: 0.7279 - val_loss: 1.4094 - val_tp: 144.0000 - val_fp: 219.0000 - val_tn: 773.0000 - val_fn: 352.0000 - val_accuracy: 0.4012 - val_precision: 0.3967 - val_recall: 0.2903 - val_auc: 0.5657\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.20694\n",
      "Epoch 29/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9492 - tp: 1471.0000 - fp: 821.0000 - tn: 8107.0000 - fn: 2993.0000 - accuracy: 0.5477 - precision: 0.6418 - recall: 0.3295 - auc: 0.7332 - val_loss: 2.4949 - val_tp: 193.0000 - val_fp: 299.0000 - val_tn: 693.0000 - val_fn: 303.0000 - val_accuracy: 0.3911 - val_precision: 0.3923 - val_recall: 0.3891 - val_auc: 0.5913\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.20694\n",
      "Epoch 30/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9577 - tp: 1415.0000 - fp: 786.0000 - tn: 8142.0000 - fn: 3049.0000 - accuracy: 0.5455 - precision: 0.6429 - recall: 0.3170 - auc: 0.7269 - val_loss: 1.5489 - val_tp: 202.0000 - val_fp: 244.0000 - val_tn: 748.0000 - val_fn: 294.0000 - val_accuracy: 0.4456 - val_precision: 0.4529 - val_recall: 0.4073 - val_auc: 0.5949\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.20694\n",
      "Epoch 31/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9571 - tp: 1403.0000 - fp: 776.0000 - tn: 8152.0000 - fn: 3061.0000 - accuracy: 0.5468 - precision: 0.6439 - recall: 0.3143 - auc: 0.7254 - val_loss: 1.3517 - val_tp: 109.0000 - val_fp: 169.0000 - val_tn: 823.0000 - val_fn: 387.0000 - val_accuracy: 0.3730 - val_precision: 0.3921 - val_recall: 0.2198 - val_auc: 0.5222\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.20694\n",
      "Epoch 32/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9504 - tp: 1458.0000 - fp: 871.0000 - tn: 8057.0000 - fn: 3006.0000 - accuracy: 0.5511 - precision: 0.6260 - recall: 0.3266 - auc: 0.7309 - val_loss: 1.2563 - val_tp: 131.0000 - val_fp: 197.0000 - val_tn: 795.0000 - val_fn: 365.0000 - val_accuracy: 0.3750 - val_precision: 0.3994 - val_recall: 0.2641 - val_auc: 0.5371\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.20694\n",
      "Epoch 33/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9500 - tp: 1457.0000 - fp: 825.0000 - tn: 8103.0000 - fn: 3007.0000 - accuracy: 0.5506 - precision: 0.6385 - recall: 0.3264 - auc: 0.7307 - val_loss: 1.9178 - val_tp: 200.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 296.0000 - val_accuracy: 0.4315 - val_precision: 0.4274 - val_recall: 0.4032 - val_auc: 0.5946\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.20694\n",
      "Epoch 34/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9644 - tp: 1423.0000 - fp: 884.0000 - tn: 8044.0000 - fn: 3041.0000 - accuracy: 0.5388 - precision: 0.6168 - recall: 0.3188 - auc: 0.7199 - val_loss: 1.3511 - val_tp: 192.0000 - val_fp: 233.0000 - val_tn: 759.0000 - val_fn: 304.0000 - val_accuracy: 0.4597 - val_precision: 0.4518 - val_recall: 0.3871 - val_auc: 0.6210\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.20694\n",
      "Epoch 35/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9485 - tp: 1493.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 2971.0000 - accuracy: 0.5470 - precision: 0.6350 - recall: 0.3345 - auc: 0.7319 - val_loss: 1.7787 - val_tp: 183.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 313.0000 - val_accuracy: 0.3750 - val_precision: 0.3828 - val_recall: 0.3690 - val_auc: 0.5630\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.20694\n",
      "Epoch 36/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9506 - tp: 1483.0000 - fp: 848.0000 - tn: 8080.0000 - fn: 2981.0000 - accuracy: 0.5444 - precision: 0.6362 - recall: 0.3322 - auc: 0.7316 - val_loss: 1.5621 - val_tp: 162.0000 - val_fp: 287.0000 - val_tn: 705.0000 - val_fn: 334.0000 - val_accuracy: 0.3488 - val_precision: 0.3608 - val_recall: 0.3266 - val_auc: 0.5124\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.20694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9504 - tp: 1463.0000 - fp: 813.0000 - tn: 8115.0000 - fn: 3001.0000 - accuracy: 0.5497 - precision: 0.6428 - recall: 0.3277 - auc: 0.7299 - val_loss: 1.2523 - val_tp: 137.0000 - val_fp: 162.0000 - val_tn: 830.0000 - val_fn: 359.0000 - val_accuracy: 0.3992 - val_precision: 0.4582 - val_recall: 0.2762 - val_auc: 0.5723\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.20694\n",
      "Epoch 38/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9561 - tp: 1468.0000 - fp: 839.0000 - tn: 8089.0000 - fn: 2996.0000 - accuracy: 0.5497 - precision: 0.6363 - recall: 0.3289 - auc: 0.7298 - val_loss: 1.3967 - val_tp: 139.0000 - val_fp: 194.0000 - val_tn: 798.0000 - val_fn: 357.0000 - val_accuracy: 0.3931 - val_precision: 0.4174 - val_recall: 0.2802 - val_auc: 0.5611\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.20694\n",
      "Epoch 39/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9641 - tp: 1319.0000 - fp: 798.0000 - tn: 8130.0000 - fn: 3145.0000 - accuracy: 0.5336 - precision: 0.6231 - recall: 0.2955 - auc: 0.7219 - val_loss: 1.3024 - val_tp: 114.0000 - val_fp: 144.0000 - val_tn: 848.0000 - val_fn: 382.0000 - val_accuracy: 0.3911 - val_precision: 0.4419 - val_recall: 0.2298 - val_auc: 0.5694\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.20694\n",
      "Epoch 40/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9522 - tp: 1444.0000 - fp: 838.0000 - tn: 8090.0000 - fn: 3020.0000 - accuracy: 0.5466 - precision: 0.6328 - recall: 0.3235 - auc: 0.7291 - val_loss: 1.3314 - val_tp: 123.0000 - val_fp: 165.0000 - val_tn: 827.0000 - val_fn: 373.0000 - val_accuracy: 0.3810 - val_precision: 0.4271 - val_recall: 0.2480 - val_auc: 0.5637\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.20694\n",
      "Epoch 41/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9664 - tp: 1352.0000 - fp: 821.0000 - tn: 8107.0000 - fn: 3112.0000 - accuracy: 0.5311 - precision: 0.6222 - recall: 0.3029 - auc: 0.7181 - val_loss: 1.4533 - val_tp: 142.0000 - val_fp: 313.0000 - val_tn: 679.0000 - val_fn: 354.0000 - val_accuracy: 0.3306 - val_precision: 0.3121 - val_recall: 0.2863 - val_auc: 0.5133\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.20694\n",
      "Epoch 42/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9436 - tp: 1472.0000 - fp: 847.0000 - tn: 8081.0000 - fn: 2992.0000 - accuracy: 0.5531 - precision: 0.6348 - recall: 0.3297 - auc: 0.7338 - val_loss: 1.3914 - val_tp: 152.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 344.0000 - val_accuracy: 0.3649 - val_precision: 0.3628 - val_recall: 0.3065 - val_auc: 0.5333\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.20694\n",
      "Epoch 43/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9477 - tp: 1518.0000 - fp: 842.0000 - tn: 8086.0000 - fn: 2946.0000 - accuracy: 0.5464 - precision: 0.6432 - recall: 0.3401 - auc: 0.7332 - val_loss: 1.5565 - val_tp: 174.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 322.0000 - val_accuracy: 0.3851 - val_precision: 0.3973 - val_recall: 0.3508 - val_auc: 0.5588\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.20694\n",
      "Epoch 44/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9547 - tp: 1477.0000 - fp: 872.0000 - tn: 8056.0000 - fn: 2987.0000 - accuracy: 0.5479 - precision: 0.6288 - recall: 0.3309 - auc: 0.7287 - val_loss: 1.3385 - val_tp: 132.0000 - val_fp: 186.0000 - val_tn: 806.0000 - val_fn: 364.0000 - val_accuracy: 0.3931 - val_precision: 0.4151 - val_recall: 0.2661 - val_auc: 0.5664\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.20694\n",
      "Epoch 45/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9456 - tp: 1448.0000 - fp: 848.0000 - tn: 8080.0000 - fn: 3016.0000 - accuracy: 0.5484 - precision: 0.6307 - recall: 0.3244 - auc: 0.7325 - val_loss: 1.2179 - val_tp: 132.0000 - val_fp: 173.0000 - val_tn: 819.0000 - val_fn: 364.0000 - val_accuracy: 0.4254 - val_precision: 0.4328 - val_recall: 0.2661 - val_auc: 0.5737\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.20694\n",
      "Epoch 46/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9442 - tp: 1504.0000 - fp: 821.0000 - tn: 8107.0000 - fn: 2960.0000 - accuracy: 0.5540 - precision: 0.6469 - recall: 0.3369 - auc: 0.7357 - val_loss: 2.1229 - val_tp: 189.0000 - val_fp: 294.0000 - val_tn: 698.0000 - val_fn: 307.0000 - val_accuracy: 0.3972 - val_precision: 0.3913 - val_recall: 0.3810 - val_auc: 0.5661\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.20694\n",
      "Epoch 47/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9461 - tp: 1512.0000 - fp: 838.0000 - tn: 8090.0000 - fn: 2952.0000 - accuracy: 0.5587 - precision: 0.6434 - recall: 0.3387 - auc: 0.7371 - val_loss: 1.4838 - val_tp: 150.0000 - val_fp: 235.0000 - val_tn: 757.0000 - val_fn: 346.0000 - val_accuracy: 0.3669 - val_precision: 0.3896 - val_recall: 0.3024 - val_auc: 0.5475\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.20694\n",
      "Epoch 48/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9500 - tp: 1447.0000 - fp: 812.0000 - tn: 8116.0000 - fn: 3017.0000 - accuracy: 0.5506 - precision: 0.6405 - recall: 0.3241 - auc: 0.7324 - val_loss: 1.3175 - val_tp: 167.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 329.0000 - val_accuracy: 0.3871 - val_precision: 0.3986 - val_recall: 0.3367 - val_auc: 0.5687\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.20694\n",
      "Epoch 49/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9473 - tp: 1497.0000 - fp: 848.0000 - tn: 8080.0000 - fn: 2967.0000 - accuracy: 0.5500 - precision: 0.6384 - recall: 0.3353 - auc: 0.7333 - val_loss: 1.6686 - val_tp: 188.0000 - val_fp: 276.0000 - val_tn: 716.0000 - val_fn: 308.0000 - val_accuracy: 0.3972 - val_precision: 0.4052 - val_recall: 0.3790 - val_auc: 0.5677\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.20694\n",
      "Epoch 50/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9426 - tp: 1485.0000 - fp: 800.0000 - tn: 8128.0000 - fn: 2979.0000 - accuracy: 0.5526 - precision: 0.6499 - recall: 0.3327 - auc: 0.7337 - val_loss: 1.7409 - val_tp: 174.0000 - val_fp: 293.0000 - val_tn: 699.0000 - val_fn: 322.0000 - val_accuracy: 0.3629 - val_precision: 0.3726 - val_recall: 0.3508 - val_auc: 0.5574\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.20694\n",
      "Epoch 51/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9511 - tp: 1499.0000 - fp: 822.0000 - tn: 8106.0000 - fn: 2965.0000 - accuracy: 0.5502 - precision: 0.6458 - recall: 0.3358 - auc: 0.7332 - val_loss: 1.3562 - val_tp: 166.0000 - val_fp: 232.0000 - val_tn: 760.0000 - val_fn: 330.0000 - val_accuracy: 0.4194 - val_precision: 0.4171 - val_recall: 0.3347 - val_auc: 0.5784\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.20694\n",
      "Epoch 52/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9508 - tp: 1463.0000 - fp: 863.0000 - tn: 8065.0000 - fn: 3001.0000 - accuracy: 0.5464 - precision: 0.6290 - recall: 0.3277 - auc: 0.7303 - val_loss: 1.3897 - val_tp: 170.0000 - val_fp: 211.0000 - val_tn: 781.0000 - val_fn: 326.0000 - val_accuracy: 0.4173 - val_precision: 0.4462 - val_recall: 0.3427 - val_auc: 0.5919\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.20694\n",
      "Epoch 53/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9575 - tp: 1455.0000 - fp: 815.0000 - tn: 8113.0000 - fn: 3009.0000 - accuracy: 0.5426 - precision: 0.6410 - recall: 0.3259 - auc: 0.7269 - val_loss: 2.0705 - val_tp: 185.0000 - val_fp: 302.0000 - val_tn: 690.0000 - val_fn: 311.0000 - val_accuracy: 0.3871 - val_precision: 0.3799 - val_recall: 0.3730 - val_auc: 0.5770\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.20694\n",
      "Epoch 54/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9427 - tp: 1507.0000 - fp: 830.0000 - tn: 8098.0000 - fn: 2957.0000 - accuracy: 0.5488 - precision: 0.6448 - recall: 0.3376 - auc: 0.7365 - val_loss: 2.0289 - val_tp: 190.0000 - val_fp: 301.0000 - val_tn: 691.0000 - val_fn: 306.0000 - val_accuracy: 0.3851 - val_precision: 0.3870 - val_recall: 0.3831 - val_auc: 0.5679\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.20694\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9392 - tp: 1502.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 2962.0000 - accuracy: 0.5553 - precision: 0.6364 - recall: 0.3365 - auc: 0.7380 - val_loss: 1.3833 - val_tp: 171.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 325.0000 - val_accuracy: 0.3992 - val_precision: 0.4201 - val_recall: 0.3448 - val_auc: 0.5696\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.20694\n",
      "Epoch 56/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9374 - tp: 1538.0000 - fp: 815.0000 - tn: 8113.0000 - fn: 2926.0000 - accuracy: 0.5526 - precision: 0.6536 - recall: 0.3445 - auc: 0.7412 - val_loss: 1.2069 - val_tp: 125.0000 - val_fp: 144.0000 - val_tn: 848.0000 - val_fn: 371.0000 - val_accuracy: 0.4133 - val_precision: 0.4647 - val_recall: 0.2520 - val_auc: 0.5891\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.20694 to 1.20685, saving model to model.hdf5\n",
      "Epoch 57/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9416 - tp: 1517.0000 - fp: 852.0000 - tn: 8076.0000 - fn: 2947.0000 - accuracy: 0.5605 - precision: 0.6404 - recall: 0.3398 - auc: 0.7381 - val_loss: 1.3658 - val_tp: 136.0000 - val_fp: 197.0000 - val_tn: 795.0000 - val_fn: 360.0000 - val_accuracy: 0.3952 - val_precision: 0.4084 - val_recall: 0.2742 - val_auc: 0.5680\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.20685\n",
      "Epoch 58/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9433 - tp: 1519.0000 - fp: 836.0000 - tn: 8092.0000 - fn: 2945.0000 - accuracy: 0.5529 - precision: 0.6450 - recall: 0.3403 - auc: 0.7353 - val_loss: 1.5942 - val_tp: 184.0000 - val_fp: 232.0000 - val_tn: 760.0000 - val_fn: 312.0000 - val_accuracy: 0.4415 - val_precision: 0.4423 - val_recall: 0.3710 - val_auc: 0.5962\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.20685\n",
      "Epoch 59/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9464 - tp: 1469.0000 - fp: 852.0000 - tn: 8076.0000 - fn: 2995.0000 - accuracy: 0.5444 - precision: 0.6329 - recall: 0.3291 - auc: 0.7312 - val_loss: 1.3658 - val_tp: 187.0000 - val_fp: 237.0000 - val_tn: 755.0000 - val_fn: 309.0000 - val_accuracy: 0.4294 - val_precision: 0.4410 - val_recall: 0.3770 - val_auc: 0.5944\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.20685\n",
      "Epoch 60/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9430 - tp: 1460.0000 - fp: 815.0000 - tn: 8113.0000 - fn: 3004.0000 - accuracy: 0.5560 - precision: 0.6418 - recall: 0.3271 - auc: 0.7372 - val_loss: 1.3003 - val_tp: 115.0000 - val_fp: 152.0000 - val_tn: 840.0000 - val_fn: 381.0000 - val_accuracy: 0.4173 - val_precision: 0.4307 - val_recall: 0.2319 - val_auc: 0.5734\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.20685\n",
      "Epoch 61/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9409 - tp: 1541.0000 - fp: 834.0000 - tn: 8094.0000 - fn: 2923.0000 - accuracy: 0.5531 - precision: 0.6488 - recall: 0.3452 - auc: 0.7376 - val_loss: 1.3055 - val_tp: 158.0000 - val_fp: 237.0000 - val_tn: 755.0000 - val_fn: 338.0000 - val_accuracy: 0.3952 - val_precision: 0.4000 - val_recall: 0.3185 - val_auc: 0.5674\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.20685\n",
      "Epoch 62/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9313 - tp: 1521.0000 - fp: 808.0000 - tn: 8120.0000 - fn: 2943.0000 - accuracy: 0.5578 - precision: 0.6531 - recall: 0.3407 - auc: 0.7430 - val_loss: 1.2798 - val_tp: 103.0000 - val_fp: 146.0000 - val_tn: 846.0000 - val_fn: 393.0000 - val_accuracy: 0.3730 - val_precision: 0.4137 - val_recall: 0.2077 - val_auc: 0.5589\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.20685\n",
      "Epoch 63/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9376 - tp: 1561.0000 - fp: 840.0000 - tn: 8088.0000 - fn: 2903.0000 - accuracy: 0.5556 - precision: 0.6501 - recall: 0.3497 - auc: 0.7395 - val_loss: 1.2507 - val_tp: 121.0000 - val_fp: 155.0000 - val_tn: 837.0000 - val_fn: 375.0000 - val_accuracy: 0.3992 - val_precision: 0.4384 - val_recall: 0.2440 - val_auc: 0.5714\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.20685\n",
      "Epoch 64/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9393 - tp: 1538.0000 - fp: 873.0000 - tn: 8055.0000 - fn: 2926.0000 - accuracy: 0.5573 - precision: 0.6379 - recall: 0.3445 - auc: 0.7398 - val_loss: 1.3559 - val_tp: 150.0000 - val_fp: 213.0000 - val_tn: 779.0000 - val_fn: 346.0000 - val_accuracy: 0.3871 - val_precision: 0.4132 - val_recall: 0.3024 - val_auc: 0.5511\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.20685\n",
      "Epoch 65/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9433 - tp: 1537.0000 - fp: 860.0000 - tn: 8068.0000 - fn: 2927.0000 - accuracy: 0.5493 - precision: 0.6412 - recall: 0.3443 - auc: 0.7370 - val_loss: 1.4631 - val_tp: 164.0000 - val_fp: 215.0000 - val_tn: 777.0000 - val_fn: 332.0000 - val_accuracy: 0.4133 - val_precision: 0.4327 - val_recall: 0.3306 - val_auc: 0.5820\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.20685\n",
      "Epoch 66/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9368 - tp: 1586.0000 - fp: 838.0000 - tn: 8090.0000 - fn: 2878.0000 - accuracy: 0.5663 - precision: 0.6543 - recall: 0.3553 - auc: 0.7435 - val_loss: 1.8850 - val_tp: 189.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 307.0000 - val_accuracy: 0.4173 - val_precision: 0.4127 - val_recall: 0.3810 - val_auc: 0.5827\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.20685\n",
      "Epoch 67/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9454 - tp: 1477.0000 - fp: 889.0000 - tn: 8039.0000 - fn: 2987.0000 - accuracy: 0.5482 - precision: 0.6243 - recall: 0.3309 - auc: 0.7334 - val_loss: 2.9489 - val_tp: 154.0000 - val_fp: 338.0000 - val_tn: 654.0000 - val_fn: 342.0000 - val_accuracy: 0.3125 - val_precision: 0.3130 - val_recall: 0.3105 - val_auc: 0.5030\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.20685\n",
      "Epoch 68/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9415 - tp: 1511.0000 - fp: 804.0000 - tn: 8124.0000 - fn: 2953.0000 - accuracy: 0.5526 - precision: 0.6527 - recall: 0.3385 - auc: 0.7369 - val_loss: 1.7834 - val_tp: 179.0000 - val_fp: 293.0000 - val_tn: 699.0000 - val_fn: 317.0000 - val_accuracy: 0.3690 - val_precision: 0.3792 - val_recall: 0.3609 - val_auc: 0.5577\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.20685\n",
      "Epoch 69/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9337 - tp: 1580.0000 - fp: 865.0000 - tn: 8063.0000 - fn: 2884.0000 - accuracy: 0.5580 - precision: 0.6462 - recall: 0.3539 - auc: 0.7418 - val_loss: 1.5507 - val_tp: 156.0000 - val_fp: 239.0000 - val_tn: 753.0000 - val_fn: 340.0000 - val_accuracy: 0.3750 - val_precision: 0.3949 - val_recall: 0.3145 - val_auc: 0.5440\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.20685\n",
      "Epoch 70/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9503 - tp: 1473.0000 - fp: 843.0000 - tn: 8085.0000 - fn: 2991.0000 - accuracy: 0.5515 - precision: 0.6360 - recall: 0.3300 - auc: 0.7327 - val_loss: 2.7563 - val_tp: 210.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 286.0000 - val_accuracy: 0.4315 - val_precision: 0.4286 - val_recall: 0.4234 - val_auc: 0.6046\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.20685\n",
      "Epoch 71/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9444 - tp: 1537.0000 - fp: 815.0000 - tn: 8113.0000 - fn: 2927.0000 - accuracy: 0.5493 - precision: 0.6535 - recall: 0.3443 - auc: 0.7362 - val_loss: 1.7116 - val_tp: 163.0000 - val_fp: 313.0000 - val_tn: 679.0000 - val_fn: 333.0000 - val_accuracy: 0.3427 - val_precision: 0.3424 - val_recall: 0.3286 - val_auc: 0.5209\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.20685\n",
      "Epoch 72/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9379 - tp: 1559.0000 - fp: 837.0000 - tn: 8091.0000 - fn: 2905.0000 - accuracy: 0.5582 - precision: 0.6507 - recall: 0.3492 - auc: 0.7401 - val_loss: 1.8482 - val_tp: 216.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 280.0000 - val_accuracy: 0.4456 - val_precision: 0.4454 - val_recall: 0.4355 - val_auc: 0.5973\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.20685\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9452 - tp: 1506.0000 - fp: 845.0000 - tn: 8083.0000 - fn: 2958.0000 - accuracy: 0.5437 - precision: 0.6406 - recall: 0.3374 - auc: 0.7340 - val_loss: 1.9692 - val_tp: 160.0000 - val_fp: 322.0000 - val_tn: 670.0000 - val_fn: 336.0000 - val_accuracy: 0.3306 - val_precision: 0.3320 - val_recall: 0.3226 - val_auc: 0.5319\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.20685\n",
      "Epoch 74/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9349 - tp: 1538.0000 - fp: 766.0000 - tn: 8162.0000 - fn: 2926.0000 - accuracy: 0.5616 - precision: 0.6675 - recall: 0.3445 - auc: 0.7441 - val_loss: 1.3243 - val_tp: 110.0000 - val_fp: 159.0000 - val_tn: 833.0000 - val_fn: 386.0000 - val_accuracy: 0.3730 - val_precision: 0.4089 - val_recall: 0.2218 - val_auc: 0.5390\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.20685\n",
      "Epoch 75/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.9401 - tp: 1561.0000 - fp: 847.0000 - tn: 8081.0000 - fn: 2903.0000 - accuracy: 0.5600 - precision: 0.6483 - recall: 0.3497 - auc: 0.7391 - val_loss: 1.6504 - val_tp: 186.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 310.0000 - val_accuracy: 0.3992 - val_precision: 0.3991 - val_recall: 0.3750 - val_auc: 0.5625\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.20685\n",
      "Epoch 76/500\n",
      "4464/4464 [==============================] - 0s 79us/step - loss: 0.9485 - tp: 1451.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 3013.0000 - accuracy: 0.5484 - precision: 0.6284 - recall: 0.3250 - auc: 0.7318 - val_loss: 1.8522 - val_tp: 233.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 263.0000 - val_accuracy: 0.4758 - val_precision: 0.4794 - val_recall: 0.4698 - val_auc: 0.6101\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.20685\n",
      "Epoch 77/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9377 - tp: 1542.0000 - fp: 792.0000 - tn: 8136.0000 - fn: 2922.0000 - accuracy: 0.5585 - precision: 0.6607 - recall: 0.3454 - auc: 0.7417 - val_loss: 1.5664 - val_tp: 162.0000 - val_fp: 302.0000 - val_tn: 690.0000 - val_fn: 334.0000 - val_accuracy: 0.3387 - val_precision: 0.3491 - val_recall: 0.3266 - val_auc: 0.5345\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.20685\n",
      "Epoch 78/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9404 - tp: 1547.0000 - fp: 872.0000 - tn: 8056.0000 - fn: 2917.0000 - accuracy: 0.5466 - precision: 0.6395 - recall: 0.3466 - auc: 0.7371 - val_loss: 1.5435 - val_tp: 178.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 318.0000 - val_accuracy: 0.4133 - val_precision: 0.4279 - val_recall: 0.3589 - val_auc: 0.5695\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.20685\n",
      "Epoch 79/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9382 - tp: 1559.0000 - fp: 855.0000 - tn: 8073.0000 - fn: 2905.0000 - accuracy: 0.5549 - precision: 0.6458 - recall: 0.3492 - auc: 0.7383 - val_loss: 1.4239 - val_tp: 147.0000 - val_fp: 209.0000 - val_tn: 783.0000 - val_fn: 349.0000 - val_accuracy: 0.3931 - val_precision: 0.4129 - val_recall: 0.2964 - val_auc: 0.5647\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.20685\n",
      "Epoch 80/500\n",
      "4464/4464 [==============================] - 0s 78us/step - loss: 0.9415 - tp: 1486.0000 - fp: 861.0000 - tn: 8067.0000 - fn: 2978.0000 - accuracy: 0.5488 - precision: 0.6331 - recall: 0.3329 - auc: 0.7361 - val_loss: 1.4399 - val_tp: 168.0000 - val_fp: 286.0000 - val_tn: 706.0000 - val_fn: 328.0000 - val_accuracy: 0.3649 - val_precision: 0.3700 - val_recall: 0.3387 - val_auc: 0.5372\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.20685\n",
      "Epoch 81/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9365 - tp: 1603.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 2861.0000 - accuracy: 0.5634 - precision: 0.6514 - recall: 0.3591 - auc: 0.7420 - val_loss: 1.6410 - val_tp: 190.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 306.0000 - val_accuracy: 0.4194 - val_precision: 0.4299 - val_recall: 0.3831 - val_auc: 0.5683\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.20685\n",
      "Epoch 82/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9359 - tp: 1571.0000 - fp: 817.0000 - tn: 8111.0000 - fn: 2893.0000 - accuracy: 0.5576 - precision: 0.6579 - recall: 0.3519 - auc: 0.7438 - val_loss: 1.4441 - val_tp: 138.0000 - val_fp: 206.0000 - val_tn: 786.0000 - val_fn: 358.0000 - val_accuracy: 0.3649 - val_precision: 0.4012 - val_recall: 0.2782 - val_auc: 0.5506\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.20685\n",
      "Epoch 83/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9418 - tp: 1521.0000 - fp: 854.0000 - tn: 8074.0000 - fn: 2943.0000 - accuracy: 0.5549 - precision: 0.6404 - recall: 0.3407 - auc: 0.7382 - val_loss: 1.4730 - val_tp: 163.0000 - val_fp: 283.0000 - val_tn: 709.0000 - val_fn: 333.0000 - val_accuracy: 0.3710 - val_precision: 0.3655 - val_recall: 0.3286 - val_auc: 0.5625\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.20685\n",
      "Epoch 84/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9275 - tp: 1618.0000 - fp: 902.0000 - tn: 8026.0000 - fn: 2846.0000 - accuracy: 0.5703 - precision: 0.6421 - recall: 0.3625 - auc: 0.7469 - val_loss: 1.3240 - val_tp: 157.0000 - val_fp: 201.0000 - val_tn: 791.0000 - val_fn: 339.0000 - val_accuracy: 0.4214 - val_precision: 0.4385 - val_recall: 0.3165 - val_auc: 0.5891\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.20685\n",
      "Epoch 85/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9372 - tp: 1588.0000 - fp: 872.0000 - tn: 8056.0000 - fn: 2876.0000 - accuracy: 0.5636 - precision: 0.6455 - recall: 0.3557 - auc: 0.7426 - val_loss: 1.4678 - val_tp: 111.0000 - val_fp: 210.0000 - val_tn: 782.0000 - val_fn: 385.0000 - val_accuracy: 0.3387 - val_precision: 0.3458 - val_recall: 0.2238 - val_auc: 0.4993\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.20685\n",
      "Epoch 86/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9369 - tp: 1562.0000 - fp: 850.0000 - tn: 8078.0000 - fn: 2902.0000 - accuracy: 0.5571 - precision: 0.6476 - recall: 0.3499 - auc: 0.7410 - val_loss: 1.6442 - val_tp: 156.0000 - val_fp: 310.0000 - val_tn: 682.0000 - val_fn: 340.0000 - val_accuracy: 0.3327 - val_precision: 0.3348 - val_recall: 0.3145 - val_auc: 0.5291\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.20685\n",
      "Epoch 87/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9352 - tp: 1543.0000 - fp: 826.0000 - tn: 8102.0000 - fn: 2921.0000 - accuracy: 0.5567 - precision: 0.6513 - recall: 0.3457 - auc: 0.7413 - val_loss: 1.4310 - val_tp: 128.0000 - val_fp: 192.0000 - val_tn: 800.0000 - val_fn: 368.0000 - val_accuracy: 0.3770 - val_precision: 0.4000 - val_recall: 0.2581 - val_auc: 0.5579\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.20685\n",
      "Epoch 88/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9241 - tp: 1607.0000 - fp: 809.0000 - tn: 8119.0000 - fn: 2857.0000 - accuracy: 0.5710 - precision: 0.6651 - recall: 0.3600 - auc: 0.7495 - val_loss: 1.5702 - val_tp: 177.0000 - val_fp: 220.0000 - val_tn: 772.0000 - val_fn: 319.0000 - val_accuracy: 0.4294 - val_precision: 0.4458 - val_recall: 0.3569 - val_auc: 0.5749\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.20685\n",
      "Epoch 89/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9262 - tp: 1621.0000 - fp: 854.0000 - tn: 8074.0000 - fn: 2843.0000 - accuracy: 0.5647 - precision: 0.6549 - recall: 0.3631 - auc: 0.7487 - val_loss: 1.8035 - val_tp: 183.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 313.0000 - val_accuracy: 0.3790 - val_precision: 0.3828 - val_recall: 0.3690 - val_auc: 0.5669\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.20685\n",
      "Epoch 90/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9285 - tp: 1587.0000 - fp: 851.0000 - tn: 8077.0000 - fn: 2877.0000 - accuracy: 0.5621 - precision: 0.6509 - recall: 0.3555 - auc: 0.7483 - val_loss: 2.2523 - val_tp: 155.0000 - val_fp: 334.0000 - val_tn: 658.0000 - val_fn: 341.0000 - val_accuracy: 0.3165 - val_precision: 0.3170 - val_recall: 0.3125 - val_auc: 0.5390\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.20685\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9335 - tp: 1576.0000 - fp: 819.0000 - tn: 8109.0000 - fn: 2888.0000 - accuracy: 0.5627 - precision: 0.6580 - recall: 0.3530 - auc: 0.7444 - val_loss: 1.3098 - val_tp: 145.0000 - val_fp: 171.0000 - val_tn: 821.0000 - val_fn: 351.0000 - val_accuracy: 0.4214 - val_precision: 0.4589 - val_recall: 0.2923 - val_auc: 0.5864\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.20685\n",
      "Epoch 92/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9262 - tp: 1639.0000 - fp: 879.0000 - tn: 8049.0000 - fn: 2825.0000 - accuracy: 0.5656 - precision: 0.6509 - recall: 0.3672 - auc: 0.7477 - val_loss: 1.2885 - val_tp: 185.0000 - val_fp: 218.0000 - val_tn: 774.0000 - val_fn: 311.0000 - val_accuracy: 0.4435 - val_precision: 0.4591 - val_recall: 0.3730 - val_auc: 0.6081\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.20685\n",
      "Epoch 93/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9349 - tp: 1535.0000 - fp: 849.0000 - tn: 8079.0000 - fn: 2929.0000 - accuracy: 0.5585 - precision: 0.6439 - recall: 0.3439 - auc: 0.7426 - val_loss: 1.5771 - val_tp: 166.0000 - val_fp: 239.0000 - val_tn: 753.0000 - val_fn: 330.0000 - val_accuracy: 0.4113 - val_precision: 0.4099 - val_recall: 0.3347 - val_auc: 0.5519\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.20685\n",
      "Epoch 94/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9293 - tp: 1668.0000 - fp: 894.0000 - tn: 8034.0000 - fn: 2796.0000 - accuracy: 0.5677 - precision: 0.6511 - recall: 0.3737 - auc: 0.7473 - val_loss: 2.0557 - val_tp: 236.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 260.0000 - val_accuracy: 0.4859 - val_precision: 0.4826 - val_recall: 0.4758 - val_auc: 0.6181\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.20685\n",
      "Epoch 95/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9381 - tp: 1583.0000 - fp: 875.0000 - tn: 8053.0000 - fn: 2881.0000 - accuracy: 0.5542 - precision: 0.6440 - recall: 0.3546 - auc: 0.7388 - val_loss: 1.3966 - val_tp: 182.0000 - val_fp: 210.0000 - val_tn: 782.0000 - val_fn: 314.0000 - val_accuracy: 0.4315 - val_precision: 0.4643 - val_recall: 0.3669 - val_auc: 0.6030\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.20685\n",
      "Epoch 96/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9301 - tp: 1621.0000 - fp: 856.0000 - tn: 8072.0000 - fn: 2843.0000 - accuracy: 0.5600 - precision: 0.6544 - recall: 0.3631 - auc: 0.7464 - val_loss: 1.5849 - val_tp: 151.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 345.0000 - val_accuracy: 0.3952 - val_precision: 0.3882 - val_recall: 0.3044 - val_auc: 0.5484\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.20685\n",
      "Epoch 97/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9262 - tp: 1630.0000 - fp: 861.0000 - tn: 8067.0000 - fn: 2834.0000 - accuracy: 0.5607 - precision: 0.6544 - recall: 0.3651 - auc: 0.7480 - val_loss: 1.9074 - val_tp: 213.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 283.0000 - val_accuracy: 0.4516 - val_precision: 0.4600 - val_recall: 0.4294 - val_auc: 0.6105\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.20685\n",
      "Epoch 98/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9212 - tp: 1657.0000 - fp: 832.0000 - tn: 8096.0000 - fn: 2807.0000 - accuracy: 0.5768 - precision: 0.6657 - recall: 0.3712 - auc: 0.7538 - val_loss: 2.0878 - val_tp: 160.0000 - val_fp: 325.0000 - val_tn: 667.0000 - val_fn: 336.0000 - val_accuracy: 0.3266 - val_precision: 0.3299 - val_recall: 0.3226 - val_auc: 0.5217\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.20685\n",
      "Epoch 99/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9285 - tp: 1601.0000 - fp: 819.0000 - tn: 8109.0000 - fn: 2863.0000 - accuracy: 0.5719 - precision: 0.6616 - recall: 0.3586 - auc: 0.7498 - val_loss: 1.4413 - val_tp: 175.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 321.0000 - val_accuracy: 0.4133 - val_precision: 0.4237 - val_recall: 0.3528 - val_auc: 0.5633\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.20685\n",
      "Epoch 100/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9333 - tp: 1568.0000 - fp: 824.0000 - tn: 8104.0000 - fn: 2896.0000 - accuracy: 0.5591 - precision: 0.6555 - recall: 0.3513 - auc: 0.7433 - val_loss: 1.3716 - val_tp: 133.0000 - val_fp: 176.0000 - val_tn: 816.0000 - val_fn: 363.0000 - val_accuracy: 0.4415 - val_precision: 0.4304 - val_recall: 0.2681 - val_auc: 0.5784\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.20685\n",
      "Epoch 101/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9404 - tp: 1554.0000 - fp: 866.0000 - tn: 8062.0000 - fn: 2910.0000 - accuracy: 0.5526 - precision: 0.6421 - recall: 0.3481 - auc: 0.7373 - val_loss: 1.5806 - val_tp: 179.0000 - val_fp: 241.0000 - val_tn: 751.0000 - val_fn: 317.0000 - val_accuracy: 0.4052 - val_precision: 0.4262 - val_recall: 0.3609 - val_auc: 0.5486\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.20685\n",
      "Epoch 102/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9284 - tp: 1582.0000 - fp: 861.0000 - tn: 8067.0000 - fn: 2882.0000 - accuracy: 0.5634 - precision: 0.6476 - recall: 0.3544 - auc: 0.7467 - val_loss: 1.8738 - val_tp: 184.0000 - val_fp: 290.0000 - val_tn: 702.0000 - val_fn: 312.0000 - val_accuracy: 0.3891 - val_precision: 0.3882 - val_recall: 0.3710 - val_auc: 0.5673\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.20685\n",
      "Epoch 103/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9309 - tp: 1602.0000 - fp: 864.0000 - tn: 8064.0000 - fn: 2862.0000 - accuracy: 0.5672 - precision: 0.6496 - recall: 0.3589 - auc: 0.7446 - val_loss: 1.6400 - val_tp: 177.0000 - val_fp: 290.0000 - val_tn: 702.0000 - val_fn: 319.0000 - val_accuracy: 0.3770 - val_precision: 0.3790 - val_recall: 0.3569 - val_auc: 0.5735\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.20685\n",
      "Epoch 104/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9322 - tp: 1600.0000 - fp: 875.0000 - tn: 8053.0000 - fn: 2864.0000 - accuracy: 0.5540 - precision: 0.6465 - recall: 0.3584 - auc: 0.7437 - val_loss: 1.6336 - val_tp: 201.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 295.0000 - val_accuracy: 0.4153 - val_precision: 0.4258 - val_recall: 0.4052 - val_auc: 0.5879\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.20685\n",
      "Epoch 105/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9326 - tp: 1588.0000 - fp: 822.0000 - tn: 8106.0000 - fn: 2876.0000 - accuracy: 0.5587 - precision: 0.6589 - recall: 0.3557 - auc: 0.7417 - val_loss: 1.7147 - val_tp: 211.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 285.0000 - val_accuracy: 0.4395 - val_precision: 0.4617 - val_recall: 0.4254 - val_auc: 0.6117\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.20685\n",
      "Epoch 106/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9305 - tp: 1526.0000 - fp: 834.0000 - tn: 8094.0000 - fn: 2938.0000 - accuracy: 0.5497 - precision: 0.6466 - recall: 0.3418 - auc: 0.7437 - val_loss: 1.7570 - val_tp: 204.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 292.0000 - val_accuracy: 0.4254 - val_precision: 0.4232 - val_recall: 0.4113 - val_auc: 0.5948\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.20685\n",
      "Epoch 107/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9491 - tp: 1505.0000 - fp: 900.0000 - tn: 8028.0000 - fn: 2959.0000 - accuracy: 0.5435 - precision: 0.6258 - recall: 0.3371 - auc: 0.7297 - val_loss: 1.3381 - val_tp: 116.0000 - val_fp: 189.0000 - val_tn: 803.0000 - val_fn: 380.0000 - val_accuracy: 0.3690 - val_precision: 0.3803 - val_recall: 0.2339 - val_auc: 0.5412\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.20685\n",
      "Epoch 108/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9349 - tp: 1528.0000 - fp: 822.0000 - tn: 8106.0000 - fn: 2936.0000 - accuracy: 0.5569 - precision: 0.6502 - recall: 0.3423 - auc: 0.7403 - val_loss: 1.2656 - val_tp: 135.0000 - val_fp: 151.0000 - val_tn: 841.0000 - val_fn: 361.0000 - val_accuracy: 0.4294 - val_precision: 0.4720 - val_recall: 0.2722 - val_auc: 0.5844\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.20685\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9189 - tp: 1663.0000 - fp: 923.0000 - tn: 8005.0000 - fn: 2801.0000 - accuracy: 0.5694 - precision: 0.6431 - recall: 0.3725 - auc: 0.7522 - val_loss: 1.5869 - val_tp: 173.0000 - val_fp: 284.0000 - val_tn: 708.0000 - val_fn: 323.0000 - val_accuracy: 0.3690 - val_precision: 0.3786 - val_recall: 0.3488 - val_auc: 0.5649\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.20685\n",
      "Epoch 110/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9307 - tp: 1626.0000 - fp: 888.0000 - tn: 8040.0000 - fn: 2838.0000 - accuracy: 0.5553 - precision: 0.6468 - recall: 0.3642 - auc: 0.7463 - val_loss: 1.2511 - val_tp: 100.0000 - val_fp: 129.0000 - val_tn: 863.0000 - val_fn: 396.0000 - val_accuracy: 0.3992 - val_precision: 0.4367 - val_recall: 0.2016 - val_auc: 0.5659\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.20685\n",
      "Epoch 111/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9342 - tp: 1580.0000 - fp: 885.0000 - tn: 8043.0000 - fn: 2884.0000 - accuracy: 0.5542 - precision: 0.6410 - recall: 0.3539 - auc: 0.7421 - val_loss: 1.3901 - val_tp: 142.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 354.0000 - val_accuracy: 0.3629 - val_precision: 0.3595 - val_recall: 0.2863 - val_auc: 0.5311\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.20685\n",
      "Epoch 112/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9199 - tp: 1605.0000 - fp: 837.0000 - tn: 8091.0000 - fn: 2859.0000 - accuracy: 0.5647 - precision: 0.6572 - recall: 0.3595 - auc: 0.7524 - val_loss: 1.5594 - val_tp: 195.0000 - val_fp: 233.0000 - val_tn: 759.0000 - val_fn: 301.0000 - val_accuracy: 0.4415 - val_precision: 0.4556 - val_recall: 0.3931 - val_auc: 0.6077\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.20685\n",
      "Epoch 113/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9271 - tp: 1595.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 2869.0000 - accuracy: 0.5641 - precision: 0.6502 - recall: 0.3573 - auc: 0.7471 - val_loss: 2.1685 - val_tp: 159.0000 - val_fp: 331.0000 - val_tn: 661.0000 - val_fn: 337.0000 - val_accuracy: 0.3206 - val_precision: 0.3245 - val_recall: 0.3206 - val_auc: 0.5374\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.20685\n",
      "Epoch 114/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9304 - tp: 1588.0000 - fp: 856.0000 - tn: 8072.0000 - fn: 2876.0000 - accuracy: 0.5591 - precision: 0.6498 - recall: 0.3557 - auc: 0.7439 - val_loss: 1.6567 - val_tp: 182.0000 - val_fp: 293.0000 - val_tn: 699.0000 - val_fn: 314.0000 - val_accuracy: 0.3810 - val_precision: 0.3832 - val_recall: 0.3669 - val_auc: 0.5779\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.20685\n",
      "Epoch 115/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9125 - tp: 1682.0000 - fp: 875.0000 - tn: 8053.0000 - fn: 2782.0000 - accuracy: 0.5706 - precision: 0.6578 - recall: 0.3768 - auc: 0.7563 - val_loss: 1.4912 - val_tp: 148.0000 - val_fp: 219.0000 - val_tn: 773.0000 - val_fn: 348.0000 - val_accuracy: 0.4032 - val_precision: 0.4033 - val_recall: 0.2984 - val_auc: 0.5580\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.20685\n",
      "Epoch 116/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9103 - tp: 1698.0000 - fp: 864.0000 - tn: 8064.0000 - fn: 2766.0000 - accuracy: 0.5677 - precision: 0.6628 - recall: 0.3804 - auc: 0.7579 - val_loss: 1.7654 - val_tp: 182.0000 - val_fp: 292.0000 - val_tn: 700.0000 - val_fn: 314.0000 - val_accuracy: 0.3770 - val_precision: 0.3840 - val_recall: 0.3669 - val_auc: 0.5568\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.20685\n",
      "Epoch 117/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9201 - tp: 1670.0000 - fp: 898.0000 - tn: 8030.0000 - fn: 2794.0000 - accuracy: 0.5663 - precision: 0.6503 - recall: 0.3741 - auc: 0.7527 - val_loss: 1.4140 - val_tp: 176.0000 - val_fp: 211.0000 - val_tn: 781.0000 - val_fn: 320.0000 - val_accuracy: 0.4234 - val_precision: 0.4548 - val_recall: 0.3548 - val_auc: 0.5715\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.20685\n",
      "Epoch 118/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9177 - tp: 1686.0000 - fp: 843.0000 - tn: 8085.0000 - fn: 2778.0000 - accuracy: 0.5694 - precision: 0.6667 - recall: 0.3777 - auc: 0.7534 - val_loss: 1.3339 - val_tp: 124.0000 - val_fp: 159.0000 - val_tn: 833.0000 - val_fn: 372.0000 - val_accuracy: 0.4274 - val_precision: 0.4382 - val_recall: 0.2500 - val_auc: 0.5717\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.20685\n",
      "Epoch 119/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9196 - tp: 1655.0000 - fp: 874.0000 - tn: 8054.0000 - fn: 2809.0000 - accuracy: 0.5677 - precision: 0.6544 - recall: 0.3707 - auc: 0.7528 - val_loss: 1.3250 - val_tp: 176.0000 - val_fp: 191.0000 - val_tn: 801.0000 - val_fn: 320.0000 - val_accuracy: 0.4657 - val_precision: 0.4796 - val_recall: 0.3548 - val_auc: 0.6091\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.20685\n",
      "Epoch 120/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9292 - tp: 1647.0000 - fp: 846.0000 - tn: 8082.0000 - fn: 2817.0000 - accuracy: 0.5712 - precision: 0.6606 - recall: 0.3690 - auc: 0.7504 - val_loss: 1.7140 - val_tp: 182.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 314.0000 - val_accuracy: 0.3810 - val_precision: 0.3816 - val_recall: 0.3669 - val_auc: 0.5759\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.20685\n",
      "Epoch 121/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9427 - tp: 1535.0000 - fp: 885.0000 - tn: 8043.0000 - fn: 2929.0000 - accuracy: 0.5506 - precision: 0.6343 - recall: 0.3439 - auc: 0.7354 - val_loss: 1.4802 - val_tp: 191.0000 - val_fp: 221.0000 - val_tn: 771.0000 - val_fn: 305.0000 - val_accuracy: 0.4456 - val_precision: 0.4636 - val_recall: 0.3851 - val_auc: 0.6239\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.20685\n",
      "Epoch 122/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9261 - tp: 1626.0000 - fp: 857.0000 - tn: 8071.0000 - fn: 2838.0000 - accuracy: 0.5647 - precision: 0.6549 - recall: 0.3642 - auc: 0.7484 - val_loss: 1.6412 - val_tp: 189.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 307.0000 - val_accuracy: 0.4214 - val_precision: 0.4375 - val_recall: 0.3810 - val_auc: 0.5810\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.20685\n",
      "Epoch 123/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9253 - tp: 1630.0000 - fp: 861.0000 - tn: 8067.0000 - fn: 2834.0000 - accuracy: 0.5582 - precision: 0.6544 - recall: 0.3651 - auc: 0.7481 - val_loss: 1.3751 - val_tp: 164.0000 - val_fp: 241.0000 - val_tn: 751.0000 - val_fn: 332.0000 - val_accuracy: 0.4052 - val_precision: 0.4049 - val_recall: 0.3306 - val_auc: 0.5570\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.20685\n",
      "Epoch 124/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9273 - tp: 1610.0000 - fp: 901.0000 - tn: 8027.0000 - fn: 2854.0000 - accuracy: 0.5636 - precision: 0.6412 - recall: 0.3607 - auc: 0.7459 - val_loss: 1.5351 - val_tp: 195.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 301.0000 - val_accuracy: 0.4113 - val_precision: 0.4248 - val_recall: 0.3931 - val_auc: 0.5875\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.20685\n",
      "Epoch 125/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9227 - tp: 1691.0000 - fp: 853.0000 - tn: 8075.0000 - fn: 2773.0000 - accuracy: 0.5708 - precision: 0.6647 - recall: 0.3788 - auc: 0.7524 - val_loss: 1.5316 - val_tp: 179.0000 - val_fp: 235.0000 - val_tn: 757.0000 - val_fn: 317.0000 - val_accuracy: 0.4294 - val_precision: 0.4324 - val_recall: 0.3609 - val_auc: 0.5926\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.20685\n",
      "Epoch 126/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9181 - tp: 1627.0000 - fp: 874.0000 - tn: 8054.0000 - fn: 2837.0000 - accuracy: 0.5674 - precision: 0.6505 - recall: 0.3645 - auc: 0.7535 - val_loss: 1.4901 - val_tp: 189.0000 - val_fp: 225.0000 - val_tn: 767.0000 - val_fn: 307.0000 - val_accuracy: 0.4274 - val_precision: 0.4565 - val_recall: 0.3810 - val_auc: 0.5926\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.20685\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9251 - tp: 1643.0000 - fp: 886.0000 - tn: 8042.0000 - fn: 2821.0000 - accuracy: 0.5540 - precision: 0.6497 - recall: 0.3681 - auc: 0.7470 - val_loss: 1.3454 - val_tp: 189.0000 - val_fp: 217.0000 - val_tn: 775.0000 - val_fn: 307.0000 - val_accuracy: 0.4738 - val_precision: 0.4655 - val_recall: 0.3810 - val_auc: 0.6185\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.20685\n",
      "Epoch 128/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9211 - tp: 1643.0000 - fp: 890.0000 - tn: 8038.0000 - fn: 2821.0000 - accuracy: 0.5672 - precision: 0.6486 - recall: 0.3681 - auc: 0.7508 - val_loss: 2.2723 - val_tp: 154.0000 - val_fp: 332.0000 - val_tn: 660.0000 - val_fn: 342.0000 - val_accuracy: 0.3165 - val_precision: 0.3169 - val_recall: 0.3105 - val_auc: 0.5314\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.20685\n",
      "Epoch 129/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9145 - tp: 1679.0000 - fp: 844.0000 - tn: 8084.0000 - fn: 2785.0000 - accuracy: 0.5647 - precision: 0.6655 - recall: 0.3761 - auc: 0.7549 - val_loss: 1.4706 - val_tp: 198.0000 - val_fp: 231.0000 - val_tn: 761.0000 - val_fn: 298.0000 - val_accuracy: 0.4637 - val_precision: 0.4615 - val_recall: 0.3992 - val_auc: 0.6096\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.20685\n",
      "Epoch 130/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9165 - tp: 1634.0000 - fp: 850.0000 - tn: 8078.0000 - fn: 2830.0000 - accuracy: 0.5715 - precision: 0.6578 - recall: 0.3660 - auc: 0.7544 - val_loss: 1.4884 - val_tp: 192.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 304.0000 - val_accuracy: 0.4032 - val_precision: 0.4120 - val_recall: 0.3871 - val_auc: 0.5854\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.20685\n",
      "Epoch 131/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9222 - tp: 1686.0000 - fp: 855.0000 - tn: 8073.0000 - fn: 2778.0000 - accuracy: 0.5730 - precision: 0.6635 - recall: 0.3777 - auc: 0.7520 - val_loss: 1.6804 - val_tp: 202.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 294.0000 - val_accuracy: 0.4274 - val_precision: 0.4280 - val_recall: 0.4073 - val_auc: 0.5937\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.20685\n",
      "Epoch 132/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9256 - tp: 1628.0000 - fp: 902.0000 - tn: 8026.0000 - fn: 2836.0000 - accuracy: 0.5571 - precision: 0.6435 - recall: 0.3647 - auc: 0.7478 - val_loss: 1.4723 - val_tp: 195.0000 - val_fp: 229.0000 - val_tn: 763.0000 - val_fn: 301.0000 - val_accuracy: 0.4556 - val_precision: 0.4599 - val_recall: 0.3931 - val_auc: 0.6103\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.20685\n",
      "Epoch 133/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9169 - tp: 1677.0000 - fp: 877.0000 - tn: 8051.0000 - fn: 2787.0000 - accuracy: 0.5652 - precision: 0.6566 - recall: 0.3757 - auc: 0.7539 - val_loss: 1.5453 - val_tp: 200.0000 - val_fp: 234.0000 - val_tn: 758.0000 - val_fn: 296.0000 - val_accuracy: 0.4577 - val_precision: 0.4608 - val_recall: 0.4032 - val_auc: 0.6030\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.20685\n",
      "Epoch 134/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9221 - tp: 1746.0000 - fp: 914.0000 - tn: 8014.0000 - fn: 2718.0000 - accuracy: 0.5753 - precision: 0.6564 - recall: 0.3911 - auc: 0.7520 - val_loss: 1.8080 - val_tp: 166.0000 - val_fp: 315.0000 - val_tn: 677.0000 - val_fn: 330.0000 - val_accuracy: 0.3488 - val_precision: 0.3451 - val_recall: 0.3347 - val_auc: 0.5545\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.20685\n",
      "Epoch 135/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9090 - tp: 1688.0000 - fp: 838.0000 - tn: 8090.0000 - fn: 2776.0000 - accuracy: 0.5797 - precision: 0.6683 - recall: 0.3781 - auc: 0.7600 - val_loss: 1.3947 - val_tp: 159.0000 - val_fp: 224.0000 - val_tn: 768.0000 - val_fn: 337.0000 - val_accuracy: 0.4012 - val_precision: 0.4151 - val_recall: 0.3206 - val_auc: 0.5567\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.20685\n",
      "Epoch 136/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9178 - tp: 1684.0000 - fp: 862.0000 - tn: 8066.0000 - fn: 2780.0000 - accuracy: 0.5728 - precision: 0.6614 - recall: 0.3772 - auc: 0.7554 - val_loss: 1.4534 - val_tp: 119.0000 - val_fp: 186.0000 - val_tn: 806.0000 - val_fn: 377.0000 - val_accuracy: 0.3851 - val_precision: 0.3902 - val_recall: 0.2399 - val_auc: 0.5376\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.20685\n",
      "Epoch 137/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9184 - tp: 1718.0000 - fp: 901.0000 - tn: 8027.0000 - fn: 2746.0000 - accuracy: 0.5724 - precision: 0.6560 - recall: 0.3849 - auc: 0.7536 - val_loss: 1.3769 - val_tp: 133.0000 - val_fp: 192.0000 - val_tn: 800.0000 - val_fn: 363.0000 - val_accuracy: 0.3911 - val_precision: 0.4092 - val_recall: 0.2681 - val_auc: 0.5592\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.20685\n",
      "Epoch 138/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.9089 - tp: 1737.0000 - fp: 830.0000 - tn: 8098.0000 - fn: 2727.0000 - accuracy: 0.5706 - precision: 0.6767 - recall: 0.3891 - auc: 0.7608 - val_loss: 1.4474 - val_tp: 191.0000 - val_fp: 244.0000 - val_tn: 748.0000 - val_fn: 305.0000 - val_accuracy: 0.4133 - val_precision: 0.4391 - val_recall: 0.3851 - val_auc: 0.5950\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.20685\n",
      "Epoch 139/500\n",
      "4464/4464 [==============================] - 0s 76us/step - loss: 0.9085 - tp: 1702.0000 - fp: 872.0000 - tn: 8056.0000 - fn: 2762.0000 - accuracy: 0.5728 - precision: 0.6612 - recall: 0.3813 - auc: 0.7603 - val_loss: 1.5406 - val_tp: 186.0000 - val_fp: 223.0000 - val_tn: 769.0000 - val_fn: 310.0000 - val_accuracy: 0.4476 - val_precision: 0.4548 - val_recall: 0.3750 - val_auc: 0.6053\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.20685\n",
      "Epoch 140/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9181 - tp: 1719.0000 - fp: 881.0000 - tn: 8047.0000 - fn: 2745.0000 - accuracy: 0.5685 - precision: 0.6612 - recall: 0.3851 - auc: 0.7526 - val_loss: 2.2236 - val_tp: 209.0000 - val_fp: 266.0000 - val_tn: 726.0000 - val_fn: 287.0000 - val_accuracy: 0.4456 - val_precision: 0.4400 - val_recall: 0.4214 - val_auc: 0.6031\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.20685\n",
      "Epoch 141/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9161 - tp: 1711.0000 - fp: 860.0000 - tn: 8068.0000 - fn: 2753.0000 - accuracy: 0.5762 - precision: 0.6655 - recall: 0.3833 - auc: 0.7546 - val_loss: 1.5218 - val_tp: 189.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 307.0000 - val_accuracy: 0.4234 - val_precision: 0.4345 - val_recall: 0.3810 - val_auc: 0.5697\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.20685\n",
      "Epoch 142/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9044 - tp: 1764.0000 - fp: 850.0000 - tn: 8078.0000 - fn: 2700.0000 - accuracy: 0.5833 - precision: 0.6748 - recall: 0.3952 - auc: 0.7628 - val_loss: 1.5984 - val_tp: 162.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 334.0000 - val_accuracy: 0.4052 - val_precision: 0.4050 - val_recall: 0.3266 - val_auc: 0.5754\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.20685\n",
      "Epoch 143/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9161 - tp: 1701.0000 - fp: 870.0000 - tn: 8058.0000 - fn: 2763.0000 - accuracy: 0.5730 - precision: 0.6616 - recall: 0.3810 - auc: 0.7551 - val_loss: 2.1396 - val_tp: 230.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 266.0000 - val_accuracy: 0.4778 - val_precision: 0.4772 - val_recall: 0.4637 - val_auc: 0.6146\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.20685\n",
      "Epoch 144/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.9182 - tp: 1719.0000 - fp: 832.0000 - tn: 8096.0000 - fn: 2745.0000 - accuracy: 0.5786 - precision: 0.6739 - recall: 0.3851 - auc: 0.7574 - val_loss: 1.6839 - val_tp: 190.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 306.0000 - val_accuracy: 0.4133 - val_precision: 0.4222 - val_recall: 0.3831 - val_auc: 0.5896\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.20685\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.9281 - tp: 1590.0000 - fp: 945.0000 - tn: 7983.0000 - fn: 2874.0000 - accuracy: 0.5576 - precision: 0.6272 - recall: 0.3562 - auc: 0.7444 - val_loss: 1.7350 - val_tp: 190.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 306.0000 - val_accuracy: 0.4214 - val_precision: 0.4299 - val_recall: 0.3831 - val_auc: 0.5923\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.20685\n",
      "Epoch 146/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.9039 - tp: 1709.0000 - fp: 868.0000 - tn: 8060.0000 - fn: 2755.0000 - accuracy: 0.5681 - precision: 0.6632 - recall: 0.3828 - auc: 0.7615 - val_loss: 1.9434 - val_tp: 174.0000 - val_fp: 297.0000 - val_tn: 695.0000 - val_fn: 322.0000 - val_accuracy: 0.3649 - val_precision: 0.3694 - val_recall: 0.3508 - val_auc: 0.5551\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.20685\n",
      "Epoch 147/500\n",
      "4464/4464 [==============================] - 0s 80us/step - loss: 0.9131 - tp: 1736.0000 - fp: 865.0000 - tn: 8063.0000 - fn: 2728.0000 - accuracy: 0.5737 - precision: 0.6674 - recall: 0.3889 - auc: 0.7572 - val_loss: 1.4899 - val_tp: 180.0000 - val_fp: 228.0000 - val_tn: 764.0000 - val_fn: 316.0000 - val_accuracy: 0.4375 - val_precision: 0.4412 - val_recall: 0.3629 - val_auc: 0.5769\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.20685\n",
      "Epoch 148/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9075 - tp: 1737.0000 - fp: 888.0000 - tn: 8040.0000 - fn: 2727.0000 - accuracy: 0.5804 - precision: 0.6617 - recall: 0.3891 - auc: 0.7619 - val_loss: 1.5918 - val_tp: 201.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 295.0000 - val_accuracy: 0.4637 - val_precision: 0.4600 - val_recall: 0.4052 - val_auc: 0.6060\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.20685\n",
      "Epoch 149/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9160 - tp: 1707.0000 - fp: 846.0000 - tn: 8082.0000 - fn: 2757.0000 - accuracy: 0.5701 - precision: 0.6686 - recall: 0.3824 - auc: 0.7549 - val_loss: 1.9922 - val_tp: 192.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 304.0000 - val_accuracy: 0.4173 - val_precision: 0.4229 - val_recall: 0.3871 - val_auc: 0.5893\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.20685\n",
      "Epoch 150/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9076 - tp: 1745.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2719.0000 - accuracy: 0.5746 - precision: 0.6526 - recall: 0.3909 - auc: 0.7592 - val_loss: 1.4440 - val_tp: 184.0000 - val_fp: 222.0000 - val_tn: 770.0000 - val_fn: 312.0000 - val_accuracy: 0.4234 - val_precision: 0.4532 - val_recall: 0.3710 - val_auc: 0.6014\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.20685\n",
      "Epoch 151/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9191 - tp: 1685.0000 - fp: 894.0000 - tn: 8034.0000 - fn: 2779.0000 - accuracy: 0.5683 - precision: 0.6534 - recall: 0.3775 - auc: 0.7531 - val_loss: 1.5377 - val_tp: 202.0000 - val_fp: 240.0000 - val_tn: 752.0000 - val_fn: 294.0000 - val_accuracy: 0.4435 - val_precision: 0.4570 - val_recall: 0.4073 - val_auc: 0.6036\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.20685\n",
      "Epoch 152/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9001 - tp: 1748.0000 - fp: 884.0000 - tn: 8044.0000 - fn: 2716.0000 - accuracy: 0.5726 - precision: 0.6641 - recall: 0.3916 - auc: 0.7645 - val_loss: 1.6125 - val_tp: 194.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 302.0000 - val_accuracy: 0.4113 - val_precision: 0.4199 - val_recall: 0.3911 - val_auc: 0.5869\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.20685\n",
      "Epoch 153/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9099 - tp: 1673.0000 - fp: 880.0000 - tn: 8048.0000 - fn: 2791.0000 - accuracy: 0.5759 - precision: 0.6553 - recall: 0.3748 - auc: 0.7584 - val_loss: 1.5454 - val_tp: 197.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 299.0000 - val_accuracy: 0.4234 - val_precision: 0.4407 - val_recall: 0.3972 - val_auc: 0.5847\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.20685\n",
      "Epoch 154/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9023 - tp: 1776.0000 - fp: 867.0000 - tn: 8061.0000 - fn: 2688.0000 - accuracy: 0.5833 - precision: 0.6720 - recall: 0.3978 - auc: 0.7658 - val_loss: 1.9545 - val_tp: 208.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 288.0000 - val_accuracy: 0.4294 - val_precision: 0.4361 - val_recall: 0.4194 - val_auc: 0.6008\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.20685\n",
      "Epoch 155/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9140 - tp: 1763.0000 - fp: 922.0000 - tn: 8006.0000 - fn: 2701.0000 - accuracy: 0.5712 - precision: 0.6566 - recall: 0.3949 - auc: 0.7560 - val_loss: 1.6209 - val_tp: 188.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 308.0000 - val_accuracy: 0.4234 - val_precision: 0.4273 - val_recall: 0.3790 - val_auc: 0.5663\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.20685\n",
      "Epoch 156/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.9064 - tp: 1783.0000 - fp: 898.0000 - tn: 8030.0000 - fn: 2681.0000 - accuracy: 0.5782 - precision: 0.6651 - recall: 0.3994 - auc: 0.7617 - val_loss: 1.4646 - val_tp: 204.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 292.0000 - val_accuracy: 0.4415 - val_precision: 0.4564 - val_recall: 0.4113 - val_auc: 0.6066\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.20685\n",
      "Epoch 157/500\n",
      "4464/4464 [==============================] - 0s 79us/step - loss: 0.9040 - tp: 1756.0000 - fp: 875.0000 - tn: 8053.0000 - fn: 2708.0000 - accuracy: 0.5811 - precision: 0.6674 - recall: 0.3934 - auc: 0.7626 - val_loss: 1.6367 - val_tp: 192.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 304.0000 - val_accuracy: 0.4052 - val_precision: 0.4138 - val_recall: 0.3871 - val_auc: 0.5857\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.20685\n",
      "Epoch 158/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.9157 - tp: 1668.0000 - fp: 878.0000 - tn: 8050.0000 - fn: 2796.0000 - accuracy: 0.5717 - precision: 0.6551 - recall: 0.3737 - auc: 0.7553 - val_loss: 1.6305 - val_tp: 191.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 305.0000 - val_accuracy: 0.4153 - val_precision: 0.4161 - val_recall: 0.3851 - val_auc: 0.5746\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.20685\n",
      "Epoch 159/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9111 - tp: 1745.0000 - fp: 934.0000 - tn: 7994.0000 - fn: 2719.0000 - accuracy: 0.5768 - precision: 0.6514 - recall: 0.3909 - auc: 0.7594 - val_loss: 1.5155 - val_tp: 175.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 321.0000 - val_accuracy: 0.4133 - val_precision: 0.4187 - val_recall: 0.3528 - val_auc: 0.5910\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.20685\n",
      "Epoch 160/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.9103 - tp: 1697.0000 - fp: 890.0000 - tn: 8038.0000 - fn: 2767.0000 - accuracy: 0.5802 - precision: 0.6560 - recall: 0.3802 - auc: 0.7597 - val_loss: 1.5264 - val_tp: 148.0000 - val_fp: 228.0000 - val_tn: 764.0000 - val_fn: 348.0000 - val_accuracy: 0.3770 - val_precision: 0.3936 - val_recall: 0.2984 - val_auc: 0.5509\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.20685\n",
      "Epoch 161/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9078 - tp: 1735.0000 - fp: 869.0000 - tn: 8059.0000 - fn: 2729.0000 - accuracy: 0.5800 - precision: 0.6663 - recall: 0.3887 - auc: 0.7617 - val_loss: 1.4278 - val_tp: 169.0000 - val_fp: 213.0000 - val_tn: 779.0000 - val_fn: 327.0000 - val_accuracy: 0.4254 - val_precision: 0.4424 - val_recall: 0.3407 - val_auc: 0.5915\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.20685\n",
      "Epoch 162/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8999 - tp: 1783.0000 - fp: 899.0000 - tn: 8029.0000 - fn: 2681.0000 - accuracy: 0.5836 - precision: 0.6648 - recall: 0.3994 - auc: 0.7647 - val_loss: 1.4332 - val_tp: 156.0000 - val_fp: 191.0000 - val_tn: 801.0000 - val_fn: 340.0000 - val_accuracy: 0.4375 - val_precision: 0.4496 - val_recall: 0.3145 - val_auc: 0.5843\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.20685\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9056 - tp: 1757.0000 - fp: 877.0000 - tn: 8051.0000 - fn: 2707.0000 - accuracy: 0.5759 - precision: 0.6670 - recall: 0.3936 - auc: 0.7607 - val_loss: 1.9092 - val_tp: 164.0000 - val_fp: 316.0000 - val_tn: 676.0000 - val_fn: 332.0000 - val_accuracy: 0.3407 - val_precision: 0.3417 - val_recall: 0.3306 - val_auc: 0.5331\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.20685\n",
      "Epoch 164/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9022 - tp: 1737.0000 - fp: 900.0000 - tn: 8028.0000 - fn: 2727.0000 - accuracy: 0.5764 - precision: 0.6587 - recall: 0.3891 - auc: 0.7643 - val_loss: 2.1441 - val_tp: 204.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 292.0000 - val_accuracy: 0.4274 - val_precision: 0.4268 - val_recall: 0.4113 - val_auc: 0.5906\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.20685\n",
      "Epoch 165/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8994 - tp: 1822.0000 - fp: 895.0000 - tn: 8033.0000 - fn: 2642.0000 - accuracy: 0.5773 - precision: 0.6706 - recall: 0.4082 - auc: 0.7668 - val_loss: 2.0262 - val_tp: 186.0000 - val_fp: 287.0000 - val_tn: 705.0000 - val_fn: 310.0000 - val_accuracy: 0.3871 - val_precision: 0.3932 - val_recall: 0.3750 - val_auc: 0.5926\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.20685\n",
      "Epoch 166/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9053 - tp: 1785.0000 - fp: 908.0000 - tn: 8020.0000 - fn: 2679.0000 - accuracy: 0.5768 - precision: 0.6628 - recall: 0.3999 - auc: 0.7629 - val_loss: 2.2578 - val_tp: 209.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 287.0000 - val_accuracy: 0.4335 - val_precision: 0.4382 - val_recall: 0.4214 - val_auc: 0.6099\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.20685\n",
      "Epoch 167/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9088 - tp: 1719.0000 - fp: 891.0000 - tn: 8037.0000 - fn: 2745.0000 - accuracy: 0.5793 - precision: 0.6586 - recall: 0.3851 - auc: 0.7619 - val_loss: 1.6178 - val_tp: 198.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 298.0000 - val_accuracy: 0.4234 - val_precision: 0.4240 - val_recall: 0.3992 - val_auc: 0.5801\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.20685\n",
      "Epoch 168/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9047 - tp: 1764.0000 - fp: 856.0000 - tn: 8072.0000 - fn: 2700.0000 - accuracy: 0.5688 - precision: 0.6733 - recall: 0.3952 - auc: 0.7614 - val_loss: 1.4133 - val_tp: 180.0000 - val_fp: 212.0000 - val_tn: 780.0000 - val_fn: 316.0000 - val_accuracy: 0.4375 - val_precision: 0.4592 - val_recall: 0.3629 - val_auc: 0.5921\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.20685\n",
      "Epoch 169/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9050 - tp: 1813.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2651.0000 - accuracy: 0.5811 - precision: 0.6593 - recall: 0.4061 - auc: 0.7631 - val_loss: 1.4355 - val_tp: 178.0000 - val_fp: 214.0000 - val_tn: 778.0000 - val_fn: 318.0000 - val_accuracy: 0.4315 - val_precision: 0.4541 - val_recall: 0.3589 - val_auc: 0.6032\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.20685\n",
      "Epoch 170/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.9001 - tp: 1779.0000 - fp: 880.0000 - tn: 8048.0000 - fn: 2685.0000 - accuracy: 0.5746 - precision: 0.6690 - recall: 0.3985 - auc: 0.7643 - val_loss: 1.7296 - val_tp: 203.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 293.0000 - val_accuracy: 0.4315 - val_precision: 0.4301 - val_recall: 0.4093 - val_auc: 0.5882\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.20685\n",
      "Epoch 171/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8911 - tp: 1840.0000 - fp: 887.0000 - tn: 8041.0000 - fn: 2624.0000 - accuracy: 0.5912 - precision: 0.6747 - recall: 0.4122 - auc: 0.7728 - val_loss: 1.7106 - val_tp: 195.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 301.0000 - val_accuracy: 0.4294 - val_precision: 0.4353 - val_recall: 0.3931 - val_auc: 0.5937\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.20685\n",
      "Epoch 172/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8960 - tp: 1797.0000 - fp: 858.0000 - tn: 8070.0000 - fn: 2667.0000 - accuracy: 0.5836 - precision: 0.6768 - recall: 0.4026 - auc: 0.7670 - val_loss: 1.5824 - val_tp: 191.0000 - val_fp: 227.0000 - val_tn: 765.0000 - val_fn: 305.0000 - val_accuracy: 0.4395 - val_precision: 0.4569 - val_recall: 0.3851 - val_auc: 0.6028\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.20685\n",
      "Epoch 173/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.8982 - tp: 1813.0000 - fp: 921.0000 - tn: 8007.0000 - fn: 2651.0000 - accuracy: 0.5764 - precision: 0.6631 - recall: 0.4061 - auc: 0.7654 - val_loss: 1.6407 - val_tp: 204.0000 - val_fp: 237.0000 - val_tn: 755.0000 - val_fn: 292.0000 - val_accuracy: 0.4516 - val_precision: 0.4626 - val_recall: 0.4113 - val_auc: 0.6121\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.20685\n",
      "Epoch 174/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.8993 - tp: 1819.0000 - fp: 901.0000 - tn: 8027.0000 - fn: 2645.0000 - accuracy: 0.5916 - precision: 0.6687 - recall: 0.4075 - auc: 0.7680 - val_loss: 2.0044 - val_tp: 217.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 279.0000 - val_accuracy: 0.4597 - val_precision: 0.4627 - val_recall: 0.4375 - val_auc: 0.6109\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.20685\n",
      "Epoch 175/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.9027 - tp: 1832.0000 - fp: 910.0000 - tn: 8018.0000 - fn: 2632.0000 - accuracy: 0.5759 - precision: 0.6681 - recall: 0.4104 - auc: 0.7637 - val_loss: 2.0640 - val_tp: 186.0000 - val_fp: 286.0000 - val_tn: 706.0000 - val_fn: 310.0000 - val_accuracy: 0.3911 - val_precision: 0.3941 - val_recall: 0.3750 - val_auc: 0.5660\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.20685\n",
      "Epoch 176/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9013 - tp: 1784.0000 - fp: 895.0000 - tn: 8033.0000 - fn: 2680.0000 - accuracy: 0.5845 - precision: 0.6659 - recall: 0.3996 - auc: 0.7659 - val_loss: 2.0533 - val_tp: 217.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 279.0000 - val_accuracy: 0.4456 - val_precision: 0.4540 - val_recall: 0.4375 - val_auc: 0.6006\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.20685\n",
      "Epoch 177/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9093 - tp: 1778.0000 - fp: 882.0000 - tn: 8046.0000 - fn: 2686.0000 - accuracy: 0.5771 - precision: 0.6684 - recall: 0.3983 - auc: 0.7593 - val_loss: 1.8417 - val_tp: 202.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 294.0000 - val_accuracy: 0.4234 - val_precision: 0.4363 - val_recall: 0.4073 - val_auc: 0.6032\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.20685\n",
      "Epoch 178/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9118 - tp: 1763.0000 - fp: 935.0000 - tn: 7993.0000 - fn: 2701.0000 - accuracy: 0.5674 - precision: 0.6534 - recall: 0.3949 - auc: 0.7577 - val_loss: 2.0763 - val_tp: 221.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 275.0000 - val_accuracy: 0.4516 - val_precision: 0.4510 - val_recall: 0.4456 - val_auc: 0.6110\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.20685\n",
      "Epoch 179/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9077 - tp: 1771.0000 - fp: 913.0000 - tn: 8015.0000 - fn: 2693.0000 - accuracy: 0.5822 - precision: 0.6598 - recall: 0.3967 - auc: 0.7624 - val_loss: 1.6004 - val_tp: 201.0000 - val_fp: 233.0000 - val_tn: 759.0000 - val_fn: 295.0000 - val_accuracy: 0.4718 - val_precision: 0.4631 - val_recall: 0.4052 - val_auc: 0.6196\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.20685\n",
      "Epoch 180/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9011 - tp: 1790.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2674.0000 - accuracy: 0.5753 - precision: 0.6564 - recall: 0.4010 - auc: 0.7639 - val_loss: 1.6183 - val_tp: 192.0000 - val_fp: 235.0000 - val_tn: 757.0000 - val_fn: 304.0000 - val_accuracy: 0.4254 - val_precision: 0.4496 - val_recall: 0.3871 - val_auc: 0.5938\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.20685\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.9017 - tp: 1830.0000 - fp: 877.0000 - tn: 8051.0000 - fn: 2634.0000 - accuracy: 0.5813 - precision: 0.6760 - recall: 0.4099 - auc: 0.7664 - val_loss: 2.4832 - val_tp: 202.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 294.0000 - val_accuracy: 0.4153 - val_precision: 0.4191 - val_recall: 0.4073 - val_auc: 0.5892\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.20685\n",
      "Epoch 182/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8895 - tp: 1854.0000 - fp: 884.0000 - tn: 8044.0000 - fn: 2610.0000 - accuracy: 0.5912 - precision: 0.6771 - recall: 0.4153 - auc: 0.7735 - val_loss: 1.5716 - val_tp: 192.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 304.0000 - val_accuracy: 0.4294 - val_precision: 0.4424 - val_recall: 0.3871 - val_auc: 0.5830\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.20685\n",
      "Epoch 183/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9053 - tp: 1772.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2692.0000 - accuracy: 0.5762 - precision: 0.6568 - recall: 0.3970 - auc: 0.7622 - val_loss: 1.9894 - val_tp: 212.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 284.0000 - val_accuracy: 0.4476 - val_precision: 0.4463 - val_recall: 0.4274 - val_auc: 0.6109\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.20685\n",
      "Epoch 184/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8927 - tp: 1861.0000 - fp: 867.0000 - tn: 8061.0000 - fn: 2603.0000 - accuracy: 0.5849 - precision: 0.6822 - recall: 0.4169 - auc: 0.7716 - val_loss: 1.7107 - val_tp: 171.0000 - val_fp: 299.0000 - val_tn: 693.0000 - val_fn: 325.0000 - val_accuracy: 0.3528 - val_precision: 0.3638 - val_recall: 0.3448 - val_auc: 0.5499\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.20685\n",
      "Epoch 185/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8984 - tp: 1853.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2611.0000 - accuracy: 0.5822 - precision: 0.6651 - recall: 0.4151 - auc: 0.7647 - val_loss: 1.6621 - val_tp: 192.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 304.0000 - val_accuracy: 0.4073 - val_precision: 0.4111 - val_recall: 0.3871 - val_auc: 0.5699\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.20685\n",
      "Epoch 186/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.9010 - tp: 1770.0000 - fp: 892.0000 - tn: 8036.0000 - fn: 2694.0000 - accuracy: 0.5802 - precision: 0.6649 - recall: 0.3965 - auc: 0.7637 - val_loss: 1.5677 - val_tp: 197.0000 - val_fp: 233.0000 - val_tn: 759.0000 - val_fn: 299.0000 - val_accuracy: 0.4435 - val_precision: 0.4581 - val_recall: 0.3972 - val_auc: 0.5925\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.20685\n",
      "Epoch 187/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8922 - tp: 1813.0000 - fp: 898.0000 - tn: 8030.0000 - fn: 2651.0000 - accuracy: 0.5867 - precision: 0.6688 - recall: 0.4061 - auc: 0.7703 - val_loss: 1.5240 - val_tp: 175.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 321.0000 - val_accuracy: 0.3911 - val_precision: 0.3863 - val_recall: 0.3528 - val_auc: 0.5731\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.20685\n",
      "Epoch 188/500\n",
      "4464/4464 [==============================] - 0s 78us/step - loss: 0.8957 - tp: 1813.0000 - fp: 888.0000 - tn: 8040.0000 - fn: 2651.0000 - accuracy: 0.5856 - precision: 0.6712 - recall: 0.4061 - auc: 0.7684 - val_loss: 2.1912 - val_tp: 226.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 270.0000 - val_accuracy: 0.4698 - val_precision: 0.4788 - val_recall: 0.4556 - val_auc: 0.6260\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.20685\n",
      "Epoch 189/500\n",
      "4464/4464 [==============================] - 0s 78us/step - loss: 0.8981 - tp: 1815.0000 - fp: 870.0000 - tn: 8058.0000 - fn: 2649.0000 - accuracy: 0.5869 - precision: 0.6760 - recall: 0.4066 - auc: 0.7669 - val_loss: 1.8371 - val_tp: 214.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 282.0000 - val_accuracy: 0.4536 - val_precision: 0.4683 - val_recall: 0.4315 - val_auc: 0.6141\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.20685\n",
      "Epoch 190/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8927 - tp: 1880.0000 - fp: 935.0000 - tn: 7993.0000 - fn: 2584.0000 - accuracy: 0.5871 - precision: 0.6679 - recall: 0.4211 - auc: 0.7710 - val_loss: 1.6137 - val_tp: 203.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 293.0000 - val_accuracy: 0.4657 - val_precision: 0.4603 - val_recall: 0.4093 - val_auc: 0.6198\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.20685\n",
      "Epoch 191/500\n",
      "4464/4464 [==============================] - 0s 80us/step - loss: 0.9046 - tp: 1769.0000 - fp: 931.0000 - tn: 7997.0000 - fn: 2695.0000 - accuracy: 0.5677 - precision: 0.6552 - recall: 0.3963 - auc: 0.7614 - val_loss: 1.3918 - val_tp: 138.0000 - val_fp: 207.0000 - val_tn: 785.0000 - val_fn: 358.0000 - val_accuracy: 0.3548 - val_precision: 0.4000 - val_recall: 0.2782 - val_auc: 0.5415\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.20685\n",
      "Epoch 192/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9032 - tp: 1789.0000 - fp: 917.0000 - tn: 8011.0000 - fn: 2675.0000 - accuracy: 0.5815 - precision: 0.6611 - recall: 0.4008 - auc: 0.7641 - val_loss: 1.6039 - val_tp: 201.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 295.0000 - val_accuracy: 0.4214 - val_precision: 0.4370 - val_recall: 0.4052 - val_auc: 0.5987\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.20685\n",
      "Epoch 193/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8919 - tp: 1805.0000 - fp: 878.0000 - tn: 8050.0000 - fn: 2659.0000 - accuracy: 0.5907 - precision: 0.6728 - recall: 0.4043 - auc: 0.7723 - val_loss: 1.5587 - val_tp: 172.0000 - val_fp: 229.0000 - val_tn: 763.0000 - val_fn: 324.0000 - val_accuracy: 0.4153 - val_precision: 0.4289 - val_recall: 0.3468 - val_auc: 0.5891\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.20685\n",
      "Epoch 194/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8982 - tp: 1837.0000 - fp: 921.0000 - tn: 8007.0000 - fn: 2627.0000 - accuracy: 0.5883 - precision: 0.6661 - recall: 0.4115 - auc: 0.7677 - val_loss: 1.5319 - val_tp: 193.0000 - val_fp: 231.0000 - val_tn: 761.0000 - val_fn: 303.0000 - val_accuracy: 0.4597 - val_precision: 0.4552 - val_recall: 0.3891 - val_auc: 0.6146\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.20685\n",
      "Epoch 195/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8938 - tp: 1834.0000 - fp: 907.0000 - tn: 8021.0000 - fn: 2630.0000 - accuracy: 0.5822 - precision: 0.6691 - recall: 0.4108 - auc: 0.7679 - val_loss: 1.7284 - val_tp: 217.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 279.0000 - val_accuracy: 0.4556 - val_precision: 0.4607 - val_recall: 0.4375 - val_auc: 0.6100\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.20685\n",
      "Epoch 196/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8975 - tp: 1829.0000 - fp: 906.0000 - tn: 8022.0000 - fn: 2635.0000 - accuracy: 0.5858 - precision: 0.6687 - recall: 0.4097 - auc: 0.7688 - val_loss: 1.7017 - val_tp: 202.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 294.0000 - val_accuracy: 0.4274 - val_precision: 0.4430 - val_recall: 0.4073 - val_auc: 0.6016\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.20685\n",
      "Epoch 197/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8975 - tp: 1867.0000 - fp: 890.0000 - tn: 8038.0000 - fn: 2597.0000 - accuracy: 0.5934 - precision: 0.6772 - recall: 0.4182 - auc: 0.7686 - val_loss: 1.5179 - val_tp: 167.0000 - val_fp: 220.0000 - val_tn: 772.0000 - val_fn: 329.0000 - val_accuracy: 0.4173 - val_precision: 0.4315 - val_recall: 0.3367 - val_auc: 0.5697\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.20685\n",
      "Epoch 198/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8875 - tp: 1838.0000 - fp: 905.0000 - tn: 8023.0000 - fn: 2626.0000 - accuracy: 0.5907 - precision: 0.6701 - recall: 0.4117 - auc: 0.7732 - val_loss: 1.4364 - val_tp: 187.0000 - val_fp: 201.0000 - val_tn: 791.0000 - val_fn: 309.0000 - val_accuracy: 0.4516 - val_precision: 0.4820 - val_recall: 0.3770 - val_auc: 0.6025\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.20685\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8917 - tp: 1844.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2620.0000 - accuracy: 0.5874 - precision: 0.6657 - recall: 0.4131 - auc: 0.7706 - val_loss: 2.7855 - val_tp: 236.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 260.0000 - val_accuracy: 0.4778 - val_precision: 0.4826 - val_recall: 0.4758 - val_auc: 0.6199\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.20685\n",
      "Epoch 200/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8941 - tp: 1834.0000 - fp: 913.0000 - tn: 8015.0000 - fn: 2630.0000 - accuracy: 0.5918 - precision: 0.6676 - recall: 0.4108 - auc: 0.7693 - val_loss: 2.1062 - val_tp: 173.0000 - val_fp: 309.0000 - val_tn: 683.0000 - val_fn: 323.0000 - val_accuracy: 0.3528 - val_precision: 0.3589 - val_recall: 0.3488 - val_auc: 0.5665\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.20685\n",
      "Epoch 201/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8957 - tp: 1865.0000 - fp: 962.0000 - tn: 7966.0000 - fn: 2599.0000 - accuracy: 0.5824 - precision: 0.6597 - recall: 0.4178 - auc: 0.7685 - val_loss: 1.8172 - val_tp: 211.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 285.0000 - val_accuracy: 0.4415 - val_precision: 0.4480 - val_recall: 0.4254 - val_auc: 0.6026\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1.20685\n",
      "Epoch 202/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8871 - tp: 1891.0000 - fp: 909.0000 - tn: 8019.0000 - fn: 2573.0000 - accuracy: 0.5909 - precision: 0.6754 - recall: 0.4236 - auc: 0.7743 - val_loss: 1.6142 - val_tp: 200.0000 - val_fp: 239.0000 - val_tn: 753.0000 - val_fn: 296.0000 - val_accuracy: 0.4415 - val_precision: 0.4556 - val_recall: 0.4032 - val_auc: 0.6071\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1.20685\n",
      "Epoch 203/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8944 - tp: 1832.0000 - fp: 908.0000 - tn: 8020.0000 - fn: 2632.0000 - accuracy: 0.5925 - precision: 0.6686 - recall: 0.4104 - auc: 0.7704 - val_loss: 1.9084 - val_tp: 161.0000 - val_fp: 319.0000 - val_tn: 673.0000 - val_fn: 335.0000 - val_accuracy: 0.3327 - val_precision: 0.3354 - val_recall: 0.3246 - val_auc: 0.5196\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.20685\n",
      "Epoch 204/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8878 - tp: 1845.0000 - fp: 885.0000 - tn: 8043.0000 - fn: 2619.0000 - accuracy: 0.5856 - precision: 0.6758 - recall: 0.4133 - auc: 0.7719 - val_loss: 1.6359 - val_tp: 214.0000 - val_fp: 232.0000 - val_tn: 760.0000 - val_fn: 282.0000 - val_accuracy: 0.4698 - val_precision: 0.4798 - val_recall: 0.4315 - val_auc: 0.6259\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.20685\n",
      "Epoch 205/500\n",
      "4464/4464 [==============================] - 0s 90us/step - loss: 0.8981 - tp: 1844.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2620.0000 - accuracy: 0.5804 - precision: 0.6576 - recall: 0.4131 - auc: 0.7661 - val_loss: 1.4073 - val_tp: 209.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 287.0000 - val_accuracy: 0.4738 - val_precision: 0.4676 - val_recall: 0.4214 - val_auc: 0.6247\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.20685\n",
      "Epoch 206/500\n",
      "4464/4464 [==============================] - 0s 90us/step - loss: 0.8916 - tp: 1833.0000 - fp: 944.0000 - tn: 7984.0000 - fn: 2631.0000 - accuracy: 0.5925 - precision: 0.6601 - recall: 0.4106 - auc: 0.7701 - val_loss: 1.6909 - val_tp: 207.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 289.0000 - val_accuracy: 0.4234 - val_precision: 0.4367 - val_recall: 0.4173 - val_auc: 0.5948\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.20685\n",
      "Epoch 207/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8859 - tp: 1913.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2551.0000 - accuracy: 0.5909 - precision: 0.6708 - recall: 0.4285 - auc: 0.7750 - val_loss: 1.8506 - val_tp: 201.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 295.0000 - val_accuracy: 0.4173 - val_precision: 0.4249 - val_recall: 0.4052 - val_auc: 0.5823\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.20685\n",
      "Epoch 208/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.8794 - tp: 1917.0000 - fp: 889.0000 - tn: 8039.0000 - fn: 2547.0000 - accuracy: 0.5981 - precision: 0.6832 - recall: 0.4294 - auc: 0.7794 - val_loss: 1.9632 - val_tp: 164.0000 - val_fp: 302.0000 - val_tn: 690.0000 - val_fn: 332.0000 - val_accuracy: 0.3468 - val_precision: 0.3519 - val_recall: 0.3306 - val_auc: 0.5378\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.20685\n",
      "Epoch 209/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.8874 - tp: 1826.0000 - fp: 889.0000 - tn: 8039.0000 - fn: 2638.0000 - accuracy: 0.5842 - precision: 0.6726 - recall: 0.4091 - auc: 0.7721 - val_loss: 1.6357 - val_tp: 189.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 307.0000 - val_accuracy: 0.4153 - val_precision: 0.4276 - val_recall: 0.3810 - val_auc: 0.5795\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.20685\n",
      "Epoch 210/500\n",
      "4464/4464 [==============================] - 0s 77us/step - loss: 0.8923 - tp: 1893.0000 - fp: 951.0000 - tn: 7977.0000 - fn: 2571.0000 - accuracy: 0.5907 - precision: 0.6656 - recall: 0.4241 - auc: 0.7699 - val_loss: 1.7460 - val_tp: 193.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 303.0000 - val_accuracy: 0.4294 - val_precision: 0.4270 - val_recall: 0.3891 - val_auc: 0.5868\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.20685\n",
      "Epoch 211/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8852 - tp: 1879.0000 - fp: 895.0000 - tn: 8033.0000 - fn: 2585.0000 - accuracy: 0.5979 - precision: 0.6774 - recall: 0.4209 - auc: 0.7761 - val_loss: 2.0781 - val_tp: 195.0000 - val_fp: 273.0000 - val_tn: 719.0000 - val_fn: 301.0000 - val_accuracy: 0.4254 - val_precision: 0.4167 - val_recall: 0.3931 - val_auc: 0.5828\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.20685\n",
      "Epoch 212/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8937 - tp: 1800.0000 - fp: 887.0000 - tn: 8041.0000 - fn: 2664.0000 - accuracy: 0.5811 - precision: 0.6699 - recall: 0.4032 - auc: 0.7706 - val_loss: 1.6490 - val_tp: 210.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 286.0000 - val_accuracy: 0.4395 - val_precision: 0.4526 - val_recall: 0.4234 - val_auc: 0.6097\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1.20685\n",
      "Epoch 213/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8966 - tp: 1892.0000 - fp: 946.0000 - tn: 7982.0000 - fn: 2572.0000 - accuracy: 0.5793 - precision: 0.6667 - recall: 0.4238 - auc: 0.7688 - val_loss: 2.0332 - val_tp: 196.0000 - val_fp: 292.0000 - val_tn: 700.0000 - val_fn: 300.0000 - val_accuracy: 0.3992 - val_precision: 0.4016 - val_recall: 0.3952 - val_auc: 0.5702\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1.20685\n",
      "Epoch 214/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8978 - tp: 1803.0000 - fp: 910.0000 - tn: 8018.0000 - fn: 2661.0000 - accuracy: 0.5811 - precision: 0.6646 - recall: 0.4039 - auc: 0.7663 - val_loss: 1.4435 - val_tp: 177.0000 - val_fp: 213.0000 - val_tn: 779.0000 - val_fn: 319.0000 - val_accuracy: 0.4496 - val_precision: 0.4538 - val_recall: 0.3569 - val_auc: 0.6025\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.20685\n",
      "Epoch 215/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8917 - tp: 1887.0000 - fp: 909.0000 - tn: 8019.0000 - fn: 2577.0000 - accuracy: 0.5887 - precision: 0.6749 - recall: 0.4227 - auc: 0.7720 - val_loss: 1.3418 - val_tp: 129.0000 - val_fp: 162.0000 - val_tn: 830.0000 - val_fn: 367.0000 - val_accuracy: 0.4173 - val_precision: 0.4433 - val_recall: 0.2601 - val_auc: 0.5714\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.20685\n",
      "Epoch 216/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8913 - tp: 1844.0000 - fp: 895.0000 - tn: 8033.0000 - fn: 2620.0000 - accuracy: 0.5806 - precision: 0.6732 - recall: 0.4131 - auc: 0.7713 - val_loss: 1.8071 - val_tp: 209.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 287.0000 - val_accuracy: 0.4476 - val_precision: 0.4514 - val_recall: 0.4214 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.20685\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8888 - tp: 1844.0000 - fp: 931.0000 - tn: 7997.0000 - fn: 2620.0000 - accuracy: 0.5889 - precision: 0.6645 - recall: 0.4131 - auc: 0.7728 - val_loss: 1.8593 - val_tp: 217.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 279.0000 - val_accuracy: 0.4577 - val_precision: 0.4637 - val_recall: 0.4375 - val_auc: 0.6184\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.20685\n",
      "Epoch 218/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8836 - tp: 1907.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2557.0000 - accuracy: 0.5901 - precision: 0.6724 - recall: 0.4272 - auc: 0.7753 - val_loss: 1.5820 - val_tp: 169.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 327.0000 - val_accuracy: 0.4032 - val_precision: 0.3967 - val_recall: 0.3407 - val_auc: 0.5610\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1.20685\n",
      "Epoch 219/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8952 - tp: 1815.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2649.0000 - accuracy: 0.5860 - precision: 0.6614 - recall: 0.4066 - auc: 0.7690 - val_loss: 1.5786 - val_tp: 213.0000 - val_fp: 244.0000 - val_tn: 748.0000 - val_fn: 283.0000 - val_accuracy: 0.4657 - val_precision: 0.4661 - val_recall: 0.4294 - val_auc: 0.6082\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.20685\n",
      "Epoch 220/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8888 - tp: 1879.0000 - fp: 901.0000 - tn: 8027.0000 - fn: 2585.0000 - accuracy: 0.5916 - precision: 0.6759 - recall: 0.4209 - auc: 0.7738 - val_loss: 1.3582 - val_tp: 173.0000 - val_fp: 216.0000 - val_tn: 776.0000 - val_fn: 323.0000 - val_accuracy: 0.4214 - val_precision: 0.4447 - val_recall: 0.3488 - val_auc: 0.5935\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1.20685\n",
      "Epoch 221/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8796 - tp: 1897.0000 - fp: 897.0000 - tn: 8031.0000 - fn: 2567.0000 - accuracy: 0.6001 - precision: 0.6790 - recall: 0.4250 - auc: 0.7789 - val_loss: 1.5369 - val_tp: 191.0000 - val_fp: 230.0000 - val_tn: 762.0000 - val_fn: 305.0000 - val_accuracy: 0.4496 - val_precision: 0.4537 - val_recall: 0.3851 - val_auc: 0.5988\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1.20685\n",
      "Epoch 222/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8721 - tp: 1903.0000 - fp: 878.0000 - tn: 8050.0000 - fn: 2561.0000 - accuracy: 0.5909 - precision: 0.6843 - recall: 0.4263 - auc: 0.7811 - val_loss: 2.0272 - val_tp: 184.0000 - val_fp: 297.0000 - val_tn: 695.0000 - val_fn: 312.0000 - val_accuracy: 0.3790 - val_precision: 0.3825 - val_recall: 0.3710 - val_auc: 0.5644\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.20685\n",
      "Epoch 223/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8884 - tp: 1868.0000 - fp: 919.0000 - tn: 8009.0000 - fn: 2596.0000 - accuracy: 0.5869 - precision: 0.6703 - recall: 0.4185 - auc: 0.7710 - val_loss: 1.6698 - val_tp: 180.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 316.0000 - val_accuracy: 0.3911 - val_precision: 0.3991 - val_recall: 0.3629 - val_auc: 0.5672\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1.20685\n",
      "Epoch 224/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8901 - tp: 1898.0000 - fp: 940.0000 - tn: 7988.0000 - fn: 2566.0000 - accuracy: 0.5851 - precision: 0.6688 - recall: 0.4252 - auc: 0.7712 - val_loss: 1.5957 - val_tp: 135.0000 - val_fp: 209.0000 - val_tn: 783.0000 - val_fn: 361.0000 - val_accuracy: 0.3690 - val_precision: 0.3924 - val_recall: 0.2722 - val_auc: 0.5138\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1.20685\n",
      "Epoch 225/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8877 - tp: 1876.0000 - fp: 904.0000 - tn: 8024.0000 - fn: 2588.0000 - accuracy: 0.5836 - precision: 0.6748 - recall: 0.4203 - auc: 0.7728 - val_loss: 1.6256 - val_tp: 204.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 292.0000 - val_accuracy: 0.4254 - val_precision: 0.4387 - val_recall: 0.4113 - val_auc: 0.6056\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1.20685\n",
      "Epoch 226/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8814 - tp: 1922.0000 - fp: 921.0000 - tn: 8007.0000 - fn: 2542.0000 - accuracy: 0.5941 - precision: 0.6760 - recall: 0.4306 - auc: 0.7774 - val_loss: 1.9864 - val_tp: 190.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 306.0000 - val_accuracy: 0.4214 - val_precision: 0.4194 - val_recall: 0.3831 - val_auc: 0.5713\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1.20685\n",
      "Epoch 227/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8736 - tp: 1894.0000 - fp: 906.0000 - tn: 8022.0000 - fn: 2570.0000 - accuracy: 0.5990 - precision: 0.6764 - recall: 0.4243 - auc: 0.7816 - val_loss: 2.0060 - val_tp: 212.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 284.0000 - val_accuracy: 0.4456 - val_precision: 0.4549 - val_recall: 0.4274 - val_auc: 0.6100\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1.20685\n",
      "Epoch 228/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8744 - tp: 1929.0000 - fp: 867.0000 - tn: 8061.0000 - fn: 2535.0000 - accuracy: 0.5988 - precision: 0.6899 - recall: 0.4321 - auc: 0.7823 - val_loss: 1.7593 - val_tp: 181.0000 - val_fp: 289.0000 - val_tn: 703.0000 - val_fn: 315.0000 - val_accuracy: 0.3931 - val_precision: 0.3851 - val_recall: 0.3649 - val_auc: 0.5530\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1.20685\n",
      "Epoch 229/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8762 - tp: 1898.0000 - fp: 907.0000 - tn: 8021.0000 - fn: 2566.0000 - accuracy: 0.5889 - precision: 0.6766 - recall: 0.4252 - auc: 0.7793 - val_loss: 1.6681 - val_tp: 208.0000 - val_fp: 248.0000 - val_tn: 744.0000 - val_fn: 288.0000 - val_accuracy: 0.4536 - val_precision: 0.4561 - val_recall: 0.4194 - val_auc: 0.6152\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1.20685\n",
      "Epoch 230/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8810 - tp: 1982.0000 - fp: 966.0000 - tn: 7962.0000 - fn: 2482.0000 - accuracy: 0.5934 - precision: 0.6723 - recall: 0.4440 - auc: 0.7781 - val_loss: 1.7193 - val_tp: 191.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 305.0000 - val_accuracy: 0.4173 - val_precision: 0.4170 - val_recall: 0.3851 - val_auc: 0.5669\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.20685\n",
      "Epoch 231/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8829 - tp: 1931.0000 - fp: 907.0000 - tn: 8021.0000 - fn: 2533.0000 - accuracy: 0.5966 - precision: 0.6804 - recall: 0.4326 - auc: 0.7755 - val_loss: 1.6279 - val_tp: 181.0000 - val_fp: 286.0000 - val_tn: 706.0000 - val_fn: 315.0000 - val_accuracy: 0.3831 - val_precision: 0.3876 - val_recall: 0.3649 - val_auc: 0.5756\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.20685\n",
      "Epoch 232/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.9028 - tp: 1816.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2648.0000 - accuracy: 0.5759 - precision: 0.6532 - recall: 0.4068 - auc: 0.7627 - val_loss: 2.1948 - val_tp: 228.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 268.0000 - val_accuracy: 0.4798 - val_precision: 0.4760 - val_recall: 0.4597 - val_auc: 0.6155\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.20685\n",
      "Epoch 233/500\n",
      "4464/4464 [==============================] - 0s 83us/step - loss: 0.8855 - tp: 1870.0000 - fp: 928.0000 - tn: 8000.0000 - fn: 2594.0000 - accuracy: 0.5943 - precision: 0.6683 - recall: 0.4189 - auc: 0.7753 - val_loss: 1.7587 - val_tp: 195.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 301.0000 - val_accuracy: 0.4254 - val_precision: 0.4382 - val_recall: 0.3931 - val_auc: 0.6045\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.20685\n",
      "Epoch 234/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8830 - tp: 1917.0000 - fp: 916.0000 - tn: 8012.0000 - fn: 2547.0000 - accuracy: 0.5954 - precision: 0.6767 - recall: 0.4294 - auc: 0.7769 - val_loss: 2.1092 - val_tp: 201.0000 - val_fp: 281.0000 - val_tn: 711.0000 - val_fn: 295.0000 - val_accuracy: 0.4153 - val_precision: 0.4170 - val_recall: 0.4052 - val_auc: 0.5867\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1.20685\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 77us/step - loss: 0.8860 - tp: 1878.0000 - fp: 909.0000 - tn: 8019.0000 - fn: 2586.0000 - accuracy: 0.5869 - precision: 0.6738 - recall: 0.4207 - auc: 0.7739 - val_loss: 1.7196 - val_tp: 196.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 300.0000 - val_accuracy: 0.4315 - val_precision: 0.4224 - val_recall: 0.3952 - val_auc: 0.5726\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1.20685\n",
      "Epoch 236/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.8852 - tp: 1895.0000 - fp: 931.0000 - tn: 7997.0000 - fn: 2569.0000 - accuracy: 0.5878 - precision: 0.6706 - recall: 0.4245 - auc: 0.7752 - val_loss: 1.7430 - val_tp: 187.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 309.0000 - val_accuracy: 0.4052 - val_precision: 0.4083 - val_recall: 0.3770 - val_auc: 0.5840\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1.20685\n",
      "Epoch 237/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8737 - tp: 1946.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2518.0000 - accuracy: 0.5880 - precision: 0.6776 - recall: 0.4359 - auc: 0.7793 - val_loss: 1.8180 - val_tp: 206.0000 - val_fp: 265.0000 - val_tn: 727.0000 - val_fn: 290.0000 - val_accuracy: 0.4355 - val_precision: 0.4374 - val_recall: 0.4153 - val_auc: 0.6016\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1.20685\n",
      "Epoch 238/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8745 - tp: 1923.0000 - fp: 889.0000 - tn: 8039.0000 - fn: 2541.0000 - accuracy: 0.6028 - precision: 0.6839 - recall: 0.4308 - auc: 0.7824 - val_loss: 1.5915 - val_tp: 202.0000 - val_fp: 247.0000 - val_tn: 745.0000 - val_fn: 294.0000 - val_accuracy: 0.4435 - val_precision: 0.4499 - val_recall: 0.4073 - val_auc: 0.5910\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1.20685\n",
      "Epoch 239/500\n",
      "4464/4464 [==============================] - 0s 74us/step - loss: 0.8704 - tp: 1950.0000 - fp: 928.0000 - tn: 8000.0000 - fn: 2514.0000 - accuracy: 0.5979 - precision: 0.6776 - recall: 0.4368 - auc: 0.7835 - val_loss: 1.6736 - val_tp: 191.0000 - val_fp: 248.0000 - val_tn: 744.0000 - val_fn: 305.0000 - val_accuracy: 0.4476 - val_precision: 0.4351 - val_recall: 0.3851 - val_auc: 0.5960\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1.20685\n",
      "Epoch 240/500\n",
      "4464/4464 [==============================] - 0s 83us/step - loss: 0.8837 - tp: 1866.0000 - fp: 893.0000 - tn: 8035.0000 - fn: 2598.0000 - accuracy: 0.5889 - precision: 0.6763 - recall: 0.4180 - auc: 0.7753 - val_loss: 1.6470 - val_tp: 182.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 314.0000 - val_accuracy: 0.4113 - val_precision: 0.4203 - val_recall: 0.3669 - val_auc: 0.5709\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1.20685\n",
      "Epoch 241/500\n",
      "4464/4464 [==============================] - 0s 75us/step - loss: 0.8852 - tp: 1872.0000 - fp: 969.0000 - tn: 7959.0000 - fn: 2592.0000 - accuracy: 0.5880 - precision: 0.6589 - recall: 0.4194 - auc: 0.7725 - val_loss: 1.7676 - val_tp: 189.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 307.0000 - val_accuracy: 0.4335 - val_precision: 0.4447 - val_recall: 0.3810 - val_auc: 0.6043\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1.20685\n",
      "Epoch 242/500\n",
      "4464/4464 [==============================] - 0s 82us/step - loss: 0.8783 - tp: 1942.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2522.0000 - accuracy: 0.5860 - precision: 0.6755 - recall: 0.4350 - auc: 0.7775 - val_loss: 1.5207 - val_tp: 195.0000 - val_fp: 222.0000 - val_tn: 770.0000 - val_fn: 301.0000 - val_accuracy: 0.4577 - val_precision: 0.4676 - val_recall: 0.3931 - val_auc: 0.6154\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1.20685\n",
      "Epoch 243/500\n",
      "4464/4464 [==============================] - 0s 76us/step - loss: 0.8783 - tp: 1927.0000 - fp: 925.0000 - tn: 8003.0000 - fn: 2537.0000 - accuracy: 0.5952 - precision: 0.6757 - recall: 0.4317 - auc: 0.7794 - val_loss: 1.8804 - val_tp: 198.0000 - val_fp: 285.0000 - val_tn: 707.0000 - val_fn: 298.0000 - val_accuracy: 0.4153 - val_precision: 0.4099 - val_recall: 0.3992 - val_auc: 0.5737\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1.20685\n",
      "Epoch 244/500\n",
      "4464/4464 [==============================] - 0s 78us/step - loss: 0.8771 - tp: 1966.0000 - fp: 940.0000 - tn: 7988.0000 - fn: 2498.0000 - accuracy: 0.5988 - precision: 0.6765 - recall: 0.4404 - auc: 0.7800 - val_loss: 1.5516 - val_tp: 184.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 312.0000 - val_accuracy: 0.4315 - val_precision: 0.4381 - val_recall: 0.3710 - val_auc: 0.5802\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1.20685\n",
      "Epoch 245/500\n",
      "4464/4464 [==============================] - 0s 76us/step - loss: 0.8805 - tp: 1904.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2560.0000 - accuracy: 0.5901 - precision: 0.6711 - recall: 0.4265 - auc: 0.7771 - val_loss: 1.4161 - val_tp: 175.0000 - val_fp: 194.0000 - val_tn: 798.0000 - val_fn: 321.0000 - val_accuracy: 0.4597 - val_precision: 0.4743 - val_recall: 0.3528 - val_auc: 0.6089\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.20685\n",
      "Epoch 246/500\n",
      "4464/4464 [==============================] - 0s 78us/step - loss: 0.8755 - tp: 1912.0000 - fp: 925.0000 - tn: 8003.0000 - fn: 2552.0000 - accuracy: 0.5894 - precision: 0.6740 - recall: 0.4283 - auc: 0.7791 - val_loss: 1.7898 - val_tp: 152.0000 - val_fp: 302.0000 - val_tn: 690.0000 - val_fn: 344.0000 - val_accuracy: 0.3246 - val_precision: 0.3348 - val_recall: 0.3065 - val_auc: 0.5142\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.20685\n",
      "Epoch 247/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8763 - tp: 1872.0000 - fp: 882.0000 - tn: 8046.0000 - fn: 2592.0000 - accuracy: 0.5923 - precision: 0.6797 - recall: 0.4194 - auc: 0.7817 - val_loss: 1.9310 - val_tp: 203.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 293.0000 - val_accuracy: 0.4375 - val_precision: 0.4394 - val_recall: 0.4093 - val_auc: 0.5984\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.20685\n",
      "Epoch 248/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8780 - tp: 1923.0000 - fp: 938.0000 - tn: 7990.0000 - fn: 2541.0000 - accuracy: 0.5950 - precision: 0.6721 - recall: 0.4308 - auc: 0.7806 - val_loss: 1.4602 - val_tp: 200.0000 - val_fp: 212.0000 - val_tn: 780.0000 - val_fn: 296.0000 - val_accuracy: 0.4556 - val_precision: 0.4854 - val_recall: 0.4032 - val_auc: 0.6181\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.20685\n",
      "Epoch 249/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8748 - tp: 1982.0000 - fp: 910.0000 - tn: 8018.0000 - fn: 2482.0000 - accuracy: 0.6019 - precision: 0.6853 - recall: 0.4440 - auc: 0.7828 - val_loss: 1.8604 - val_tp: 200.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 296.0000 - val_accuracy: 0.4153 - val_precision: 0.4211 - val_recall: 0.4032 - val_auc: 0.5956\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.20685\n",
      "Epoch 250/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8590 - tp: 2030.0000 - fp: 902.0000 - tn: 8026.0000 - fn: 2434.0000 - accuracy: 0.6080 - precision: 0.6924 - recall: 0.4547 - auc: 0.7906 - val_loss: 1.6938 - val_tp: 220.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 276.0000 - val_accuracy: 0.4577 - val_precision: 0.4651 - val_recall: 0.4435 - val_auc: 0.6197\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1.20685\n",
      "Epoch 251/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8619 - tp: 2020.0000 - fp: 902.0000 - tn: 8026.0000 - fn: 2444.0000 - accuracy: 0.6060 - precision: 0.6913 - recall: 0.4525 - auc: 0.7902 - val_loss: 2.4888 - val_tp: 208.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 288.0000 - val_accuracy: 0.4294 - val_precision: 0.4262 - val_recall: 0.4194 - val_auc: 0.6034\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1.20685\n",
      "Epoch 252/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8706 - tp: 1966.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2498.0000 - accuracy: 0.6022 - precision: 0.6710 - recall: 0.4404 - auc: 0.7834 - val_loss: 2.1413 - val_tp: 220.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 276.0000 - val_accuracy: 0.4577 - val_precision: 0.4612 - val_recall: 0.4435 - val_auc: 0.6132\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1.20685\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8836 - tp: 1879.0000 - fp: 917.0000 - tn: 8011.0000 - fn: 2585.0000 - accuracy: 0.5883 - precision: 0.6720 - recall: 0.4209 - auc: 0.7756 - val_loss: 1.8488 - val_tp: 204.0000 - val_fp: 276.0000 - val_tn: 716.0000 - val_fn: 292.0000 - val_accuracy: 0.4254 - val_precision: 0.4250 - val_recall: 0.4113 - val_auc: 0.5872\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.20685\n",
      "Epoch 254/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8723 - tp: 1935.0000 - fp: 873.0000 - tn: 8055.0000 - fn: 2529.0000 - accuracy: 0.5972 - precision: 0.6891 - recall: 0.4335 - auc: 0.7808 - val_loss: 1.5272 - val_tp: 171.0000 - val_fp: 230.0000 - val_tn: 762.0000 - val_fn: 325.0000 - val_accuracy: 0.4375 - val_precision: 0.4264 - val_recall: 0.3448 - val_auc: 0.5734\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.20685\n",
      "Epoch 255/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8826 - tp: 1944.0000 - fp: 984.0000 - tn: 7944.0000 - fn: 2520.0000 - accuracy: 0.5952 - precision: 0.6639 - recall: 0.4355 - auc: 0.7757 - val_loss: 1.8026 - val_tp: 201.0000 - val_fp: 279.0000 - val_tn: 713.0000 - val_fn: 295.0000 - val_accuracy: 0.4093 - val_precision: 0.4187 - val_recall: 0.4052 - val_auc: 0.5780\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.20685\n",
      "Epoch 256/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8766 - tp: 1916.0000 - fp: 924.0000 - tn: 8004.0000 - fn: 2548.0000 - accuracy: 0.6015 - precision: 0.6746 - recall: 0.4292 - auc: 0.7803 - val_loss: 1.7519 - val_tp: 230.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 266.0000 - val_accuracy: 0.4738 - val_precision: 0.4782 - val_recall: 0.4637 - val_auc: 0.6260\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1.20685\n",
      "Epoch 257/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8721 - tp: 1969.0000 - fp: 949.0000 - tn: 7979.0000 - fn: 2495.0000 - accuracy: 0.5932 - precision: 0.6748 - recall: 0.4411 - auc: 0.7814 - val_loss: 1.6301 - val_tp: 189.0000 - val_fp: 279.0000 - val_tn: 713.0000 - val_fn: 307.0000 - val_accuracy: 0.4012 - val_precision: 0.4038 - val_recall: 0.3810 - val_auc: 0.5597\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1.20685\n",
      "Epoch 258/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8701 - tp: 1972.0000 - fp: 916.0000 - tn: 8012.0000 - fn: 2492.0000 - accuracy: 0.6111 - precision: 0.6828 - recall: 0.4418 - auc: 0.7839 - val_loss: 1.9426 - val_tp: 228.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 268.0000 - val_accuracy: 0.4657 - val_precision: 0.4672 - val_recall: 0.4597 - val_auc: 0.6095\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1.20685\n",
      "Epoch 259/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8914 - tp: 1902.0000 - fp: 1004.0000 - tn: 7924.0000 - fn: 2562.0000 - accuracy: 0.5791 - precision: 0.6545 - recall: 0.4261 - auc: 0.7704 - val_loss: 1.4344 - val_tp: 110.0000 - val_fp: 198.0000 - val_tn: 794.0000 - val_fn: 386.0000 - val_accuracy: 0.3710 - val_precision: 0.3571 - val_recall: 0.2218 - val_auc: 0.5339\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.20685\n",
      "Epoch 260/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8682 - tp: 1965.0000 - fp: 905.0000 - tn: 8023.0000 - fn: 2499.0000 - accuracy: 0.5986 - precision: 0.6847 - recall: 0.4402 - auc: 0.7853 - val_loss: 1.7229 - val_tp: 217.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 279.0000 - val_accuracy: 0.4556 - val_precision: 0.4568 - val_recall: 0.4375 - val_auc: 0.6186\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1.20685\n",
      "Epoch 261/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8853 - tp: 1937.0000 - fp: 950.0000 - tn: 7978.0000 - fn: 2527.0000 - accuracy: 0.5966 - precision: 0.6709 - recall: 0.4339 - auc: 0.7757 - val_loss: 1.7900 - val_tp: 197.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 299.0000 - val_accuracy: 0.4274 - val_precision: 0.4339 - val_recall: 0.3972 - val_auc: 0.5983\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1.20685\n",
      "Epoch 262/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8773 - tp: 1906.0000 - fp: 921.0000 - tn: 8007.0000 - fn: 2558.0000 - accuracy: 0.5927 - precision: 0.6742 - recall: 0.4270 - auc: 0.7795 - val_loss: 1.4746 - val_tp: 195.0000 - val_fp: 230.0000 - val_tn: 762.0000 - val_fn: 301.0000 - val_accuracy: 0.4435 - val_precision: 0.4588 - val_recall: 0.3931 - val_auc: 0.5864\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.20685\n",
      "Epoch 263/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8796 - tp: 1917.0000 - fp: 917.0000 - tn: 8011.0000 - fn: 2547.0000 - accuracy: 0.5867 - precision: 0.6764 - recall: 0.4294 - auc: 0.7782 - val_loss: 1.6289 - val_tp: 174.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 322.0000 - val_accuracy: 0.3851 - val_precision: 0.3884 - val_recall: 0.3508 - val_auc: 0.5684\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.20685\n",
      "Epoch 264/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8722 - tp: 1938.0000 - fp: 948.0000 - tn: 7980.0000 - fn: 2526.0000 - accuracy: 0.5981 - precision: 0.6715 - recall: 0.4341 - auc: 0.7820 - val_loss: 1.5147 - val_tp: 202.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 294.0000 - val_accuracy: 0.4496 - val_precision: 0.4591 - val_recall: 0.4073 - val_auc: 0.6160\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.20685\n",
      "Epoch 265/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8704 - tp: 1951.0000 - fp: 927.0000 - tn: 8001.0000 - fn: 2513.0000 - accuracy: 0.6004 - precision: 0.6779 - recall: 0.4371 - auc: 0.7830 - val_loss: 2.3320 - val_tp: 197.0000 - val_fp: 291.0000 - val_tn: 701.0000 - val_fn: 299.0000 - val_accuracy: 0.3992 - val_precision: 0.4037 - val_recall: 0.3972 - val_auc: 0.5888\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1.20685\n",
      "Epoch 266/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8743 - tp: 1937.0000 - fp: 919.0000 - tn: 8009.0000 - fn: 2527.0000 - accuracy: 0.5988 - precision: 0.6782 - recall: 0.4339 - auc: 0.7806 - val_loss: 1.6162 - val_tp: 185.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 311.0000 - val_accuracy: 0.4113 - val_precision: 0.4333 - val_recall: 0.3730 - val_auc: 0.5837\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1.20685\n",
      "Epoch 267/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8776 - tp: 1958.0000 - fp: 934.0000 - tn: 7994.0000 - fn: 2506.0000 - accuracy: 0.5970 - precision: 0.6770 - recall: 0.4386 - auc: 0.7798 - val_loss: 2.0939 - val_tp: 212.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 284.0000 - val_accuracy: 0.4516 - val_precision: 0.4482 - val_recall: 0.4274 - val_auc: 0.6099\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1.20685\n",
      "Epoch 268/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8622 - tp: 2000.0000 - fp: 927.0000 - tn: 8001.0000 - fn: 2464.0000 - accuracy: 0.6055 - precision: 0.6833 - recall: 0.4480 - auc: 0.7893 - val_loss: 2.0804 - val_tp: 227.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 269.0000 - val_accuracy: 0.4637 - val_precision: 0.4623 - val_recall: 0.4577 - val_auc: 0.6151\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1.20685\n",
      "Epoch 269/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8676 - tp: 1967.0000 - fp: 881.0000 - tn: 8047.0000 - fn: 2497.0000 - accuracy: 0.6086 - precision: 0.6907 - recall: 0.4406 - auc: 0.7861 - val_loss: 1.6042 - val_tp: 191.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 305.0000 - val_accuracy: 0.4153 - val_precision: 0.4292 - val_recall: 0.3851 - val_auc: 0.5766\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.20685\n",
      "Epoch 270/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8677 - tp: 2016.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2448.0000 - accuracy: 0.6082 - precision: 0.6767 - recall: 0.4516 - auc: 0.7855 - val_loss: 2.2136 - val_tp: 201.0000 - val_fp: 277.0000 - val_tn: 715.0000 - val_fn: 295.0000 - val_accuracy: 0.4133 - val_precision: 0.4205 - val_recall: 0.4052 - val_auc: 0.5862\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.20685\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8637 - tp: 1943.0000 - fp: 886.0000 - tn: 8042.0000 - fn: 2521.0000 - accuracy: 0.6055 - precision: 0.6868 - recall: 0.4353 - auc: 0.7894 - val_loss: 1.8884 - val_tp: 201.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 295.0000 - val_accuracy: 0.4355 - val_precision: 0.4389 - val_recall: 0.4052 - val_auc: 0.5938\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.20685\n",
      "Epoch 272/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8781 - tp: 2002.0000 - fp: 970.0000 - tn: 7958.0000 - fn: 2462.0000 - accuracy: 0.5918 - precision: 0.6736 - recall: 0.4485 - auc: 0.7787 - val_loss: 1.9458 - val_tp: 213.0000 - val_fp: 266.0000 - val_tn: 726.0000 - val_fn: 283.0000 - val_accuracy: 0.4435 - val_precision: 0.4447 - val_recall: 0.4294 - val_auc: 0.5927\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.20685\n",
      "Epoch 273/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8878 - tp: 1935.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2529.0000 - accuracy: 0.5952 - precision: 0.6747 - recall: 0.4335 - auc: 0.7734 - val_loss: 2.1704 - val_tp: 186.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 310.0000 - val_accuracy: 0.3992 - val_precision: 0.4009 - val_recall: 0.3750 - val_auc: 0.5874\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1.20685\n",
      "Epoch 274/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8778 - tp: 1916.0000 - fp: 954.0000 - tn: 7974.0000 - fn: 2548.0000 - accuracy: 0.6006 - precision: 0.6676 - recall: 0.4292 - auc: 0.7799 - val_loss: 1.4435 - val_tp: 180.0000 - val_fp: 200.0000 - val_tn: 792.0000 - val_fn: 316.0000 - val_accuracy: 0.4516 - val_precision: 0.4737 - val_recall: 0.3629 - val_auc: 0.6056\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1.20685\n",
      "Epoch 275/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8628 - tp: 1974.0000 - fp: 915.0000 - tn: 8013.0000 - fn: 2490.0000 - accuracy: 0.6098 - precision: 0.6833 - recall: 0.4422 - auc: 0.7881 - val_loss: 1.8697 - val_tp: 200.0000 - val_fp: 244.0000 - val_tn: 748.0000 - val_fn: 296.0000 - val_accuracy: 0.4435 - val_precision: 0.4505 - val_recall: 0.4032 - val_auc: 0.6084\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1.20685\n",
      "Epoch 276/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8674 - tp: 1994.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2470.0000 - accuracy: 0.6062 - precision: 0.6766 - recall: 0.4467 - auc: 0.7845 - val_loss: 1.4196 - val_tp: 163.0000 - val_fp: 188.0000 - val_tn: 804.0000 - val_fn: 333.0000 - val_accuracy: 0.4294 - val_precision: 0.4644 - val_recall: 0.3286 - val_auc: 0.5909\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1.20685\n",
      "Epoch 277/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8684 - tp: 1982.0000 - fp: 894.0000 - tn: 8034.0000 - fn: 2482.0000 - accuracy: 0.5974 - precision: 0.6892 - recall: 0.4440 - auc: 0.7841 - val_loss: 2.3301 - val_tp: 208.0000 - val_fp: 281.0000 - val_tn: 711.0000 - val_fn: 288.0000 - val_accuracy: 0.4214 - val_precision: 0.4254 - val_recall: 0.4194 - val_auc: 0.5952\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1.20685\n",
      "Epoch 278/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8668 - tp: 2027.0000 - fp: 935.0000 - tn: 7993.0000 - fn: 2437.0000 - accuracy: 0.6055 - precision: 0.6843 - recall: 0.4541 - auc: 0.7868 - val_loss: 2.1866 - val_tp: 228.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 268.0000 - val_accuracy: 0.4617 - val_precision: 0.4663 - val_recall: 0.4597 - val_auc: 0.6204\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1.20685\n",
      "Epoch 279/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8757 - tp: 1975.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2489.0000 - accuracy: 0.5948 - precision: 0.6702 - recall: 0.4424 - auc: 0.7802 - val_loss: 1.9403 - val_tp: 172.0000 - val_fp: 279.0000 - val_tn: 713.0000 - val_fn: 324.0000 - val_accuracy: 0.3770 - val_precision: 0.3814 - val_recall: 0.3468 - val_auc: 0.5535\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1.20685\n",
      "Epoch 280/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8716 - tp: 1966.0000 - fp: 946.0000 - tn: 7982.0000 - fn: 2498.0000 - accuracy: 0.6017 - precision: 0.6751 - recall: 0.4404 - auc: 0.7828 - val_loss: 1.7931 - val_tp: 193.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 303.0000 - val_accuracy: 0.4415 - val_precision: 0.4357 - val_recall: 0.3891 - val_auc: 0.5997\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1.20685\n",
      "Epoch 281/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8744 - tp: 1984.0000 - fp: 913.0000 - tn: 8015.0000 - fn: 2480.0000 - accuracy: 0.5966 - precision: 0.6848 - recall: 0.4444 - auc: 0.7822 - val_loss: 2.0949 - val_tp: 197.0000 - val_fp: 290.0000 - val_tn: 702.0000 - val_fn: 299.0000 - val_accuracy: 0.4012 - val_precision: 0.4045 - val_recall: 0.3972 - val_auc: 0.5888\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1.20685\n",
      "Epoch 282/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8564 - tp: 2092.0000 - fp: 925.0000 - tn: 8003.0000 - fn: 2372.0000 - accuracy: 0.6176 - precision: 0.6934 - recall: 0.4686 - auc: 0.7930 - val_loss: 2.1566 - val_tp: 191.0000 - val_fp: 291.0000 - val_tn: 701.0000 - val_fn: 305.0000 - val_accuracy: 0.3911 - val_precision: 0.3963 - val_recall: 0.3851 - val_auc: 0.5703\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1.20685\n",
      "Epoch 283/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8740 - tp: 1961.0000 - fp: 968.0000 - tn: 7960.0000 - fn: 2503.0000 - accuracy: 0.5943 - precision: 0.6695 - recall: 0.4393 - auc: 0.7809 - val_loss: 1.8553 - val_tp: 168.0000 - val_fp: 310.0000 - val_tn: 682.0000 - val_fn: 328.0000 - val_accuracy: 0.3488 - val_precision: 0.3515 - val_recall: 0.3387 - val_auc: 0.5607\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1.20685\n",
      "Epoch 284/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8773 - tp: 1950.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2514.0000 - accuracy: 0.6004 - precision: 0.6773 - recall: 0.4368 - auc: 0.7805 - val_loss: 1.7827 - val_tp: 197.0000 - val_fp: 279.0000 - val_tn: 713.0000 - val_fn: 299.0000 - val_accuracy: 0.4153 - val_precision: 0.4139 - val_recall: 0.3972 - val_auc: 0.5861\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1.20685\n",
      "Epoch 285/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8675 - tp: 1960.0000 - fp: 927.0000 - tn: 8001.0000 - fn: 2504.0000 - accuracy: 0.5939 - precision: 0.6789 - recall: 0.4391 - auc: 0.7849 - val_loss: 2.0373 - val_tp: 185.0000 - val_fp: 292.0000 - val_tn: 700.0000 - val_fn: 311.0000 - val_accuracy: 0.3871 - val_precision: 0.3878 - val_recall: 0.3730 - val_auc: 0.5750\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1.20685\n",
      "Epoch 286/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8765 - tp: 1960.0000 - fp: 920.0000 - tn: 8008.0000 - fn: 2504.0000 - accuracy: 0.5923 - precision: 0.6806 - recall: 0.4391 - auc: 0.7802 - val_loss: 2.2701 - val_tp: 185.0000 - val_fp: 297.0000 - val_tn: 695.0000 - val_fn: 311.0000 - val_accuracy: 0.3851 - val_precision: 0.3838 - val_recall: 0.3730 - val_auc: 0.5786\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1.20685\n",
      "Epoch 287/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8531 - tp: 2034.0000 - fp: 896.0000 - tn: 8032.0000 - fn: 2430.0000 - accuracy: 0.6116 - precision: 0.6942 - recall: 0.4556 - auc: 0.7961 - val_loss: 1.5379 - val_tp: 191.0000 - val_fp: 226.0000 - val_tn: 766.0000 - val_fn: 305.0000 - val_accuracy: 0.4456 - val_precision: 0.4580 - val_recall: 0.3851 - val_auc: 0.5967\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1.20685\n",
      "Epoch 288/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8570 - tp: 2032.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2432.0000 - accuracy: 0.6042 - precision: 0.6780 - recall: 0.4552 - auc: 0.7900 - val_loss: 1.8768 - val_tp: 209.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 287.0000 - val_accuracy: 0.4375 - val_precision: 0.4354 - val_recall: 0.4214 - val_auc: 0.6101\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1.20685\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8690 - tp: 2002.0000 - fp: 966.0000 - tn: 7962.0000 - fn: 2462.0000 - accuracy: 0.5972 - precision: 0.6745 - recall: 0.4485 - auc: 0.7838 - val_loss: 1.7877 - val_tp: 214.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 282.0000 - val_accuracy: 0.4395 - val_precision: 0.4496 - val_recall: 0.4315 - val_auc: 0.6021\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1.20685\n",
      "Epoch 290/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8633 - tp: 1990.0000 - fp: 943.0000 - tn: 7985.0000 - fn: 2474.0000 - accuracy: 0.6044 - precision: 0.6785 - recall: 0.4458 - auc: 0.7881 - val_loss: 2.3325 - val_tp: 205.0000 - val_fp: 287.0000 - val_tn: 705.0000 - val_fn: 291.0000 - val_accuracy: 0.4173 - val_precision: 0.4167 - val_recall: 0.4133 - val_auc: 0.5928\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1.20685\n",
      "Epoch 291/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8651 - tp: 1985.0000 - fp: 942.0000 - tn: 7986.0000 - fn: 2479.0000 - accuracy: 0.6057 - precision: 0.6782 - recall: 0.4447 - auc: 0.7858 - val_loss: 1.7464 - val_tp: 221.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 275.0000 - val_accuracy: 0.4698 - val_precision: 0.4763 - val_recall: 0.4456 - val_auc: 0.6280\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1.20685\n",
      "Epoch 292/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8661 - tp: 2024.0000 - fp: 951.0000 - tn: 7977.0000 - fn: 2440.0000 - accuracy: 0.5990 - precision: 0.6803 - recall: 0.4534 - auc: 0.7855 - val_loss: 1.9443 - val_tp: 174.0000 - val_fp: 284.0000 - val_tn: 708.0000 - val_fn: 322.0000 - val_accuracy: 0.3669 - val_precision: 0.3799 - val_recall: 0.3508 - val_auc: 0.5421\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1.20685\n",
      "Epoch 293/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8569 - tp: 2046.0000 - fp: 946.0000 - tn: 7982.0000 - fn: 2418.0000 - accuracy: 0.6064 - precision: 0.6838 - recall: 0.4583 - auc: 0.7905 - val_loss: 1.9046 - val_tp: 218.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 278.0000 - val_accuracy: 0.4415 - val_precision: 0.4561 - val_recall: 0.4395 - val_auc: 0.6152\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1.20685\n",
      "Epoch 294/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8497 - tp: 2104.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2360.0000 - accuracy: 0.6084 - precision: 0.6867 - recall: 0.4713 - auc: 0.7949 - val_loss: 2.2701 - val_tp: 200.0000 - val_fp: 283.0000 - val_tn: 709.0000 - val_fn: 296.0000 - val_accuracy: 0.4153 - val_precision: 0.4141 - val_recall: 0.4032 - val_auc: 0.5772\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1.20685\n",
      "Epoch 295/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8590 - tp: 2061.0000 - fp: 944.0000 - tn: 7984.0000 - fn: 2403.0000 - accuracy: 0.6122 - precision: 0.6859 - recall: 0.4617 - auc: 0.7923 - val_loss: 1.9800 - val_tp: 203.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 293.0000 - val_accuracy: 0.4214 - val_precision: 0.4247 - val_recall: 0.4093 - val_auc: 0.5977\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1.20685\n",
      "Epoch 296/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8582 - tp: 2024.0000 - fp: 945.0000 - tn: 7983.0000 - fn: 2440.0000 - accuracy: 0.6073 - precision: 0.6817 - recall: 0.4534 - auc: 0.7919 - val_loss: 1.9050 - val_tp: 194.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 302.0000 - val_accuracy: 0.4113 - val_precision: 0.4163 - val_recall: 0.3911 - val_auc: 0.5890\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1.20685\n",
      "Epoch 297/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8649 - tp: 2050.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2414.0000 - accuracy: 0.6006 - precision: 0.6781 - recall: 0.4592 - auc: 0.7859 - val_loss: 1.8508 - val_tp: 168.0000 - val_fp: 286.0000 - val_tn: 706.0000 - val_fn: 328.0000 - val_accuracy: 0.3750 - val_precision: 0.3700 - val_recall: 0.3387 - val_auc: 0.5562\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1.20685\n",
      "Epoch 298/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8635 - tp: 2021.0000 - fp: 903.0000 - tn: 8025.0000 - fn: 2443.0000 - accuracy: 0.6042 - precision: 0.6912 - recall: 0.4527 - auc: 0.7889 - val_loss: 1.8805 - val_tp: 201.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 295.0000 - val_accuracy: 0.4274 - val_precision: 0.4332 - val_recall: 0.4052 - val_auc: 0.5987\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1.20685\n",
      "Epoch 299/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8599 - tp: 2083.0000 - fp: 942.0000 - tn: 7986.0000 - fn: 2381.0000 - accuracy: 0.6089 - precision: 0.6886 - recall: 0.4666 - auc: 0.7904 - val_loss: 1.9106 - val_tp: 202.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 294.0000 - val_accuracy: 0.4194 - val_precision: 0.4235 - val_recall: 0.4073 - val_auc: 0.5866\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1.20685\n",
      "Epoch 300/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8602 - tp: 2081.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2383.0000 - accuracy: 0.6026 - precision: 0.6816 - recall: 0.4662 - auc: 0.7888 - val_loss: 1.4580 - val_tp: 183.0000 - val_fp: 232.0000 - val_tn: 760.0000 - val_fn: 313.0000 - val_accuracy: 0.4274 - val_precision: 0.4410 - val_recall: 0.3690 - val_auc: 0.5980\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1.20685\n",
      "Epoch 301/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8594 - tp: 2047.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2417.0000 - accuracy: 0.6057 - precision: 0.6823 - recall: 0.4586 - auc: 0.7909 - val_loss: 2.6603 - val_tp: 178.0000 - val_fp: 308.0000 - val_tn: 684.0000 - val_fn: 318.0000 - val_accuracy: 0.3690 - val_precision: 0.3663 - val_recall: 0.3589 - val_auc: 0.5540\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 1.20685\n",
      "Epoch 302/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8594 - tp: 2028.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2436.0000 - accuracy: 0.6026 - precision: 0.6865 - recall: 0.4543 - auc: 0.7901 - val_loss: 1.5490 - val_tp: 191.0000 - val_fp: 228.0000 - val_tn: 764.0000 - val_fn: 305.0000 - val_accuracy: 0.4274 - val_precision: 0.4558 - val_recall: 0.3851 - val_auc: 0.5840\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1.20685\n",
      "Epoch 303/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8672 - tp: 2027.0000 - fp: 948.0000 - tn: 7980.0000 - fn: 2437.0000 - accuracy: 0.6010 - precision: 0.6813 - recall: 0.4541 - auc: 0.7847 - val_loss: 2.2661 - val_tp: 191.0000 - val_fp: 293.0000 - val_tn: 699.0000 - val_fn: 305.0000 - val_accuracy: 0.3972 - val_precision: 0.3946 - val_recall: 0.3851 - val_auc: 0.5664\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1.20685\n",
      "Epoch 304/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8555 - tp: 2062.0000 - fp: 911.0000 - tn: 8017.0000 - fn: 2402.0000 - accuracy: 0.6073 - precision: 0.6936 - recall: 0.4619 - auc: 0.7926 - val_loss: 2.6199 - val_tp: 152.0000 - val_fp: 324.0000 - val_tn: 668.0000 - val_fn: 344.0000 - val_accuracy: 0.3145 - val_precision: 0.3193 - val_recall: 0.3065 - val_auc: 0.4966\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1.20685\n",
      "Epoch 305/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8662 - tp: 2011.0000 - fp: 962.0000 - tn: 7966.0000 - fn: 2453.0000 - accuracy: 0.6026 - precision: 0.6764 - recall: 0.4505 - auc: 0.7870 - val_loss: 1.9139 - val_tp: 205.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 291.0000 - val_accuracy: 0.4274 - val_precision: 0.4316 - val_recall: 0.4133 - val_auc: 0.5910\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1.20685\n",
      "Epoch 306/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8602 - tp: 2005.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2459.0000 - accuracy: 0.6066 - precision: 0.6753 - recall: 0.4491 - auc: 0.7882 - val_loss: 1.6664 - val_tp: 215.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 281.0000 - val_accuracy: 0.4456 - val_precision: 0.4555 - val_recall: 0.4335 - val_auc: 0.6089\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1.20685\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8502 - tp: 2083.0000 - fp: 915.0000 - tn: 8013.0000 - fn: 2381.0000 - accuracy: 0.6138 - precision: 0.6948 - recall: 0.4666 - auc: 0.7960 - val_loss: 1.9121 - val_tp: 173.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 323.0000 - val_accuracy: 0.4153 - val_precision: 0.4071 - val_recall: 0.3488 - val_auc: 0.5454\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1.20685\n",
      "Epoch 308/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8521 - tp: 2035.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2429.0000 - accuracy: 0.6042 - precision: 0.6795 - recall: 0.4559 - auc: 0.7926 - val_loss: 2.2565 - val_tp: 208.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 288.0000 - val_accuracy: 0.4234 - val_precision: 0.4262 - val_recall: 0.4194 - val_auc: 0.5783\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1.20685\n",
      "Epoch 309/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8558 - tp: 2050.0000 - fp: 970.0000 - tn: 7958.0000 - fn: 2414.0000 - accuracy: 0.6048 - precision: 0.6788 - recall: 0.4592 - auc: 0.7908 - val_loss: 1.6693 - val_tp: 169.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 327.0000 - val_accuracy: 0.4052 - val_precision: 0.4173 - val_recall: 0.3407 - val_auc: 0.5778\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 1.20685\n",
      "Epoch 310/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8500 - tp: 2108.0000 - fp: 927.0000 - tn: 8001.0000 - fn: 2356.0000 - accuracy: 0.6147 - precision: 0.6946 - recall: 0.4722 - auc: 0.7955 - val_loss: 1.8906 - val_tp: 217.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 279.0000 - val_accuracy: 0.4435 - val_precision: 0.4521 - val_recall: 0.4375 - val_auc: 0.6034\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1.20685\n",
      "Epoch 311/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8649 - tp: 2016.0000 - fp: 982.0000 - tn: 7946.0000 - fn: 2448.0000 - accuracy: 0.5970 - precision: 0.6724 - recall: 0.4516 - auc: 0.7862 - val_loss: 2.1067 - val_tp: 188.0000 - val_fp: 293.0000 - val_tn: 699.0000 - val_fn: 308.0000 - val_accuracy: 0.3911 - val_precision: 0.3909 - val_recall: 0.3790 - val_auc: 0.5626\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1.20685\n",
      "Epoch 312/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8473 - tp: 2067.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2397.0000 - accuracy: 0.6107 - precision: 0.6881 - recall: 0.4630 - auc: 0.7960 - val_loss: 1.9013 - val_tp: 176.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 320.0000 - val_accuracy: 0.3831 - val_precision: 0.3911 - val_recall: 0.3548 - val_auc: 0.5638\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1.20685\n",
      "Epoch 313/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8474 - tp: 2057.0000 - fp: 898.0000 - tn: 8030.0000 - fn: 2407.0000 - accuracy: 0.6142 - precision: 0.6961 - recall: 0.4608 - auc: 0.7958 - val_loss: 1.7414 - val_tp: 192.0000 - val_fp: 232.0000 - val_tn: 760.0000 - val_fn: 304.0000 - val_accuracy: 0.4415 - val_precision: 0.4528 - val_recall: 0.3871 - val_auc: 0.5796\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1.20685\n",
      "Epoch 314/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8543 - tp: 2078.0000 - fp: 959.0000 - tn: 7969.0000 - fn: 2386.0000 - accuracy: 0.6080 - precision: 0.6842 - recall: 0.4655 - auc: 0.7922 - val_loss: 2.7970 - val_tp: 192.0000 - val_fp: 299.0000 - val_tn: 693.0000 - val_fn: 304.0000 - val_accuracy: 0.3911 - val_precision: 0.3910 - val_recall: 0.3871 - val_auc: 0.5809\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1.20685\n",
      "Epoch 315/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8644 - tp: 2017.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2447.0000 - accuracy: 0.6057 - precision: 0.6854 - recall: 0.4518 - auc: 0.7866 - val_loss: 1.5810 - val_tp: 187.0000 - val_fp: 228.0000 - val_tn: 764.0000 - val_fn: 309.0000 - val_accuracy: 0.4355 - val_precision: 0.4506 - val_recall: 0.3770 - val_auc: 0.5904\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1.20685\n",
      "Epoch 316/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8545 - tp: 2064.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2400.0000 - accuracy: 0.6190 - precision: 0.6896 - recall: 0.4624 - auc: 0.7953 - val_loss: 1.6950 - val_tp: 213.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 283.0000 - val_accuracy: 0.4435 - val_precision: 0.4484 - val_recall: 0.4294 - val_auc: 0.6019\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1.20685\n",
      "Epoch 317/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8598 - tp: 2053.0000 - fp: 916.0000 - tn: 8012.0000 - fn: 2411.0000 - accuracy: 0.6086 - precision: 0.6915 - recall: 0.4599 - auc: 0.7902 - val_loss: 2.0326 - val_tp: 182.0000 - val_fp: 303.0000 - val_tn: 689.0000 - val_fn: 314.0000 - val_accuracy: 0.3710 - val_precision: 0.3753 - val_recall: 0.3669 - val_auc: 0.5652\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1.20685\n",
      "Epoch 318/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8696 - tp: 2003.0000 - fp: 928.0000 - tn: 8000.0000 - fn: 2461.0000 - accuracy: 0.5979 - precision: 0.6834 - recall: 0.4487 - auc: 0.7836 - val_loss: 1.5838 - val_tp: 192.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 304.0000 - val_accuracy: 0.4355 - val_precision: 0.4424 - val_recall: 0.3871 - val_auc: 0.5879\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1.20685\n",
      "Epoch 319/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8514 - tp: 2086.0000 - fp: 919.0000 - tn: 8009.0000 - fn: 2378.0000 - accuracy: 0.6140 - precision: 0.6942 - recall: 0.4673 - auc: 0.7955 - val_loss: 1.4313 - val_tp: 166.0000 - val_fp: 205.0000 - val_tn: 787.0000 - val_fn: 330.0000 - val_accuracy: 0.4234 - val_precision: 0.4474 - val_recall: 0.3347 - val_auc: 0.5936\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1.20685\n",
      "Epoch 320/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8527 - tp: 2087.0000 - fp: 950.0000 - tn: 7978.0000 - fn: 2377.0000 - accuracy: 0.6190 - precision: 0.6872 - recall: 0.4675 - auc: 0.7939 - val_loss: 1.6455 - val_tp: 179.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 317.0000 - val_accuracy: 0.3851 - val_precision: 0.3917 - val_recall: 0.3609 - val_auc: 0.5654\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1.20685\n",
      "Epoch 321/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8447 - tp: 2104.0000 - fp: 918.0000 - tn: 8010.0000 - fn: 2360.0000 - accuracy: 0.6185 - precision: 0.6962 - recall: 0.4713 - auc: 0.7979 - val_loss: 1.6924 - val_tp: 205.0000 - val_fp: 230.0000 - val_tn: 762.0000 - val_fn: 291.0000 - val_accuracy: 0.4637 - val_precision: 0.4713 - val_recall: 0.4133 - val_auc: 0.6183\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.20685\n",
      "Epoch 322/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8507 - tp: 2074.0000 - fp: 897.0000 - tn: 8031.0000 - fn: 2390.0000 - accuracy: 0.6122 - precision: 0.6981 - recall: 0.4646 - auc: 0.7949 - val_loss: 2.1432 - val_tp: 196.0000 - val_fp: 283.0000 - val_tn: 709.0000 - val_fn: 300.0000 - val_accuracy: 0.4113 - val_precision: 0.4092 - val_recall: 0.3952 - val_auc: 0.5903\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1.20685\n",
      "Epoch 323/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8571 - tp: 2064.0000 - fp: 959.0000 - tn: 7969.0000 - fn: 2400.0000 - accuracy: 0.6055 - precision: 0.6828 - recall: 0.4624 - auc: 0.7893 - val_loss: 2.4689 - val_tp: 175.0000 - val_fp: 314.0000 - val_tn: 678.0000 - val_fn: 321.0000 - val_accuracy: 0.3548 - val_precision: 0.3579 - val_recall: 0.3528 - val_auc: 0.5410\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.20685\n",
      "Epoch 324/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8549 - tp: 2031.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2433.0000 - accuracy: 0.6129 - precision: 0.6861 - recall: 0.4550 - auc: 0.7917 - val_loss: 1.8584 - val_tp: 198.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 298.0000 - val_accuracy: 0.4375 - val_precision: 0.4459 - val_recall: 0.3992 - val_auc: 0.6045\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1.20685\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8577 - tp: 2048.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2416.0000 - accuracy: 0.6091 - precision: 0.6824 - recall: 0.4588 - auc: 0.7907 - val_loss: 1.5922 - val_tp: 179.0000 - val_fp: 220.0000 - val_tn: 772.0000 - val_fn: 317.0000 - val_accuracy: 0.4335 - val_precision: 0.4486 - val_recall: 0.3609 - val_auc: 0.6018\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1.20685\n",
      "Epoch 326/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8502 - tp: 2096.0000 - fp: 914.0000 - tn: 8014.0000 - fn: 2368.0000 - accuracy: 0.6107 - precision: 0.6963 - recall: 0.4695 - auc: 0.7964 - val_loss: 1.5014 - val_tp: 192.0000 - val_fp: 236.0000 - val_tn: 756.0000 - val_fn: 304.0000 - val_accuracy: 0.4294 - val_precision: 0.4486 - val_recall: 0.3871 - val_auc: 0.5887\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1.20685\n",
      "Epoch 327/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8630 - tp: 2043.0000 - fp: 950.0000 - tn: 7978.0000 - fn: 2421.0000 - accuracy: 0.6055 - precision: 0.6826 - recall: 0.4577 - auc: 0.7890 - val_loss: 2.0938 - val_tp: 225.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 271.0000 - val_accuracy: 0.4577 - val_precision: 0.4649 - val_recall: 0.4536 - val_auc: 0.6132\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1.20685\n",
      "Epoch 328/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8368 - tp: 2131.0000 - fp: 940.0000 - tn: 7988.0000 - fn: 2333.0000 - accuracy: 0.6205 - precision: 0.6939 - recall: 0.4774 - auc: 0.8039 - val_loss: 1.6347 - val_tp: 179.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 317.0000 - val_accuracy: 0.4032 - val_precision: 0.4050 - val_recall: 0.3609 - val_auc: 0.5672\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.20685\n",
      "Epoch 329/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8526 - tp: 2050.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2414.0000 - accuracy: 0.6100 - precision: 0.6811 - recall: 0.4592 - auc: 0.7932 - val_loss: 1.8499 - val_tp: 217.0000 - val_fp: 240.0000 - val_tn: 752.0000 - val_fn: 279.0000 - val_accuracy: 0.4738 - val_precision: 0.4748 - val_recall: 0.4375 - val_auc: 0.6179\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1.20685\n",
      "Epoch 330/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8497 - tp: 2083.0000 - fp: 943.0000 - tn: 7985.0000 - fn: 2381.0000 - accuracy: 0.6104 - precision: 0.6884 - recall: 0.4666 - auc: 0.7946 - val_loss: 1.6192 - val_tp: 197.0000 - val_fp: 231.0000 - val_tn: 761.0000 - val_fn: 299.0000 - val_accuracy: 0.4476 - val_precision: 0.4603 - val_recall: 0.3972 - val_auc: 0.6163\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.20685\n",
      "Epoch 331/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8439 - tp: 2114.0000 - fp: 984.0000 - tn: 7944.0000 - fn: 2350.0000 - accuracy: 0.6187 - precision: 0.6824 - recall: 0.4736 - auc: 0.7985 - val_loss: 1.9228 - val_tp: 214.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 282.0000 - val_accuracy: 0.4435 - val_precision: 0.4515 - val_recall: 0.4315 - val_auc: 0.6106\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1.20685\n",
      "Epoch 332/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8494 - tp: 2107.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2357.0000 - accuracy: 0.6169 - precision: 0.6861 - recall: 0.4720 - auc: 0.7966 - val_loss: 1.6016 - val_tp: 201.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 295.0000 - val_accuracy: 0.4294 - val_precision: 0.4398 - val_recall: 0.4052 - val_auc: 0.5947\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1.20685\n",
      "Epoch 333/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8478 - tp: 2098.0000 - fp: 969.0000 - tn: 7959.0000 - fn: 2366.0000 - accuracy: 0.6102 - precision: 0.6841 - recall: 0.4700 - auc: 0.7969 - val_loss: 3.3304 - val_tp: 238.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 258.0000 - val_accuracy: 0.4819 - val_precision: 0.4818 - val_recall: 0.4798 - val_auc: 0.6237\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1.20685\n",
      "Epoch 334/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8477 - tp: 2097.0000 - fp: 952.0000 - tn: 7976.0000 - fn: 2367.0000 - accuracy: 0.6095 - precision: 0.6878 - recall: 0.4698 - auc: 0.7951 - val_loss: 1.7750 - val_tp: 186.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 310.0000 - val_accuracy: 0.4153 - val_precision: 0.4189 - val_recall: 0.3750 - val_auc: 0.5851\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.20685\n",
      "Epoch 335/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8491 - tp: 2101.0000 - fp: 927.0000 - tn: 8001.0000 - fn: 2363.0000 - accuracy: 0.6192 - precision: 0.6939 - recall: 0.4707 - auc: 0.7968 - val_loss: 1.6988 - val_tp: 204.0000 - val_fp: 247.0000 - val_tn: 745.0000 - val_fn: 292.0000 - val_accuracy: 0.4456 - val_precision: 0.4523 - val_recall: 0.4113 - val_auc: 0.6086\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1.20685\n",
      "Epoch 336/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8486 - tp: 2061.0000 - fp: 949.0000 - tn: 7979.0000 - fn: 2403.0000 - accuracy: 0.6120 - precision: 0.6847 - recall: 0.4617 - auc: 0.7952 - val_loss: 1.9999 - val_tp: 198.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 298.0000 - val_accuracy: 0.4214 - val_precision: 0.4231 - val_recall: 0.3992 - val_auc: 0.5850\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.20685\n",
      "Epoch 337/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8566 - tp: 2072.0000 - fp: 952.0000 - tn: 7976.0000 - fn: 2392.0000 - accuracy: 0.6046 - precision: 0.6852 - recall: 0.4642 - auc: 0.7916 - val_loss: 1.8967 - val_tp: 203.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 293.0000 - val_accuracy: 0.4415 - val_precision: 0.4356 - val_recall: 0.4093 - val_auc: 0.6104\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1.20685\n",
      "Epoch 338/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8533 - tp: 2099.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2365.0000 - accuracy: 0.6062 - precision: 0.6835 - recall: 0.4702 - auc: 0.7927 - val_loss: 1.7638 - val_tp: 201.0000 - val_fp: 249.0000 - val_tn: 743.0000 - val_fn: 295.0000 - val_accuracy: 0.4254 - val_precision: 0.4467 - val_recall: 0.4052 - val_auc: 0.6027\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 1.20685\n",
      "Epoch 339/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8338 - tp: 2120.0000 - fp: 900.0000 - tn: 8028.0000 - fn: 2344.0000 - accuracy: 0.6254 - precision: 0.7020 - recall: 0.4749 - auc: 0.8062 - val_loss: 2.0616 - val_tp: 227.0000 - val_fp: 249.0000 - val_tn: 743.0000 - val_fn: 269.0000 - val_accuracy: 0.4738 - val_precision: 0.4769 - val_recall: 0.4577 - val_auc: 0.6153\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1.20685\n",
      "Epoch 340/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8445 - tp: 2140.0000 - fp: 935.0000 - tn: 7993.0000 - fn: 2324.0000 - accuracy: 0.6147 - precision: 0.6959 - recall: 0.4794 - auc: 0.7983 - val_loss: 1.9224 - val_tp: 216.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 280.0000 - val_accuracy: 0.4415 - val_precision: 0.4444 - val_recall: 0.4355 - val_auc: 0.6026\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1.20685\n",
      "Epoch 341/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8460 - tp: 2099.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2365.0000 - accuracy: 0.6181 - precision: 0.6909 - recall: 0.4702 - auc: 0.7983 - val_loss: 1.8827 - val_tp: 218.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 278.0000 - val_accuracy: 0.4415 - val_precision: 0.4486 - val_recall: 0.4395 - val_auc: 0.6187\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1.20685\n",
      "Epoch 342/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8548 - tp: 2106.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2358.0000 - accuracy: 0.6084 - precision: 0.6869 - recall: 0.4718 - auc: 0.7931 - val_loss: 2.0900 - val_tp: 210.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 286.0000 - val_accuracy: 0.4294 - val_precision: 0.4303 - val_recall: 0.4234 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1.20685\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8497 - tp: 2110.0000 - fp: 911.0000 - tn: 8017.0000 - fn: 2354.0000 - accuracy: 0.6163 - precision: 0.6984 - recall: 0.4727 - auc: 0.7967 - val_loss: 1.6036 - val_tp: 172.0000 - val_fp: 227.0000 - val_tn: 765.0000 - val_fn: 324.0000 - val_accuracy: 0.4194 - val_precision: 0.4311 - val_recall: 0.3468 - val_auc: 0.5721\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1.20685\n",
      "Epoch 344/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8617 - tp: 2107.0000 - fp: 997.0000 - tn: 7931.0000 - fn: 2357.0000 - accuracy: 0.6122 - precision: 0.6788 - recall: 0.4720 - auc: 0.7898 - val_loss: 1.7282 - val_tp: 181.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 315.0000 - val_accuracy: 0.3931 - val_precision: 0.3996 - val_recall: 0.3649 - val_auc: 0.5808\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1.20685\n",
      "Epoch 345/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8486 - tp: 2092.0000 - fp: 999.0000 - tn: 7929.0000 - fn: 2372.0000 - accuracy: 0.6120 - precision: 0.6768 - recall: 0.4686 - auc: 0.7962 - val_loss: 1.6972 - val_tp: 188.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 308.0000 - val_accuracy: 0.4214 - val_precision: 0.4234 - val_recall: 0.3790 - val_auc: 0.5851\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 1.20685\n",
      "Epoch 346/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8554 - tp: 2115.0000 - fp: 977.0000 - tn: 7951.0000 - fn: 2349.0000 - accuracy: 0.6073 - precision: 0.6840 - recall: 0.4738 - auc: 0.7914 - val_loss: 2.1026 - val_tp: 175.0000 - val_fp: 308.0000 - val_tn: 684.0000 - val_fn: 321.0000 - val_accuracy: 0.3609 - val_precision: 0.3623 - val_recall: 0.3528 - val_auc: 0.5416\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1.20685\n",
      "Epoch 347/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8392 - tp: 2127.0000 - fp: 945.0000 - tn: 7983.0000 - fn: 2337.0000 - accuracy: 0.6183 - precision: 0.6924 - recall: 0.4765 - auc: 0.8013 - val_loss: 1.8892 - val_tp: 221.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 275.0000 - val_accuracy: 0.4496 - val_precision: 0.4604 - val_recall: 0.4456 - val_auc: 0.6096\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1.20685\n",
      "Epoch 348/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8433 - tp: 2133.0000 - fp: 924.0000 - tn: 8004.0000 - fn: 2331.0000 - accuracy: 0.6190 - precision: 0.6977 - recall: 0.4778 - auc: 0.8008 - val_loss: 1.6338 - val_tp: 188.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 308.0000 - val_accuracy: 0.4173 - val_precision: 0.4372 - val_recall: 0.3790 - val_auc: 0.5859\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1.20685\n",
      "Epoch 349/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8402 - tp: 2133.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2331.0000 - accuracy: 0.6185 - precision: 0.6885 - recall: 0.4778 - auc: 0.8008 - val_loss: 2.1653 - val_tp: 191.0000 - val_fp: 285.0000 - val_tn: 707.0000 - val_fn: 305.0000 - val_accuracy: 0.3931 - val_precision: 0.4013 - val_recall: 0.3851 - val_auc: 0.5749\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1.20685\n",
      "Epoch 350/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8498 - tp: 2105.0000 - fp: 909.0000 - tn: 8019.0000 - fn: 2359.0000 - accuracy: 0.6066 - precision: 0.6984 - recall: 0.4716 - auc: 0.7956 - val_loss: 1.4554 - val_tp: 107.0000 - val_fp: 205.0000 - val_tn: 787.0000 - val_fn: 389.0000 - val_accuracy: 0.3589 - val_precision: 0.3429 - val_recall: 0.2157 - val_auc: 0.5340\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1.20685\n",
      "Epoch 351/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8529 - tp: 2089.0000 - fp: 1002.0000 - tn: 7926.0000 - fn: 2375.0000 - accuracy: 0.6138 - precision: 0.6758 - recall: 0.4680 - auc: 0.7926 - val_loss: 2.0399 - val_tp: 183.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 313.0000 - val_accuracy: 0.3770 - val_precision: 0.3828 - val_recall: 0.3690 - val_auc: 0.5622\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1.20685\n",
      "Epoch 352/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8601 - tp: 2075.0000 - fp: 979.0000 - tn: 7949.0000 - fn: 2389.0000 - accuracy: 0.6022 - precision: 0.6794 - recall: 0.4648 - auc: 0.7888 - val_loss: 1.6917 - val_tp: 198.0000 - val_fp: 227.0000 - val_tn: 765.0000 - val_fn: 298.0000 - val_accuracy: 0.4496 - val_precision: 0.4659 - val_recall: 0.3992 - val_auc: 0.6129\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 1.20685\n",
      "Epoch 353/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8538 - tp: 2094.0000 - fp: 974.0000 - tn: 7954.0000 - fn: 2370.0000 - accuracy: 0.6134 - precision: 0.6825 - recall: 0.4691 - auc: 0.7937 - val_loss: 2.0191 - val_tp: 198.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 298.0000 - val_accuracy: 0.4315 - val_precision: 0.4342 - val_recall: 0.3992 - val_auc: 0.5718\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1.20685\n",
      "Epoch 354/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8483 - tp: 2068.0000 - fp: 948.0000 - tn: 7980.0000 - fn: 2396.0000 - accuracy: 0.6118 - precision: 0.6857 - recall: 0.4633 - auc: 0.7956 - val_loss: 1.7081 - val_tp: 210.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 286.0000 - val_accuracy: 0.4355 - val_precision: 0.4468 - val_recall: 0.4234 - val_auc: 0.6029\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 1.20685\n",
      "Epoch 355/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8522 - tp: 2096.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2368.0000 - accuracy: 0.6093 - precision: 0.6852 - recall: 0.4695 - auc: 0.7932 - val_loss: 2.7563 - val_tp: 171.0000 - val_fp: 323.0000 - val_tn: 669.0000 - val_fn: 325.0000 - val_accuracy: 0.3448 - val_precision: 0.3462 - val_recall: 0.3448 - val_auc: 0.5594\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1.20685\n",
      "Epoch 356/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8510 - tp: 2100.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2364.0000 - accuracy: 0.6142 - precision: 0.6910 - recall: 0.4704 - auc: 0.7944 - val_loss: 2.1502 - val_tp: 205.0000 - val_fp: 285.0000 - val_tn: 707.0000 - val_fn: 291.0000 - val_accuracy: 0.4153 - val_precision: 0.4184 - val_recall: 0.4133 - val_auc: 0.5926\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 1.20685\n",
      "Epoch 357/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8489 - tp: 2090.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2374.0000 - accuracy: 0.6073 - precision: 0.6846 - recall: 0.4682 - auc: 0.7960 - val_loss: 2.0563 - val_tp: 195.0000 - val_fp: 291.0000 - val_tn: 701.0000 - val_fn: 301.0000 - val_accuracy: 0.3972 - val_precision: 0.4012 - val_recall: 0.3931 - val_auc: 0.5685\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 1.20685\n",
      "Epoch 358/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8415 - tp: 2083.0000 - fp: 934.0000 - tn: 7994.0000 - fn: 2381.0000 - accuracy: 0.6136 - precision: 0.6904 - recall: 0.4666 - auc: 0.7985 - val_loss: 2.2374 - val_tp: 221.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 275.0000 - val_accuracy: 0.4617 - val_precision: 0.4692 - val_recall: 0.4456 - val_auc: 0.6160\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1.20685\n",
      "Epoch 359/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8484 - tp: 2127.0000 - fp: 952.0000 - tn: 7976.0000 - fn: 2337.0000 - accuracy: 0.6192 - precision: 0.6908 - recall: 0.4765 - auc: 0.7968 - val_loss: 1.9885 - val_tp: 161.0000 - val_fp: 295.0000 - val_tn: 697.0000 - val_fn: 335.0000 - val_accuracy: 0.3548 - val_precision: 0.3531 - val_recall: 0.3246 - val_auc: 0.5370\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 1.20685\n",
      "Epoch 360/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8574 - tp: 2094.0000 - fp: 968.0000 - tn: 7960.0000 - fn: 2370.0000 - accuracy: 0.6120 - precision: 0.6839 - recall: 0.4691 - auc: 0.7921 - val_loss: 1.7762 - val_tp: 204.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 292.0000 - val_accuracy: 0.4335 - val_precision: 0.4397 - val_recall: 0.4113 - val_auc: 0.5738\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 1.20685\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8361 - tp: 2109.0000 - fp: 925.0000 - tn: 8003.0000 - fn: 2355.0000 - accuracy: 0.6149 - precision: 0.6951 - recall: 0.4724 - auc: 0.8022 - val_loss: 1.5207 - val_tp: 206.0000 - val_fp: 235.0000 - val_tn: 757.0000 - val_fn: 290.0000 - val_accuracy: 0.4617 - val_precision: 0.4671 - val_recall: 0.4153 - val_auc: 0.6302\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 1.20685\n",
      "Epoch 362/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8408 - tp: 2180.0000 - fp: 932.0000 - tn: 7996.0000 - fn: 2284.0000 - accuracy: 0.6216 - precision: 0.7005 - recall: 0.4884 - auc: 0.8020 - val_loss: 2.0597 - val_tp: 174.0000 - val_fp: 306.0000 - val_tn: 686.0000 - val_fn: 322.0000 - val_accuracy: 0.3649 - val_precision: 0.3625 - val_recall: 0.3508 - val_auc: 0.5513\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1.20685\n",
      "Epoch 363/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8499 - tp: 2116.0000 - fp: 910.0000 - tn: 8018.0000 - fn: 2348.0000 - accuracy: 0.6149 - precision: 0.6993 - recall: 0.4740 - auc: 0.7950 - val_loss: 1.8793 - val_tp: 213.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 283.0000 - val_accuracy: 0.4375 - val_precision: 0.4410 - val_recall: 0.4294 - val_auc: 0.5887\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1.20685\n",
      "Epoch 364/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8377 - tp: 2135.0000 - fp: 904.0000 - tn: 8024.0000 - fn: 2329.0000 - accuracy: 0.6223 - precision: 0.7025 - recall: 0.4783 - auc: 0.8028 - val_loss: 1.6325 - val_tp: 212.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 284.0000 - val_accuracy: 0.4516 - val_precision: 0.4659 - val_recall: 0.4274 - val_auc: 0.6146\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 1.20685\n",
      "Epoch 365/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8448 - tp: 2115.0000 - fp: 944.0000 - tn: 7984.0000 - fn: 2349.0000 - accuracy: 0.6190 - precision: 0.6914 - recall: 0.4738 - auc: 0.8001 - val_loss: 2.5816 - val_tp: 221.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 275.0000 - val_accuracy: 0.4496 - val_precision: 0.4529 - val_recall: 0.4456 - val_auc: 0.6096\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 1.20685\n",
      "Epoch 366/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8416 - tp: 2130.0000 - fp: 1004.0000 - tn: 7924.0000 - fn: 2334.0000 - accuracy: 0.6116 - precision: 0.6796 - recall: 0.4772 - auc: 0.7994 - val_loss: 1.8907 - val_tp: 170.0000 - val_fp: 285.0000 - val_tn: 707.0000 - val_fn: 326.0000 - val_accuracy: 0.3649 - val_precision: 0.3736 - val_recall: 0.3427 - val_auc: 0.5396\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1.20685\n",
      "Epoch 367/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8419 - tp: 2143.0000 - fp: 956.0000 - tn: 7972.0000 - fn: 2321.0000 - accuracy: 0.6239 - precision: 0.6915 - recall: 0.4801 - auc: 0.7996 - val_loss: 1.6008 - val_tp: 217.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 279.0000 - val_accuracy: 0.4718 - val_precision: 0.4728 - val_recall: 0.4375 - val_auc: 0.6182\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 1.20685\n",
      "Epoch 368/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8454 - tp: 2113.0000 - fp: 947.0000 - tn: 7981.0000 - fn: 2351.0000 - accuracy: 0.6140 - precision: 0.6905 - recall: 0.4733 - auc: 0.7975 - val_loss: 1.9902 - val_tp: 226.0000 - val_fp: 252.0000 - val_tn: 740.0000 - val_fn: 270.0000 - val_accuracy: 0.4617 - val_precision: 0.4728 - val_recall: 0.4556 - val_auc: 0.6257\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1.20685\n",
      "Epoch 369/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8463 - tp: 2149.0000 - fp: 989.0000 - tn: 7939.0000 - fn: 2315.0000 - accuracy: 0.6122 - precision: 0.6848 - recall: 0.4814 - auc: 0.7971 - val_loss: 1.7547 - val_tp: 213.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 283.0000 - val_accuracy: 0.4798 - val_precision: 0.4681 - val_recall: 0.4294 - val_auc: 0.6051\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1.20685\n",
      "Epoch 370/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8512 - tp: 2093.0000 - fp: 978.0000 - tn: 7950.0000 - fn: 2371.0000 - accuracy: 0.6060 - precision: 0.6815 - recall: 0.4689 - auc: 0.7944 - val_loss: 1.5824 - val_tp: 189.0000 - val_fp: 220.0000 - val_tn: 772.0000 - val_fn: 307.0000 - val_accuracy: 0.4698 - val_precision: 0.4621 - val_recall: 0.3810 - val_auc: 0.6037\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1.20685\n",
      "Epoch 371/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8426 - tp: 2135.0000 - fp: 948.0000 - tn: 7980.0000 - fn: 2329.0000 - accuracy: 0.6185 - precision: 0.6925 - recall: 0.4783 - auc: 0.7986 - val_loss: 1.7812 - val_tp: 191.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 305.0000 - val_accuracy: 0.4173 - val_precision: 0.4254 - val_recall: 0.3851 - val_auc: 0.5871\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1.20685\n",
      "Epoch 372/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8471 - tp: 2127.0000 - fp: 945.0000 - tn: 7983.0000 - fn: 2337.0000 - accuracy: 0.6169 - precision: 0.6924 - recall: 0.4765 - auc: 0.7970 - val_loss: 1.8833 - val_tp: 192.0000 - val_fp: 282.0000 - val_tn: 710.0000 - val_fn: 304.0000 - val_accuracy: 0.4032 - val_precision: 0.4051 - val_recall: 0.3871 - val_auc: 0.5679\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1.20685\n",
      "Epoch 373/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8295 - tp: 2164.0000 - fp: 918.0000 - tn: 8010.0000 - fn: 2300.0000 - accuracy: 0.6284 - precision: 0.7021 - recall: 0.4848 - auc: 0.8065 - val_loss: 1.9632 - val_tp: 209.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 287.0000 - val_accuracy: 0.4355 - val_precision: 0.4543 - val_recall: 0.4214 - val_auc: 0.6016\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1.20685\n",
      "Epoch 374/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8390 - tp: 2134.0000 - fp: 962.0000 - tn: 7966.0000 - fn: 2330.0000 - accuracy: 0.6248 - precision: 0.6893 - recall: 0.4780 - auc: 0.8012 - val_loss: 1.5351 - val_tp: 159.0000 - val_fp: 225.0000 - val_tn: 767.0000 - val_fn: 337.0000 - val_accuracy: 0.4052 - val_precision: 0.4141 - val_recall: 0.3206 - val_auc: 0.5553\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1.20685\n",
      "Epoch 375/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8354 - tp: 2119.0000 - fp: 958.0000 - tn: 7970.0000 - fn: 2345.0000 - accuracy: 0.6145 - precision: 0.6887 - recall: 0.4747 - auc: 0.8027 - val_loss: 1.4350 - val_tp: 179.0000 - val_fp: 215.0000 - val_tn: 777.0000 - val_fn: 317.0000 - val_accuracy: 0.4294 - val_precision: 0.4543 - val_recall: 0.3609 - val_auc: 0.5912\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1.20685\n",
      "Epoch 376/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8391 - tp: 2180.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2284.0000 - accuracy: 0.6205 - precision: 0.7012 - recall: 0.4884 - auc: 0.8026 - val_loss: 1.7016 - val_tp: 212.0000 - val_fp: 225.0000 - val_tn: 767.0000 - val_fn: 284.0000 - val_accuracy: 0.4657 - val_precision: 0.4851 - val_recall: 0.4274 - val_auc: 0.6277\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1.20685\n",
      "Epoch 377/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8426 - tp: 2125.0000 - fp: 986.0000 - tn: 7942.0000 - fn: 2339.0000 - accuracy: 0.6129 - precision: 0.6831 - recall: 0.4760 - auc: 0.7991 - val_loss: 1.6547 - val_tp: 195.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 301.0000 - val_accuracy: 0.4133 - val_precision: 0.4176 - val_recall: 0.3931 - val_auc: 0.5871\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1.20685\n",
      "Epoch 378/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8322 - tp: 2179.0000 - fp: 896.0000 - tn: 8032.0000 - fn: 2285.0000 - accuracy: 0.6272 - precision: 0.7086 - recall: 0.4881 - auc: 0.8066 - val_loss: 1.7468 - val_tp: 190.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 306.0000 - val_accuracy: 0.4294 - val_precision: 0.4388 - val_recall: 0.3831 - val_auc: 0.5998\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1.20685\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8417 - tp: 2189.0000 - fp: 959.0000 - tn: 7969.0000 - fn: 2275.0000 - accuracy: 0.6190 - precision: 0.6954 - recall: 0.4904 - auc: 0.8007 - val_loss: 1.8299 - val_tp: 206.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 290.0000 - val_accuracy: 0.4375 - val_precision: 0.4383 - val_recall: 0.4153 - val_auc: 0.5995\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1.20685\n",
      "Epoch 380/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8345 - tp: 2177.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2287.0000 - accuracy: 0.6214 - precision: 0.6913 - recall: 0.4877 - auc: 0.8034 - val_loss: 1.5985 - val_tp: 158.0000 - val_fp: 214.0000 - val_tn: 778.0000 - val_fn: 338.0000 - val_accuracy: 0.3891 - val_precision: 0.4247 - val_recall: 0.3185 - val_auc: 0.5567\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 1.20685\n",
      "Epoch 381/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8332 - tp: 2150.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2314.0000 - accuracy: 0.6109 - precision: 0.6907 - recall: 0.4816 - auc: 0.8027 - val_loss: 2.5197 - val_tp: 171.0000 - val_fp: 314.0000 - val_tn: 678.0000 - val_fn: 325.0000 - val_accuracy: 0.3548 - val_precision: 0.3526 - val_recall: 0.3448 - val_auc: 0.5341\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1.20685\n",
      "Epoch 382/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8307 - tp: 2168.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2296.0000 - accuracy: 0.6207 - precision: 0.6920 - recall: 0.4857 - auc: 0.8056 - val_loss: 1.9167 - val_tp: 210.0000 - val_fp: 255.0000 - val_tn: 737.0000 - val_fn: 286.0000 - val_accuracy: 0.4456 - val_precision: 0.4516 - val_recall: 0.4234 - val_auc: 0.6051\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1.20685\n",
      "Epoch 383/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8355 - tp: 2168.0000 - fp: 962.0000 - tn: 7966.0000 - fn: 2296.0000 - accuracy: 0.6212 - precision: 0.6927 - recall: 0.4857 - auc: 0.8029 - val_loss: 3.4291 - val_tp: 144.0000 - val_fp: 344.0000 - val_tn: 648.0000 - val_fn: 352.0000 - val_accuracy: 0.2984 - val_precision: 0.2951 - val_recall: 0.2903 - val_auc: 0.4794\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1.20685\n",
      "Epoch 384/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8518 - tp: 2090.0000 - fp: 999.0000 - tn: 7929.0000 - fn: 2374.0000 - accuracy: 0.6044 - precision: 0.6766 - recall: 0.4682 - auc: 0.7922 - val_loss: 1.9689 - val_tp: 183.0000 - val_fp: 285.0000 - val_tn: 707.0000 - val_fn: 313.0000 - val_accuracy: 0.3911 - val_precision: 0.3910 - val_recall: 0.3690 - val_auc: 0.5878\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1.20685\n",
      "Epoch 385/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8370 - tp: 2121.0000 - fp: 958.0000 - tn: 7970.0000 - fn: 2343.0000 - accuracy: 0.6120 - precision: 0.6889 - recall: 0.4751 - auc: 0.8000 - val_loss: 1.5243 - val_tp: 184.0000 - val_fp: 241.0000 - val_tn: 751.0000 - val_fn: 312.0000 - val_accuracy: 0.4194 - val_precision: 0.4329 - val_recall: 0.3710 - val_auc: 0.6030\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 1.20685\n",
      "Epoch 386/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8407 - tp: 2134.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2330.0000 - accuracy: 0.6136 - precision: 0.6886 - recall: 0.4780 - auc: 0.8003 - val_loss: 1.9308 - val_tp: 225.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 271.0000 - val_accuracy: 0.4778 - val_precision: 0.4777 - val_recall: 0.4536 - val_auc: 0.6259\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1.20685\n",
      "Epoch 387/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8332 - tp: 2199.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2265.0000 - accuracy: 0.6221 - precision: 0.6954 - recall: 0.4926 - auc: 0.8037 - val_loss: 1.7528 - val_tp: 194.0000 - val_fp: 234.0000 - val_tn: 758.0000 - val_fn: 302.0000 - val_accuracy: 0.4516 - val_precision: 0.4533 - val_recall: 0.3911 - val_auc: 0.6008\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1.20685\n",
      "Epoch 388/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8353 - tp: 2153.0000 - fp: 969.0000 - tn: 7959.0000 - fn: 2311.0000 - accuracy: 0.6147 - precision: 0.6896 - recall: 0.4823 - auc: 0.8025 - val_loss: 1.9969 - val_tp: 159.0000 - val_fp: 290.0000 - val_tn: 702.0000 - val_fn: 337.0000 - val_accuracy: 0.3508 - val_precision: 0.3541 - val_recall: 0.3206 - val_auc: 0.5288\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1.20685\n",
      "Epoch 389/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8304 - tp: 2201.0000 - fp: 934.0000 - tn: 7994.0000 - fn: 2263.0000 - accuracy: 0.6369 - precision: 0.7021 - recall: 0.4931 - auc: 0.8080 - val_loss: 1.7337 - val_tp: 205.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 291.0000 - val_accuracy: 0.4435 - val_precision: 0.4447 - val_recall: 0.4133 - val_auc: 0.6094\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1.20685\n",
      "Epoch 390/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8283 - tp: 2157.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2307.0000 - accuracy: 0.6219 - precision: 0.6972 - recall: 0.4832 - auc: 0.8058 - val_loss: 1.5726 - val_tp: 170.0000 - val_fp: 220.0000 - val_tn: 772.0000 - val_fn: 326.0000 - val_accuracy: 0.4133 - val_precision: 0.4359 - val_recall: 0.3427 - val_auc: 0.5672\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1.20685\n",
      "Epoch 391/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8248 - tp: 2206.0000 - fp: 923.0000 - tn: 8005.0000 - fn: 2258.0000 - accuracy: 0.6290 - precision: 0.7050 - recall: 0.4942 - auc: 0.8091 - val_loss: 2.3361 - val_tp: 215.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 281.0000 - val_accuracy: 0.4415 - val_precision: 0.4397 - val_recall: 0.4335 - val_auc: 0.6110\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1.20685\n",
      "Epoch 392/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8269 - tp: 2177.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2287.0000 - accuracy: 0.6228 - precision: 0.7000 - recall: 0.4877 - auc: 0.8093 - val_loss: 2.3752 - val_tp: 209.0000 - val_fp: 280.0000 - val_tn: 712.0000 - val_fn: 287.0000 - val_accuracy: 0.4274 - val_precision: 0.4274 - val_recall: 0.4214 - val_auc: 0.6151\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1.20685\n",
      "Epoch 393/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8304 - tp: 2166.0000 - fp: 901.0000 - tn: 8027.0000 - fn: 2298.0000 - accuracy: 0.6248 - precision: 0.7062 - recall: 0.4852 - auc: 0.8062 - val_loss: 1.7649 - val_tp: 203.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 293.0000 - val_accuracy: 0.4274 - val_precision: 0.4319 - val_recall: 0.4093 - val_auc: 0.5961\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1.20685\n",
      "Epoch 394/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8307 - tp: 2179.0000 - fp: 985.0000 - tn: 7943.0000 - fn: 2285.0000 - accuracy: 0.6142 - precision: 0.6887 - recall: 0.4881 - auc: 0.8054 - val_loss: 1.6008 - val_tp: 205.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 291.0000 - val_accuracy: 0.4395 - val_precision: 0.4409 - val_recall: 0.4133 - val_auc: 0.6138\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1.20685\n",
      "Epoch 395/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8271 - tp: 2202.0000 - fp: 930.0000 - tn: 7998.0000 - fn: 2262.0000 - accuracy: 0.6268 - precision: 0.7031 - recall: 0.4933 - auc: 0.8084 - val_loss: 1.7937 - val_tp: 207.0000 - val_fp: 241.0000 - val_tn: 751.0000 - val_fn: 289.0000 - val_accuracy: 0.4536 - val_precision: 0.4621 - val_recall: 0.4173 - val_auc: 0.6135\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1.20685\n",
      "Epoch 396/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8194 - tp: 2219.0000 - fp: 943.0000 - tn: 7985.0000 - fn: 2245.0000 - accuracy: 0.6277 - precision: 0.7018 - recall: 0.4971 - auc: 0.8117 - val_loss: 1.8218 - val_tp: 206.0000 - val_fp: 258.0000 - val_tn: 734.0000 - val_fn: 290.0000 - val_accuracy: 0.4476 - val_precision: 0.4440 - val_recall: 0.4153 - val_auc: 0.5950\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1.20685\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8330 - tp: 2209.0000 - fp: 954.0000 - tn: 7974.0000 - fn: 2255.0000 - accuracy: 0.6261 - precision: 0.6984 - recall: 0.4948 - auc: 0.8057 - val_loss: 1.8704 - val_tp: 183.0000 - val_fp: 281.0000 - val_tn: 711.0000 - val_fn: 313.0000 - val_accuracy: 0.3931 - val_precision: 0.3944 - val_recall: 0.3690 - val_auc: 0.5505\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1.20685\n",
      "Epoch 398/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8304 - tp: 2178.0000 - fp: 970.0000 - tn: 7958.0000 - fn: 2286.0000 - accuracy: 0.6221 - precision: 0.6919 - recall: 0.4879 - auc: 0.8057 - val_loss: 2.1378 - val_tp: 194.0000 - val_fp: 292.0000 - val_tn: 700.0000 - val_fn: 302.0000 - val_accuracy: 0.3972 - val_precision: 0.3992 - val_recall: 0.3911 - val_auc: 0.5496\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1.20685\n",
      "Epoch 399/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8390 - tp: 2169.0000 - fp: 979.0000 - tn: 7949.0000 - fn: 2295.0000 - accuracy: 0.6125 - precision: 0.6890 - recall: 0.4859 - auc: 0.7991 - val_loss: 2.1526 - val_tp: 193.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 303.0000 - val_accuracy: 0.4133 - val_precision: 0.4159 - val_recall: 0.3891 - val_auc: 0.5791\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 1.20685\n",
      "Epoch 400/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8336 - tp: 2178.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2286.0000 - accuracy: 0.6263 - precision: 0.6930 - recall: 0.4879 - auc: 0.8040 - val_loss: 1.5147 - val_tp: 194.0000 - val_fp: 230.0000 - val_tn: 762.0000 - val_fn: 302.0000 - val_accuracy: 0.4435 - val_precision: 0.4575 - val_recall: 0.3911 - val_auc: 0.6060\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1.20685\n",
      "Epoch 401/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8270 - tp: 2165.0000 - fp: 925.0000 - tn: 8003.0000 - fn: 2299.0000 - accuracy: 0.6263 - precision: 0.7006 - recall: 0.4850 - auc: 0.8083 - val_loss: 2.1081 - val_tp: 209.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 287.0000 - val_accuracy: 0.4294 - val_precision: 0.4354 - val_recall: 0.4214 - val_auc: 0.5968\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1.20685\n",
      "Epoch 402/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8360 - tp: 2166.0000 - fp: 961.0000 - tn: 7967.0000 - fn: 2298.0000 - accuracy: 0.6160 - precision: 0.6927 - recall: 0.4852 - auc: 0.8012 - val_loss: 2.3618 - val_tp: 228.0000 - val_fp: 249.0000 - val_tn: 743.0000 - val_fn: 268.0000 - val_accuracy: 0.4798 - val_precision: 0.4780 - val_recall: 0.4597 - val_auc: 0.6289\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1.20685\n",
      "Epoch 403/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8237 - tp: 2210.0000 - fp: 941.0000 - tn: 7987.0000 - fn: 2254.0000 - accuracy: 0.6270 - precision: 0.7014 - recall: 0.4951 - auc: 0.8103 - val_loss: 1.5339 - val_tp: 178.0000 - val_fp: 222.0000 - val_tn: 770.0000 - val_fn: 318.0000 - val_accuracy: 0.4375 - val_precision: 0.4450 - val_recall: 0.3589 - val_auc: 0.5912\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1.20685\n",
      "Epoch 404/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8333 - tp: 2167.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2297.0000 - accuracy: 0.6263 - precision: 0.6977 - recall: 0.4854 - auc: 0.8046 - val_loss: 2.1708 - val_tp: 200.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 296.0000 - val_accuracy: 0.4173 - val_precision: 0.4219 - val_recall: 0.4032 - val_auc: 0.5942\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1.20685\n",
      "Epoch 405/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8373 - tp: 2197.0000 - fp: 998.0000 - tn: 7930.0000 - fn: 2267.0000 - accuracy: 0.6234 - precision: 0.6876 - recall: 0.4922 - auc: 0.8015 - val_loss: 1.8850 - val_tp: 214.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 282.0000 - val_accuracy: 0.4516 - val_precision: 0.4524 - val_recall: 0.4315 - val_auc: 0.6223\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1.20685\n",
      "Epoch 406/500\n",
      "4464/4464 [==============================] - 0s 73us/step - loss: 0.8313 - tp: 2193.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2271.0000 - accuracy: 0.6243 - precision: 0.6927 - recall: 0.4913 - auc: 0.8058 - val_loss: 1.5854 - val_tp: 198.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 298.0000 - val_accuracy: 0.4456 - val_precision: 0.4500 - val_recall: 0.3992 - val_auc: 0.5966\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1.20685\n",
      "Epoch 407/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8371 - tp: 2194.0000 - fp: 1009.0000 - tn: 7919.0000 - fn: 2270.0000 - accuracy: 0.6201 - precision: 0.6850 - recall: 0.4915 - auc: 0.8021 - val_loss: 1.6857 - val_tp: 197.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 299.0000 - val_accuracy: 0.4133 - val_precision: 0.4209 - val_recall: 0.3972 - val_auc: 0.5886\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1.20685\n",
      "Epoch 408/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8225 - tp: 2214.0000 - fp: 931.0000 - tn: 7997.0000 - fn: 2250.0000 - accuracy: 0.6259 - precision: 0.7040 - recall: 0.4960 - auc: 0.8100 - val_loss: 1.8999 - val_tp: 201.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 295.0000 - val_accuracy: 0.4173 - val_precision: 0.4249 - val_recall: 0.4052 - val_auc: 0.5789\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 1.20685\n",
      "Epoch 409/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8356 - tp: 2175.0000 - fp: 980.0000 - tn: 7948.0000 - fn: 2289.0000 - accuracy: 0.6252 - precision: 0.6894 - recall: 0.4872 - auc: 0.8035 - val_loss: 1.7832 - val_tp: 202.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 294.0000 - val_accuracy: 0.4536 - val_precision: 0.4459 - val_recall: 0.4073 - val_auc: 0.5886\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1.20685\n",
      "Epoch 410/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8334 - tp: 2190.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2274.0000 - accuracy: 0.6252 - precision: 0.6924 - recall: 0.4906 - auc: 0.8060 - val_loss: 2.2831 - val_tp: 214.0000 - val_fp: 273.0000 - val_tn: 719.0000 - val_fn: 282.0000 - val_accuracy: 0.4335 - val_precision: 0.4394 - val_recall: 0.4315 - val_auc: 0.6077\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1.20685\n",
      "Epoch 411/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8204 - tp: 2184.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2280.0000 - accuracy: 0.6228 - precision: 0.6920 - recall: 0.4892 - auc: 0.8099 - val_loss: 1.6755 - val_tp: 201.0000 - val_fp: 243.0000 - val_tn: 749.0000 - val_fn: 295.0000 - val_accuracy: 0.4516 - val_precision: 0.4527 - val_recall: 0.4052 - val_auc: 0.6110\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1.20685\n",
      "Epoch 412/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8287 - tp: 2180.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2284.0000 - accuracy: 0.6212 - precision: 0.6914 - recall: 0.4884 - auc: 0.8050 - val_loss: 1.7785 - val_tp: 185.0000 - val_fp: 265.0000 - val_tn: 727.0000 - val_fn: 311.0000 - val_accuracy: 0.4052 - val_precision: 0.4111 - val_recall: 0.3730 - val_auc: 0.5875\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1.20685\n",
      "Epoch 413/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8324 - tp: 2198.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2266.0000 - accuracy: 0.6198 - precision: 0.6949 - recall: 0.4924 - auc: 0.8061 - val_loss: 1.7505 - val_tp: 211.0000 - val_fp: 248.0000 - val_tn: 744.0000 - val_fn: 285.0000 - val_accuracy: 0.4435 - val_precision: 0.4597 - val_recall: 0.4254 - val_auc: 0.6050\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1.20685\n",
      "Epoch 414/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8437 - tp: 2171.0000 - fp: 1001.0000 - tn: 7927.0000 - fn: 2293.0000 - accuracy: 0.6125 - precision: 0.6844 - recall: 0.4863 - auc: 0.7985 - val_loss: 2.1762 - val_tp: 194.0000 - val_fp: 282.0000 - val_tn: 710.0000 - val_fn: 302.0000 - val_accuracy: 0.3972 - val_precision: 0.4076 - val_recall: 0.3911 - val_auc: 0.5703\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1.20685\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8271 - tp: 2199.0000 - fp: 946.0000 - tn: 7982.0000 - fn: 2265.0000 - accuracy: 0.6263 - precision: 0.6992 - recall: 0.4926 - auc: 0.8066 - val_loss: 1.8570 - val_tp: 225.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 271.0000 - val_accuracy: 0.4617 - val_precision: 0.4697 - val_recall: 0.4536 - val_auc: 0.6284\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 1.20685\n",
      "Epoch 416/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8402 - tp: 2168.0000 - fp: 955.0000 - tn: 7973.0000 - fn: 2296.0000 - accuracy: 0.6172 - precision: 0.6942 - recall: 0.4857 - auc: 0.8021 - val_loss: 2.5190 - val_tp: 187.0000 - val_fp: 303.0000 - val_tn: 689.0000 - val_fn: 309.0000 - val_accuracy: 0.3810 - val_precision: 0.3816 - val_recall: 0.3770 - val_auc: 0.5738\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 1.20685\n",
      "Epoch 417/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8284 - tp: 2216.0000 - fp: 976.0000 - tn: 7952.0000 - fn: 2248.0000 - accuracy: 0.6212 - precision: 0.6942 - recall: 0.4964 - auc: 0.8057 - val_loss: 1.6332 - val_tp: 204.0000 - val_fp: 270.0000 - val_tn: 722.0000 - val_fn: 292.0000 - val_accuracy: 0.4294 - val_precision: 0.4304 - val_recall: 0.4113 - val_auc: 0.6038\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1.20685\n",
      "Epoch 418/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8220 - tp: 2207.0000 - fp: 926.0000 - tn: 8002.0000 - fn: 2257.0000 - accuracy: 0.6266 - precision: 0.7044 - recall: 0.4944 - auc: 0.8109 - val_loss: 2.0896 - val_tp: 183.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 313.0000 - val_accuracy: 0.3911 - val_precision: 0.3970 - val_recall: 0.3690 - val_auc: 0.5574\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1.20685\n",
      "Epoch 419/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8320 - tp: 2185.0000 - fp: 956.0000 - tn: 7972.0000 - fn: 2279.0000 - accuracy: 0.6194 - precision: 0.6956 - recall: 0.4895 - auc: 0.8043 - val_loss: 1.7786 - val_tp: 176.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 320.0000 - val_accuracy: 0.3831 - val_precision: 0.3964 - val_recall: 0.3548 - val_auc: 0.5489\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 1.20685\n",
      "Epoch 420/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8344 - tp: 2209.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2255.0000 - accuracy: 0.6237 - precision: 0.6962 - recall: 0.4948 - auc: 0.8040 - val_loss: 2.2739 - val_tp: 201.0000 - val_fp: 272.0000 - val_tn: 720.0000 - val_fn: 295.0000 - val_accuracy: 0.4153 - val_precision: 0.4249 - val_recall: 0.4052 - val_auc: 0.5828\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 1.20685\n",
      "Epoch 421/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8351 - tp: 2137.0000 - fp: 956.0000 - tn: 7972.0000 - fn: 2327.0000 - accuracy: 0.6169 - precision: 0.6909 - recall: 0.4787 - auc: 0.8019 - val_loss: 1.5249 - val_tp: 187.0000 - val_fp: 239.0000 - val_tn: 753.0000 - val_fn: 309.0000 - val_accuracy: 0.4294 - val_precision: 0.4390 - val_recall: 0.3770 - val_auc: 0.5769\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1.20685\n",
      "Epoch 422/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8435 - tp: 2218.0000 - fp: 1007.0000 - tn: 7921.0000 - fn: 2246.0000 - accuracy: 0.6190 - precision: 0.6878 - recall: 0.4969 - auc: 0.7994 - val_loss: 2.0636 - val_tp: 155.0000 - val_fp: 310.0000 - val_tn: 682.0000 - val_fn: 341.0000 - val_accuracy: 0.3327 - val_precision: 0.3333 - val_recall: 0.3125 - val_auc: 0.5020\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 1.20685\n",
      "Epoch 423/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8268 - tp: 2220.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2244.0000 - accuracy: 0.6349 - precision: 0.6997 - recall: 0.4973 - auc: 0.8079 - val_loss: 1.8412 - val_tp: 202.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 294.0000 - val_accuracy: 0.4315 - val_precision: 0.4353 - val_recall: 0.4073 - val_auc: 0.6079\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 1.20685\n",
      "Epoch 424/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8247 - tp: 2209.0000 - fp: 955.0000 - tn: 7973.0000 - fn: 2255.0000 - accuracy: 0.6254 - precision: 0.6982 - recall: 0.4948 - auc: 0.8082 - val_loss: 2.7398 - val_tp: 163.0000 - val_fp: 321.0000 - val_tn: 671.0000 - val_fn: 333.0000 - val_accuracy: 0.3327 - val_precision: 0.3368 - val_recall: 0.3286 - val_auc: 0.5267\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 1.20685\n",
      "Epoch 425/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8141 - tp: 2234.0000 - fp: 908.0000 - tn: 8020.0000 - fn: 2230.0000 - accuracy: 0.6438 - precision: 0.7110 - recall: 0.5004 - auc: 0.8167 - val_loss: 1.7319 - val_tp: 206.0000 - val_fp: 273.0000 - val_tn: 719.0000 - val_fn: 290.0000 - val_accuracy: 0.4294 - val_precision: 0.4301 - val_recall: 0.4153 - val_auc: 0.5988\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 1.20685\n",
      "Epoch 426/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8322 - tp: 2191.0000 - fp: 1002.0000 - tn: 7926.0000 - fn: 2273.0000 - accuracy: 0.6201 - precision: 0.6862 - recall: 0.4908 - auc: 0.8038 - val_loss: 2.0392 - val_tp: 194.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 302.0000 - val_accuracy: 0.4073 - val_precision: 0.4172 - val_recall: 0.3911 - val_auc: 0.5799\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1.20685\n",
      "Epoch 427/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8314 - tp: 2185.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2279.0000 - accuracy: 0.6248 - precision: 0.6963 - recall: 0.4895 - auc: 0.8054 - val_loss: 2.1791 - val_tp: 211.0000 - val_fp: 277.0000 - val_tn: 715.0000 - val_fn: 285.0000 - val_accuracy: 0.4335 - val_precision: 0.4324 - val_recall: 0.4254 - val_auc: 0.6100\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1.20685\n",
      "Epoch 428/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.8237 - tp: 2214.0000 - fp: 952.0000 - tn: 7976.0000 - fn: 2250.0000 - accuracy: 0.6284 - precision: 0.6993 - recall: 0.4960 - auc: 0.8103 - val_loss: 1.9139 - val_tp: 217.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 279.0000 - val_accuracy: 0.4556 - val_precision: 0.4578 - val_recall: 0.4375 - val_auc: 0.6160\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1.20685\n",
      "Epoch 429/500\n",
      "4464/4464 [==============================] - 0s 66us/step - loss: 0.8319 - tp: 2213.0000 - fp: 964.0000 - tn: 7964.0000 - fn: 2251.0000 - accuracy: 0.6198 - precision: 0.6966 - recall: 0.4957 - auc: 0.8059 - val_loss: 1.9588 - val_tp: 186.0000 - val_fp: 298.0000 - val_tn: 694.0000 - val_fn: 310.0000 - val_accuracy: 0.3810 - val_precision: 0.3843 - val_recall: 0.3750 - val_auc: 0.5766\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 1.20685\n",
      "Epoch 430/500\n",
      "4464/4464 [==============================] - 0s 65us/step - loss: 0.8245 - tp: 2216.0000 - fp: 963.0000 - tn: 7965.0000 - fn: 2248.0000 - accuracy: 0.6308 - precision: 0.6971 - recall: 0.4964 - auc: 0.8094 - val_loss: 2.1528 - val_tp: 196.0000 - val_fp: 281.0000 - val_tn: 711.0000 - val_fn: 300.0000 - val_accuracy: 0.4093 - val_precision: 0.4109 - val_recall: 0.3952 - val_auc: 0.5680\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 1.20685\n",
      "Epoch 431/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8127 - tp: 2237.0000 - fp: 930.0000 - tn: 7998.0000 - fn: 2227.0000 - accuracy: 0.6400 - precision: 0.7063 - recall: 0.5011 - auc: 0.8151 - val_loss: 2.0858 - val_tp: 178.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 318.0000 - val_accuracy: 0.3891 - val_precision: 0.3938 - val_recall: 0.3589 - val_auc: 0.5510\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 1.20685\n",
      "Epoch 432/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8210 - tp: 2209.0000 - fp: 924.0000 - tn: 8004.0000 - fn: 2255.0000 - accuracy: 0.6299 - precision: 0.7051 - recall: 0.4948 - auc: 0.8108 - val_loss: 1.5652 - val_tp: 204.0000 - val_fp: 239.0000 - val_tn: 753.0000 - val_fn: 292.0000 - val_accuracy: 0.4536 - val_precision: 0.4605 - val_recall: 0.4113 - val_auc: 0.6147\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 1.20685\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8229 - tp: 2200.0000 - fp: 981.0000 - tn: 7947.0000 - fn: 2264.0000 - accuracy: 0.6239 - precision: 0.6916 - recall: 0.4928 - auc: 0.8086 - val_loss: 1.5119 - val_tp: 166.0000 - val_fp: 219.0000 - val_tn: 773.0000 - val_fn: 330.0000 - val_accuracy: 0.4375 - val_precision: 0.4312 - val_recall: 0.3347 - val_auc: 0.5625\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1.20685\n",
      "Epoch 434/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8273 - tp: 2225.0000 - fp: 980.0000 - tn: 7948.0000 - fn: 2239.0000 - accuracy: 0.6223 - precision: 0.6942 - recall: 0.4984 - auc: 0.8065 - val_loss: 1.9423 - val_tp: 222.0000 - val_fp: 255.0000 - val_tn: 737.0000 - val_fn: 274.0000 - val_accuracy: 0.4617 - val_precision: 0.4654 - val_recall: 0.4476 - val_auc: 0.6153\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 1.20685\n",
      "Epoch 435/500\n",
      "4464/4464 [==============================] - 0s 67us/step - loss: 0.8166 - tp: 2269.0000 - fp: 970.0000 - tn: 7958.0000 - fn: 2195.0000 - accuracy: 0.6297 - precision: 0.7005 - recall: 0.5083 - auc: 0.8119 - val_loss: 1.7386 - val_tp: 201.0000 - val_fp: 234.0000 - val_tn: 758.0000 - val_fn: 295.0000 - val_accuracy: 0.4395 - val_precision: 0.4621 - val_recall: 0.4052 - val_auc: 0.6092\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 1.20685\n",
      "Epoch 436/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8314 - tp: 2190.0000 - fp: 987.0000 - tn: 7941.0000 - fn: 2274.0000 - accuracy: 0.6190 - precision: 0.6893 - recall: 0.4906 - auc: 0.8046 - val_loss: 1.7171 - val_tp: 201.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 295.0000 - val_accuracy: 0.4415 - val_precision: 0.4537 - val_recall: 0.4052 - val_auc: 0.6077\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 1.20685\n",
      "Epoch 437/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8409 - tp: 2168.0000 - fp: 998.0000 - tn: 7930.0000 - fn: 2296.0000 - accuracy: 0.6203 - precision: 0.6848 - recall: 0.4857 - auc: 0.7994 - val_loss: 1.9095 - val_tp: 179.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 317.0000 - val_accuracy: 0.3992 - val_precision: 0.4050 - val_recall: 0.3609 - val_auc: 0.5713\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1.20685\n",
      "Epoch 438/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8417 - tp: 2152.0000 - fp: 1010.0000 - tn: 7918.0000 - fn: 2312.0000 - accuracy: 0.6113 - precision: 0.6806 - recall: 0.4821 - auc: 0.7983 - val_loss: 1.8702 - val_tp: 190.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 306.0000 - val_accuracy: 0.4294 - val_precision: 0.4222 - val_recall: 0.3831 - val_auc: 0.5729\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1.20685\n",
      "Epoch 439/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8262 - tp: 2216.0000 - fp: 950.0000 - tn: 7978.0000 - fn: 2248.0000 - accuracy: 0.6302 - precision: 0.6999 - recall: 0.4964 - auc: 0.8084 - val_loss: 2.2660 - val_tp: 213.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 283.0000 - val_accuracy: 0.4577 - val_precision: 0.4532 - val_recall: 0.4294 - val_auc: 0.6085\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 1.20685\n",
      "Epoch 440/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8157 - tp: 2271.0000 - fp: 944.0000 - tn: 7984.0000 - fn: 2193.0000 - accuracy: 0.6425 - precision: 0.7064 - recall: 0.5087 - auc: 0.8147 - val_loss: 2.5345 - val_tp: 177.0000 - val_fp: 305.0000 - val_tn: 687.0000 - val_fn: 319.0000 - val_accuracy: 0.3629 - val_precision: 0.3672 - val_recall: 0.3569 - val_auc: 0.5404\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 1.20685\n",
      "Epoch 441/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8322 - tp: 2169.0000 - fp: 977.0000 - tn: 7951.0000 - fn: 2295.0000 - accuracy: 0.6207 - precision: 0.6894 - recall: 0.4859 - auc: 0.8038 - val_loss: 1.8865 - val_tp: 201.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 295.0000 - val_accuracy: 0.4173 - val_precision: 0.4360 - val_recall: 0.4052 - val_auc: 0.5933\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1.20685\n",
      "Epoch 442/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8178 - tp: 2211.0000 - fp: 934.0000 - tn: 7994.0000 - fn: 2253.0000 - accuracy: 0.6288 - precision: 0.7030 - recall: 0.4953 - auc: 0.8122 - val_loss: 1.7947 - val_tp: 216.0000 - val_fp: 242.0000 - val_tn: 750.0000 - val_fn: 280.0000 - val_accuracy: 0.4637 - val_precision: 0.4716 - val_recall: 0.4355 - val_auc: 0.6054\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 1.20685\n",
      "Epoch 443/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8261 - tp: 2241.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2223.0000 - accuracy: 0.6288 - precision: 0.6975 - recall: 0.5020 - auc: 0.8081 - val_loss: 1.8138 - val_tp: 192.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 304.0000 - val_accuracy: 0.4214 - val_precision: 0.4211 - val_recall: 0.3871 - val_auc: 0.5806\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 1.20685\n",
      "Epoch 444/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8205 - tp: 2286.0000 - fp: 958.0000 - tn: 7970.0000 - fn: 2178.0000 - accuracy: 0.6290 - precision: 0.7047 - recall: 0.5121 - auc: 0.8104 - val_loss: 2.3280 - val_tp: 201.0000 - val_fp: 288.0000 - val_tn: 704.0000 - val_fn: 295.0000 - val_accuracy: 0.4093 - val_precision: 0.4110 - val_recall: 0.4052 - val_auc: 0.6058\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 1.20685\n",
      "Epoch 445/500\n",
      "4464/4464 [==============================] - 0s 72us/step - loss: 0.8256 - tp: 2174.0000 - fp: 960.0000 - tn: 7968.0000 - fn: 2290.0000 - accuracy: 0.6263 - precision: 0.6937 - recall: 0.4870 - auc: 0.8069 - val_loss: 1.6499 - val_tp: 188.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 308.0000 - val_accuracy: 0.4234 - val_precision: 0.4234 - val_recall: 0.3790 - val_auc: 0.6025\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1.20685\n",
      "Epoch 446/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8344 - tp: 2210.0000 - fp: 986.0000 - tn: 7942.0000 - fn: 2254.0000 - accuracy: 0.6163 - precision: 0.6915 - recall: 0.4951 - auc: 0.8029 - val_loss: 1.6613 - val_tp: 175.0000 - val_fp: 225.0000 - val_tn: 767.0000 - val_fn: 321.0000 - val_accuracy: 0.4133 - val_precision: 0.4375 - val_recall: 0.3528 - val_auc: 0.5859\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 1.20685\n",
      "Epoch 447/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8271 - tp: 2258.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2206.0000 - accuracy: 0.6268 - precision: 0.7063 - recall: 0.5058 - auc: 0.8080 - val_loss: 1.6641 - val_tp: 175.0000 - val_fp: 264.0000 - val_tn: 728.0000 - val_fn: 321.0000 - val_accuracy: 0.3931 - val_precision: 0.3986 - val_recall: 0.3528 - val_auc: 0.5629\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 1.20685\n",
      "Epoch 448/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8233 - tp: 2237.0000 - fp: 983.0000 - tn: 7945.0000 - fn: 2227.0000 - accuracy: 0.6288 - precision: 0.6947 - recall: 0.5011 - auc: 0.8103 - val_loss: 1.4886 - val_tp: 188.0000 - val_fp: 221.0000 - val_tn: 771.0000 - val_fn: 308.0000 - val_accuracy: 0.4556 - val_precision: 0.4597 - val_recall: 0.3790 - val_auc: 0.6067\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1.20685\n",
      "Epoch 449/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8297 - tp: 2206.0000 - fp: 991.0000 - tn: 7937.0000 - fn: 2258.0000 - accuracy: 0.6286 - precision: 0.6900 - recall: 0.4942 - auc: 0.8065 - val_loss: 1.5335 - val_tp: 161.0000 - val_fp: 222.0000 - val_tn: 770.0000 - val_fn: 335.0000 - val_accuracy: 0.4073 - val_precision: 0.4204 - val_recall: 0.3246 - val_auc: 0.5698\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1.20685\n",
      "Epoch 450/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8178 - tp: 2245.0000 - fp: 950.0000 - tn: 7978.0000 - fn: 2219.0000 - accuracy: 0.6402 - precision: 0.7027 - recall: 0.5029 - auc: 0.8136 - val_loss: 1.9080 - val_tp: 211.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 285.0000 - val_accuracy: 0.4536 - val_precision: 0.4538 - val_recall: 0.4254 - val_auc: 0.6112\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 1.20685\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8322 - tp: 2190.0000 - fp: 989.0000 - tn: 7939.0000 - fn: 2274.0000 - accuracy: 0.6207 - precision: 0.6889 - recall: 0.4906 - auc: 0.8038 - val_loss: 2.3752 - val_tp: 228.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 268.0000 - val_accuracy: 0.4637 - val_precision: 0.4730 - val_recall: 0.4597 - val_auc: 0.6261\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 1.20685\n",
      "Epoch 452/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8162 - tp: 2211.0000 - fp: 943.0000 - tn: 7985.0000 - fn: 2253.0000 - accuracy: 0.6317 - precision: 0.7010 - recall: 0.4953 - auc: 0.8125 - val_loss: 2.1342 - val_tp: 211.0000 - val_fp: 265.0000 - val_tn: 727.0000 - val_fn: 285.0000 - val_accuracy: 0.4315 - val_precision: 0.4433 - val_recall: 0.4254 - val_auc: 0.5938\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 1.20685\n",
      "Epoch 453/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8377 - tp: 2210.0000 - fp: 1036.0000 - tn: 7892.0000 - fn: 2254.0000 - accuracy: 0.6176 - precision: 0.6808 - recall: 0.4951 - auc: 0.8032 - val_loss: 1.5159 - val_tp: 170.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 326.0000 - val_accuracy: 0.4113 - val_precision: 0.4167 - val_recall: 0.3427 - val_auc: 0.5673\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1.20685\n",
      "Epoch 454/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8124 - tp: 2249.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2215.0000 - accuracy: 0.6317 - precision: 0.7059 - recall: 0.5038 - auc: 0.8146 - val_loss: 2.0555 - val_tp: 224.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 272.0000 - val_accuracy: 0.4778 - val_precision: 0.4766 - val_recall: 0.4516 - val_auc: 0.6202\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 1.20685\n",
      "Epoch 455/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8293 - tp: 2197.0000 - fp: 974.0000 - tn: 7954.0000 - fn: 2267.0000 - accuracy: 0.6230 - precision: 0.6928 - recall: 0.4922 - auc: 0.8062 - val_loss: 1.8250 - val_tp: 197.0000 - val_fp: 260.0000 - val_tn: 732.0000 - val_fn: 299.0000 - val_accuracy: 0.4335 - val_precision: 0.4311 - val_recall: 0.3972 - val_auc: 0.5957\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1.20685\n",
      "Epoch 456/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8176 - tp: 2243.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2221.0000 - accuracy: 0.6259 - precision: 0.7018 - recall: 0.5025 - auc: 0.8122 - val_loss: 1.9627 - val_tp: 202.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 294.0000 - val_accuracy: 0.4234 - val_precision: 0.4298 - val_recall: 0.4073 - val_auc: 0.5694\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1.20685\n",
      "Epoch 457/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8206 - tp: 2220.0000 - fp: 915.0000 - tn: 8013.0000 - fn: 2244.0000 - accuracy: 0.6331 - precision: 0.7081 - recall: 0.4973 - auc: 0.8117 - val_loss: 1.5822 - val_tp: 191.0000 - val_fp: 253.0000 - val_tn: 739.0000 - val_fn: 305.0000 - val_accuracy: 0.4214 - val_precision: 0.4302 - val_recall: 0.3851 - val_auc: 0.5765\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 1.20685\n",
      "Epoch 458/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8273 - tp: 2227.0000 - fp: 989.0000 - tn: 7939.0000 - fn: 2237.0000 - accuracy: 0.6216 - precision: 0.6925 - recall: 0.4989 - auc: 0.8080 - val_loss: 2.6607 - val_tp: 165.0000 - val_fp: 316.0000 - val_tn: 676.0000 - val_fn: 331.0000 - val_accuracy: 0.3387 - val_precision: 0.3430 - val_recall: 0.3327 - val_auc: 0.5087\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 1.20685\n",
      "Epoch 459/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8302 - tp: 2190.0000 - fp: 952.0000 - tn: 7976.0000 - fn: 2274.0000 - accuracy: 0.6210 - precision: 0.6970 - recall: 0.4906 - auc: 0.8056 - val_loss: 1.6677 - val_tp: 213.0000 - val_fp: 246.0000 - val_tn: 746.0000 - val_fn: 283.0000 - val_accuracy: 0.4556 - val_precision: 0.4641 - val_recall: 0.4294 - val_auc: 0.5983\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1.20685\n",
      "Epoch 460/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8173 - tp: 2221.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2243.0000 - accuracy: 0.6310 - precision: 0.6956 - recall: 0.4975 - auc: 0.8120 - val_loss: 2.0767 - val_tp: 207.0000 - val_fp: 269.0000 - val_tn: 723.0000 - val_fn: 289.0000 - val_accuracy: 0.4355 - val_precision: 0.4349 - val_recall: 0.4173 - val_auc: 0.5990\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1.20685\n",
      "Epoch 461/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8127 - tp: 2188.0000 - fp: 939.0000 - tn: 7989.0000 - fn: 2276.0000 - accuracy: 0.6293 - precision: 0.6997 - recall: 0.4901 - auc: 0.8140 - val_loss: 2.1203 - val_tp: 199.0000 - val_fp: 278.0000 - val_tn: 714.0000 - val_fn: 297.0000 - val_accuracy: 0.4194 - val_precision: 0.4172 - val_recall: 0.4012 - val_auc: 0.5991\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 1.20685\n",
      "Epoch 462/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8396 - tp: 2209.0000 - fp: 1023.0000 - tn: 7905.0000 - fn: 2255.0000 - accuracy: 0.6232 - precision: 0.6835 - recall: 0.4948 - auc: 0.8017 - val_loss: 1.7813 - val_tp: 220.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 276.0000 - val_accuracy: 0.4536 - val_precision: 0.4564 - val_recall: 0.4435 - val_auc: 0.6145\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1.20685\n",
      "Epoch 463/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8146 - tp: 2251.0000 - fp: 957.0000 - tn: 7971.0000 - fn: 2213.0000 - accuracy: 0.6266 - precision: 0.7017 - recall: 0.5043 - auc: 0.8130 - val_loss: 2.3819 - val_tp: 226.0000 - val_fp: 254.0000 - val_tn: 738.0000 - val_fn: 270.0000 - val_accuracy: 0.4657 - val_precision: 0.4708 - val_recall: 0.4556 - val_auc: 0.6083\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 1.20685\n",
      "Epoch 464/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8232 - tp: 2150.0000 - fp: 938.0000 - tn: 7990.0000 - fn: 2314.0000 - accuracy: 0.6310 - precision: 0.6962 - recall: 0.4816 - auc: 0.8091 - val_loss: 2.3684 - val_tp: 219.0000 - val_fp: 267.0000 - val_tn: 725.0000 - val_fn: 277.0000 - val_accuracy: 0.4496 - val_precision: 0.4506 - val_recall: 0.4415 - val_auc: 0.6145\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1.20685\n",
      "Epoch 465/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8133 - tp: 2237.0000 - fp: 962.0000 - tn: 7966.0000 - fn: 2227.0000 - accuracy: 0.6371 - precision: 0.6993 - recall: 0.5011 - auc: 0.8145 - val_loss: 1.9689 - val_tp: 209.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 287.0000 - val_accuracy: 0.4496 - val_precision: 0.4553 - val_recall: 0.4214 - val_auc: 0.5976\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 1.20685\n",
      "Epoch 466/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8275 - tp: 2210.0000 - fp: 966.0000 - tn: 7962.0000 - fn: 2254.0000 - accuracy: 0.6248 - precision: 0.6958 - recall: 0.4951 - auc: 0.8079 - val_loss: 3.2821 - val_tp: 233.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 263.0000 - val_accuracy: 0.4778 - val_precision: 0.4765 - val_recall: 0.4698 - val_auc: 0.6196\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1.20685\n",
      "Epoch 467/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8276 - tp: 2233.0000 - fp: 995.0000 - tn: 7933.0000 - fn: 2231.0000 - accuracy: 0.6297 - precision: 0.6918 - recall: 0.5002 - auc: 0.8078 - val_loss: 1.9092 - val_tp: 194.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 302.0000 - val_accuracy: 0.4254 - val_precision: 0.4254 - val_recall: 0.3911 - val_auc: 0.5825\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 1.20685\n",
      "Epoch 468/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8006 - tp: 2307.0000 - fp: 921.0000 - tn: 8007.0000 - fn: 2157.0000 - accuracy: 0.6358 - precision: 0.7147 - recall: 0.5168 - auc: 0.8208 - val_loss: 2.1377 - val_tp: 204.0000 - val_fp: 266.0000 - val_tn: 726.0000 - val_fn: 292.0000 - val_accuracy: 0.4415 - val_precision: 0.4340 - val_recall: 0.4113 - val_auc: 0.6104\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 1.20685\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8279 - tp: 2208.0000 - fp: 998.0000 - tn: 7930.0000 - fn: 2256.0000 - accuracy: 0.6210 - precision: 0.6887 - recall: 0.4946 - auc: 0.8061 - val_loss: 2.0896 - val_tp: 215.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 281.0000 - val_accuracy: 0.4375 - val_precision: 0.4424 - val_recall: 0.4335 - val_auc: 0.6179\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1.20685\n",
      "Epoch 470/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.7995 - tp: 2277.0000 - fp: 894.0000 - tn: 8034.0000 - fn: 2187.0000 - accuracy: 0.6472 - precision: 0.7181 - recall: 0.5101 - auc: 0.8234 - val_loss: 2.1534 - val_tp: 220.0000 - val_fp: 266.0000 - val_tn: 726.0000 - val_fn: 276.0000 - val_accuracy: 0.4516 - val_precision: 0.4527 - val_recall: 0.4435 - val_auc: 0.6106\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1.20685\n",
      "Epoch 471/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8254 - tp: 2246.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2218.0000 - accuracy: 0.6281 - precision: 0.6977 - recall: 0.5031 - auc: 0.8085 - val_loss: 2.2255 - val_tp: 215.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 281.0000 - val_accuracy: 0.4375 - val_precision: 0.4388 - val_recall: 0.4335 - val_auc: 0.6087\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 1.20685\n",
      "Epoch 472/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8377 - tp: 2166.0000 - fp: 1009.0000 - tn: 7919.0000 - fn: 2298.0000 - accuracy: 0.6145 - precision: 0.6822 - recall: 0.4852 - auc: 0.8017 - val_loss: 2.0623 - val_tp: 211.0000 - val_fp: 276.0000 - val_tn: 716.0000 - val_fn: 285.0000 - val_accuracy: 0.4274 - val_precision: 0.4333 - val_recall: 0.4254 - val_auc: 0.5958\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1.20685\n",
      "Epoch 473/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8142 - tp: 2224.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2240.0000 - accuracy: 0.6346 - precision: 0.7045 - recall: 0.4982 - auc: 0.8148 - val_loss: 1.6387 - val_tp: 196.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 300.0000 - val_accuracy: 0.4335 - val_precision: 0.4327 - val_recall: 0.3952 - val_auc: 0.6031\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 1.20685\n",
      "Epoch 474/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8176 - tp: 2242.0000 - fp: 947.0000 - tn: 7981.0000 - fn: 2222.0000 - accuracy: 0.6297 - precision: 0.7030 - recall: 0.5022 - auc: 0.8135 - val_loss: 2.0920 - val_tp: 205.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 291.0000 - val_accuracy: 0.4315 - val_precision: 0.4390 - val_recall: 0.4133 - val_auc: 0.6081\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 1.20685\n",
      "Epoch 475/500\n",
      "4464/4464 [==============================] - 0s 71us/step - loss: 0.8245 - tp: 2249.0000 - fp: 961.0000 - tn: 7967.0000 - fn: 2215.0000 - accuracy: 0.6281 - precision: 0.7006 - recall: 0.5038 - auc: 0.8096 - val_loss: 1.7694 - val_tp: 192.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 304.0000 - val_accuracy: 0.4073 - val_precision: 0.4111 - val_recall: 0.3871 - val_auc: 0.5884\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 1.20685\n",
      "Epoch 476/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8334 - tp: 2233.0000 - fp: 985.0000 - tn: 7943.0000 - fn: 2231.0000 - accuracy: 0.6295 - precision: 0.6939 - recall: 0.5002 - auc: 0.8039 - val_loss: 1.6204 - val_tp: 177.0000 - val_fp: 255.0000 - val_tn: 737.0000 - val_fn: 319.0000 - val_accuracy: 0.4032 - val_precision: 0.4097 - val_recall: 0.3569 - val_auc: 0.5654\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1.20685\n",
      "Epoch 477/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8104 - tp: 2277.0000 - fp: 937.0000 - tn: 7991.0000 - fn: 2187.0000 - accuracy: 0.6322 - precision: 0.7085 - recall: 0.5101 - auc: 0.8161 - val_loss: 1.5520 - val_tp: 174.0000 - val_fp: 245.0000 - val_tn: 747.0000 - val_fn: 322.0000 - val_accuracy: 0.3992 - val_precision: 0.4153 - val_recall: 0.3508 - val_auc: 0.5654\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 1.20685\n",
      "Epoch 478/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8130 - tp: 2290.0000 - fp: 978.0000 - tn: 7950.0000 - fn: 2174.0000 - accuracy: 0.6340 - precision: 0.7007 - recall: 0.5130 - auc: 0.8152 - val_loss: 1.7401 - val_tp: 217.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 279.0000 - val_accuracy: 0.4516 - val_precision: 0.4647 - val_recall: 0.4375 - val_auc: 0.6010\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 1.20685\n",
      "Epoch 479/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8130 - tp: 2270.0000 - fp: 1015.0000 - tn: 7913.0000 - fn: 2194.0000 - accuracy: 0.6297 - precision: 0.6910 - recall: 0.5085 - auc: 0.8134 - val_loss: 3.2856 - val_tp: 173.0000 - val_fp: 314.0000 - val_tn: 678.0000 - val_fn: 323.0000 - val_accuracy: 0.3548 - val_precision: 0.3552 - val_recall: 0.3488 - val_auc: 0.5155\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1.20685\n",
      "Epoch 480/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8137 - tp: 2283.0000 - fp: 929.0000 - tn: 7999.0000 - fn: 2181.0000 - accuracy: 0.6299 - precision: 0.7108 - recall: 0.5114 - auc: 0.8132 - val_loss: 2.2951 - val_tp: 222.0000 - val_fp: 263.0000 - val_tn: 729.0000 - val_fn: 274.0000 - val_accuracy: 0.4597 - val_precision: 0.4577 - val_recall: 0.4476 - val_auc: 0.6058\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1.20685\n",
      "Epoch 481/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8132 - tp: 2269.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2195.0000 - accuracy: 0.6302 - precision: 0.7042 - recall: 0.5083 - auc: 0.8156 - val_loss: 2.0497 - val_tp: 213.0000 - val_fp: 256.0000 - val_tn: 736.0000 - val_fn: 283.0000 - val_accuracy: 0.4577 - val_precision: 0.4542 - val_recall: 0.4294 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 1.20685\n",
      "Epoch 482/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8110 - tp: 2295.0000 - fp: 930.0000 - tn: 7998.0000 - fn: 2169.0000 - accuracy: 0.6306 - precision: 0.7116 - recall: 0.5141 - auc: 0.8170 - val_loss: 1.9401 - val_tp: 197.0000 - val_fp: 247.0000 - val_tn: 745.0000 - val_fn: 299.0000 - val_accuracy: 0.4234 - val_precision: 0.4437 - val_recall: 0.3972 - val_auc: 0.5968\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1.20685\n",
      "Epoch 483/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8123 - tp: 2263.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2201.0000 - accuracy: 0.6313 - precision: 0.7081 - recall: 0.5069 - auc: 0.8155 - val_loss: 2.0901 - val_tp: 221.0000 - val_fp: 240.0000 - val_tn: 752.0000 - val_fn: 275.0000 - val_accuracy: 0.4677 - val_precision: 0.4794 - val_recall: 0.4456 - val_auc: 0.6262\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 1.20685\n",
      "Epoch 484/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8097 - tp: 2265.0000 - fp: 953.0000 - tn: 7975.0000 - fn: 2199.0000 - accuracy: 0.6322 - precision: 0.7039 - recall: 0.5074 - auc: 0.8166 - val_loss: 1.7913 - val_tp: 205.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 291.0000 - val_accuracy: 0.4355 - val_precision: 0.4437 - val_recall: 0.4133 - val_auc: 0.5957\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 1.20685\n",
      "Epoch 485/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8122 - tp: 2261.0000 - fp: 961.0000 - tn: 7967.0000 - fn: 2203.0000 - accuracy: 0.6355 - precision: 0.7017 - recall: 0.5065 - auc: 0.8151 - val_loss: 2.0478 - val_tp: 224.0000 - val_fp: 251.0000 - val_tn: 741.0000 - val_fn: 272.0000 - val_accuracy: 0.4657 - val_precision: 0.4716 - val_recall: 0.4516 - val_auc: 0.6314\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1.20685\n",
      "Epoch 486/500\n",
      "4464/4464 [==============================] - 0s 68us/step - loss: 0.8319 - tp: 2206.0000 - fp: 1012.0000 - tn: 7916.0000 - fn: 2258.0000 - accuracy: 0.6223 - precision: 0.6855 - recall: 0.4942 - auc: 0.8047 - val_loss: 2.3835 - val_tp: 167.0000 - val_fp: 307.0000 - val_tn: 685.0000 - val_fn: 329.0000 - val_accuracy: 0.3488 - val_precision: 0.3523 - val_recall: 0.3367 - val_auc: 0.5096\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1.20685\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8132 - tp: 2240.0000 - fp: 982.0000 - tn: 7946.0000 - fn: 2224.0000 - accuracy: 0.6266 - precision: 0.6952 - recall: 0.5018 - auc: 0.8126 - val_loss: 1.5166 - val_tp: 167.0000 - val_fp: 227.0000 - val_tn: 765.0000 - val_fn: 329.0000 - val_accuracy: 0.4073 - val_precision: 0.4239 - val_recall: 0.3367 - val_auc: 0.5808\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1.20685\n",
      "Epoch 488/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8148 - tp: 2299.0000 - fp: 997.0000 - tn: 7931.0000 - fn: 2165.0000 - accuracy: 0.6328 - precision: 0.6975 - recall: 0.5150 - auc: 0.8136 - val_loss: 1.8629 - val_tp: 150.0000 - val_fp: 268.0000 - val_tn: 724.0000 - val_fn: 346.0000 - val_accuracy: 0.3589 - val_precision: 0.3589 - val_recall: 0.3024 - val_auc: 0.5258\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 1.20685\n",
      "Epoch 489/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8185 - tp: 2248.0000 - fp: 969.0000 - tn: 7959.0000 - fn: 2216.0000 - accuracy: 0.6281 - precision: 0.6988 - recall: 0.5036 - auc: 0.8124 - val_loss: 1.8506 - val_tp: 211.0000 - val_fp: 238.0000 - val_tn: 754.0000 - val_fn: 285.0000 - val_accuracy: 0.4496 - val_precision: 0.4699 - val_recall: 0.4254 - val_auc: 0.6138\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1.20685\n",
      "Epoch 490/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8154 - tp: 2253.0000 - fp: 973.0000 - tn: 7955.0000 - fn: 2211.0000 - accuracy: 0.6351 - precision: 0.6984 - recall: 0.5047 - auc: 0.8137 - val_loss: 1.8319 - val_tp: 179.0000 - val_fp: 261.0000 - val_tn: 731.0000 - val_fn: 317.0000 - val_accuracy: 0.3911 - val_precision: 0.4068 - val_recall: 0.3609 - val_auc: 0.5576\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1.20685\n",
      "Epoch 491/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8112 - tp: 2256.0000 - fp: 969.0000 - tn: 7959.0000 - fn: 2208.0000 - accuracy: 0.6306 - precision: 0.6995 - recall: 0.5054 - auc: 0.8156 - val_loss: 1.8739 - val_tp: 219.0000 - val_fp: 240.0000 - val_tn: 752.0000 - val_fn: 277.0000 - val_accuracy: 0.4657 - val_precision: 0.4771 - val_recall: 0.4415 - val_auc: 0.6224\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1.20685\n",
      "Epoch 492/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8140 - tp: 2255.0000 - fp: 942.0000 - tn: 7986.0000 - fn: 2209.0000 - accuracy: 0.6393 - precision: 0.7053 - recall: 0.5052 - auc: 0.8150 - val_loss: 2.8351 - val_tp: 241.0000 - val_fp: 250.0000 - val_tn: 742.0000 - val_fn: 255.0000 - val_accuracy: 0.4899 - val_precision: 0.4908 - val_recall: 0.4859 - val_auc: 0.6146\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 1.20685\n",
      "Epoch 493/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8114 - tp: 2285.0000 - fp: 970.0000 - tn: 7958.0000 - fn: 2179.0000 - accuracy: 0.6315 - precision: 0.7020 - recall: 0.5119 - auc: 0.8147 - val_loss: 2.2879 - val_tp: 211.0000 - val_fp: 257.0000 - val_tn: 735.0000 - val_fn: 285.0000 - val_accuracy: 0.4476 - val_precision: 0.4509 - val_recall: 0.4254 - val_auc: 0.6005\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 1.20685\n",
      "Epoch 494/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8081 - tp: 2306.0000 - fp: 933.0000 - tn: 7995.0000 - fn: 2158.0000 - accuracy: 0.6398 - precision: 0.7119 - recall: 0.5166 - auc: 0.8181 - val_loss: 1.7860 - val_tp: 212.0000 - val_fp: 265.0000 - val_tn: 727.0000 - val_fn: 284.0000 - val_accuracy: 0.4415 - val_precision: 0.4444 - val_recall: 0.4274 - val_auc: 0.6130\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1.20685\n",
      "Epoch 495/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8085 - tp: 2324.0000 - fp: 985.0000 - tn: 7943.0000 - fn: 2140.0000 - accuracy: 0.6398 - precision: 0.7023 - recall: 0.5206 - auc: 0.8173 - val_loss: 2.2084 - val_tp: 203.0000 - val_fp: 275.0000 - val_tn: 717.0000 - val_fn: 293.0000 - val_accuracy: 0.4234 - val_precision: 0.4247 - val_recall: 0.4093 - val_auc: 0.5955\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1.20685\n",
      "Epoch 496/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8145 - tp: 2238.0000 - fp: 972.0000 - tn: 7956.0000 - fn: 2226.0000 - accuracy: 0.6257 - precision: 0.6972 - recall: 0.5013 - auc: 0.8130 - val_loss: 2.0522 - val_tp: 213.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 283.0000 - val_accuracy: 0.4536 - val_precision: 0.4513 - val_recall: 0.4294 - val_auc: 0.6174\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1.20685\n",
      "Epoch 497/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8109 - tp: 2238.0000 - fp: 955.0000 - tn: 7973.0000 - fn: 2226.0000 - accuracy: 0.6331 - precision: 0.7009 - recall: 0.5013 - auc: 0.8154 - val_loss: 2.1148 - val_tp: 200.0000 - val_fp: 274.0000 - val_tn: 718.0000 - val_fn: 296.0000 - val_accuracy: 0.4173 - val_precision: 0.4219 - val_recall: 0.4032 - val_auc: 0.5775\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1.20685\n",
      "Epoch 498/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8105 - tp: 2279.0000 - fp: 965.0000 - tn: 7963.0000 - fn: 2185.0000 - accuracy: 0.6440 - precision: 0.7025 - recall: 0.5105 - auc: 0.8170 - val_loss: 1.9151 - val_tp: 210.0000 - val_fp: 262.0000 - val_tn: 730.0000 - val_fn: 286.0000 - val_accuracy: 0.4355 - val_precision: 0.4449 - val_recall: 0.4234 - val_auc: 0.5837\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1.20685\n",
      "Epoch 499/500\n",
      "4464/4464 [==============================] - 0s 69us/step - loss: 0.8071 - tp: 2341.0000 - fp: 982.0000 - tn: 7946.0000 - fn: 2123.0000 - accuracy: 0.6434 - precision: 0.7045 - recall: 0.5244 - auc: 0.8186 - val_loss: 2.0099 - val_tp: 217.0000 - val_fp: 259.0000 - val_tn: 733.0000 - val_fn: 279.0000 - val_accuracy: 0.4536 - val_precision: 0.4559 - val_recall: 0.4375 - val_auc: 0.6269\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 1.20685\n",
      "Epoch 500/500\n",
      "4464/4464 [==============================] - 0s 70us/step - loss: 0.8044 - tp: 2315.0000 - fp: 945.0000 - tn: 7983.0000 - fn: 2149.0000 - accuracy: 0.6425 - precision: 0.7101 - recall: 0.5186 - auc: 0.8193 - val_loss: 1.9152 - val_tp: 196.0000 - val_fp: 271.0000 - val_tn: 721.0000 - val_fn: 300.0000 - val_accuracy: 0.4274 - val_precision: 0.4197 - val_recall: 0.3952 - val_auc: 0.5640\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1.20685\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(x=X_train, \n",
    "                    y=Y_train, \n",
    "                    batch_size=128, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    shuffle=True,\n",
    "                    callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "plotted_metrics = ['accuracy']\n",
    "\n",
    "fig = plt.figure(figsize=(18, 4 * len(plotted_metrics)))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "\n",
    "for idx, metric in enumerate(plotted_metrics):\n",
    "    plt.subplot(len(plotted_metrics), 2, 2*idx+1)\n",
    "    plt.title(metric)\n",
    "    plt.plot(history_dict[metric])\n",
    "    \n",
    "    plt.subplot(len(plotted_metrics), 2, 2*idx+2)\n",
    "    plt.title('val_{}'.format(metric))\n",
    "    plt.plot(history_dict['val_{}'.format(metric)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_down_while_steady:  14\n",
      "pred_steady_while_steady:  349\n",
      "pred_up_while_steady:  291\n"
     ]
    }
   ],
   "source": [
    "pred_down_while_steady = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 0 and x[1] == 1])\n",
    "print('pred_down_while_steady: ', pred_down_while_steady)\n",
    "\n",
    "pred_steady_while_steady = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 1 and x[1] == 1])\n",
    "print('pred_steady_while_steady: ', pred_steady_while_steady)\n",
    "\n",
    "pred_up_while_steady = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 2 and x[1] == 1])\n",
    "print('pred_up_while_steady: ', pred_up_while_steady)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_down_while_down:  43\n",
      "pred_steady_while_down:  159\n",
      "pred_up_while_down:  341\n"
     ]
    }
   ],
   "source": [
    "pred_down_while_down = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 0 and x[1] == 0])\n",
    "print('pred_down_while_down: ', pred_down_while_down)\n",
    "\n",
    "pred_steady_while_down = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 1 and x[1] == 0])\n",
    "print('pred_steady_while_down: ', pred_steady_while_down)\n",
    "\n",
    "pred_up_while_down = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 2 and x[1] == 0])\n",
    "print('pred_up_while_down: ', pred_up_while_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_down_while_up:  29\n",
      "pred_steady_while_up:  240\n",
      "pred_up_while_up:  518\n"
     ]
    }
   ],
   "source": [
    "pred_down_while_up = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 0 and x[1] == 2])\n",
    "print('pred_down_while_up: ', pred_down_while_up)\n",
    "\n",
    "pred_steady_while_up = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 1 and x[1] == 2])\n",
    "print('pred_steady_while_up: ', pred_steady_while_up)\n",
    "\n",
    "pred_up_while_up = sum([1 for x in zip(np.argmax(preds, axis=1), labels) if x[0] == 2 and x[1] == 2])\n",
    "print('pred_up_while_up: ', pred_up_while_up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
